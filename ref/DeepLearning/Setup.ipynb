{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from fastai.vision.all import *\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import correlate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.core.magic import register_cell_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:17:52.549497: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-25 14:17:52.560615: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-25 14:17:52.572659: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-25 14:17:52.576362: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-25 14:17:52.585994: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n",
      "True\n",
      "4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1000000,256,device = device)\n",
    "y = x.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5838, 0.7997, 0.4081, 0.3213, 0.0968],\n",
      "        [0.8383, 0.9666, 0.5852, 0.0980, 0.1693],\n",
      "        [0.6443, 0.5052, 0.1315, 0.9768, 0.2860],\n",
      "        [0.2568, 0.7425, 0.5485, 0.7974, 0.6843],\n",
      "        [0.8687, 0.0254, 0.8877, 0.0741, 0.0439]], device='cuda:0')\n",
      "tensor([[0.5838, 0.7997, 0.4081, 0.3213, 0.0968],\n",
      "        [0.8383, 0.9666, 0.5852, 0.0980, 0.1693],\n",
      "        [0.6443, 0.5052, 0.1315, 0.9768, 0.2860],\n",
      "        [0.2568, 0.7425, 0.5485, 0.7974, 0.6843],\n",
      "        [0.8687, 0.0254, 0.8877, 0.0741, 0.0439]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(x[0:5,0:5])\n",
    "print(y.to(\"cpu\", torch.double)[0:5,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='974848' class='' max='968212' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.69% [974848/968212 00:01&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.tabular.all import *\n",
    "path = untar_data(URLs.ADULT_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sieglew/.local/lib/python3.9/site-packages/fastai/tabular/core.py:314: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  to[n].fillna(self.na_dict[n], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n",
    "    cat_names = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "    'relationship', 'race'],\n",
    "    cont_names = ['age', 'fnlwgt', 'education-num'],\n",
    "    procs = [Categorify, FillMissing, Normalize])\n",
    "\n",
    "learn = tabular_learner(dls, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.345538</td>\n",
       "      <td>0.357411</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.359135</td>\n",
       "      <td>0.362926</td>\n",
       "      <td>0.829085</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.355792</td>\n",
       "      <td>0.359608</td>\n",
       "      <td>0.826628</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.354025</td>\n",
       "      <td>0.357982</td>\n",
       "      <td>0.830467</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.349482</td>\n",
       "      <td>0.368184</td>\n",
       "      <td>0.823249</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.343748</td>\n",
       "      <td>0.359266</td>\n",
       "      <td>0.828778</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.348321</td>\n",
       "      <td>0.362397</td>\n",
       "      <td>0.822789</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.354008</td>\n",
       "      <td>0.358884</td>\n",
       "      <td>0.827856</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.343268</td>\n",
       "      <td>0.354776</td>\n",
       "      <td>0.829392</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.341514</td>\n",
       "      <td>0.353782</td>\n",
       "      <td>0.830006</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.331862</td>\n",
       "      <td>0.352696</td>\n",
       "      <td>0.832156</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.338169</td>\n",
       "      <td>0.353190</td>\n",
       "      <td>0.830774</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>education-num_na</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.142122</td>\n",
       "      <td>-0.266584</td>\n",
       "      <td>-0.024048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.142122</td>\n",
       "      <td>0.567496</td>\n",
       "      <td>-0.024048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.434863</td>\n",
       "      <td>-0.618067</td>\n",
       "      <td>-0.804646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.199807</td>\n",
       "      <td>-1.131741</td>\n",
       "      <td>1.537147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102028</td>\n",
       "      <td>0.382803</td>\n",
       "      <td>0.756550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.541140</td>\n",
       "      <td>-0.163912</td>\n",
       "      <td>1.146848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833881</td>\n",
       "      <td>-1.487889</td>\n",
       "      <td>-0.414347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.410269</td>\n",
       "      <td>-0.727973</td>\n",
       "      <td>-0.414347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.760695</td>\n",
       "      <td>-1.048918</td>\n",
       "      <td>1.537147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): return x**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = tensor(3.).requires_grad_()\n",
    "f(xt).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15., 16., 17., 18., 19.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0,20).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_soft_device_placement(True)\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(1,1000,1000)**2\n",
    "y = x.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 4, 5),\n",
       " (5, 12, 13),\n",
       " (6, 8, 10),\n",
       " (7, 24, 25),\n",
       " (8, 15, 17),\n",
       " (9, 12, 15),\n",
       " (9, 40, 41),\n",
       " (10, 24, 26),\n",
       " (11, 60, 61),\n",
       " (12, 16, 20),\n",
       " (12, 35, 37),\n",
       " (13, 84, 85),\n",
       " (14, 48, 50),\n",
       " (15, 20, 25),\n",
       " (15, 36, 39),\n",
       " (15, 112, 113),\n",
       " (16, 30, 34),\n",
       " (16, 63, 65),\n",
       " (17, 144, 145),\n",
       " (18, 24, 30),\n",
       " (18, 80, 82),\n",
       " (19, 180, 181),\n",
       " (20, 21, 29),\n",
       " (20, 48, 52),\n",
       " (20, 99, 101),\n",
       " (21, 28, 35),\n",
       " (21, 72, 75),\n",
       " (21, 220, 221),\n",
       " (22, 120, 122),\n",
       " (23, 264, 265),\n",
       " (24, 32, 40),\n",
       " (24, 45, 51),\n",
       " (24, 70, 74),\n",
       " (24, 143, 145),\n",
       " (25, 60, 65),\n",
       " (25, 312, 313),\n",
       " (26, 168, 170),\n",
       " (27, 36, 45),\n",
       " (27, 120, 123),\n",
       " (27, 364, 365),\n",
       " (28, 45, 53),\n",
       " (28, 96, 100),\n",
       " (28, 195, 197),\n",
       " (29, 420, 421),\n",
       " (30, 40, 50),\n",
       " (30, 72, 78),\n",
       " (30, 224, 226),\n",
       " (31, 480, 481),\n",
       " (32, 60, 68),\n",
       " (32, 126, 130),\n",
       " (32, 255, 257),\n",
       " (33, 44, 55),\n",
       " (33, 56, 65),\n",
       " (33, 180, 183),\n",
       " (33, 544, 545),\n",
       " (34, 288, 290),\n",
       " (35, 84, 91),\n",
       " (35, 120, 125),\n",
       " (35, 612, 613),\n",
       " (36, 48, 60),\n",
       " (36, 77, 85),\n",
       " (36, 105, 111),\n",
       " (36, 160, 164),\n",
       " (36, 323, 325),\n",
       " (37, 684, 685),\n",
       " (38, 360, 362),\n",
       " (39, 52, 65),\n",
       " (39, 80, 89),\n",
       " (39, 252, 255),\n",
       " (39, 760, 761),\n",
       " (40, 42, 58),\n",
       " (40, 75, 85),\n",
       " (40, 96, 104),\n",
       " (40, 198, 202),\n",
       " (40, 399, 401),\n",
       " (41, 840, 841),\n",
       " (42, 56, 70),\n",
       " (42, 144, 150),\n",
       " (42, 440, 442),\n",
       " (43, 924, 925),\n",
       " (44, 117, 125),\n",
       " (44, 240, 244),\n",
       " (44, 483, 485),\n",
       " (45, 60, 75),\n",
       " (45, 108, 117),\n",
       " (45, 200, 205),\n",
       " (45, 336, 339),\n",
       " (46, 528, 530),\n",
       " (48, 55, 73),\n",
       " (48, 64, 80),\n",
       " (48, 90, 102),\n",
       " (48, 140, 148),\n",
       " (48, 189, 195),\n",
       " (48, 286, 290),\n",
       " (48, 575, 577),\n",
       " (49, 168, 175),\n",
       " (50, 120, 130),\n",
       " (50, 624, 626),\n",
       " (51, 68, 85),\n",
       " (51, 140, 149),\n",
       " (51, 432, 435),\n",
       " (52, 165, 173),\n",
       " (52, 336, 340),\n",
       " (52, 675, 677),\n",
       " (54, 72, 90),\n",
       " (54, 240, 246),\n",
       " (54, 728, 730),\n",
       " (55, 132, 143),\n",
       " (55, 300, 305),\n",
       " (56, 90, 106),\n",
       " (56, 105, 119),\n",
       " (56, 192, 200),\n",
       " (56, 390, 394),\n",
       " (56, 783, 785),\n",
       " (57, 76, 95),\n",
       " (57, 176, 185),\n",
       " (57, 540, 543),\n",
       " (58, 840, 842),\n",
       " (60, 63, 87),\n",
       " (60, 80, 100),\n",
       " (60, 91, 109),\n",
       " (60, 144, 156),\n",
       " (60, 175, 185),\n",
       " (60, 221, 229),\n",
       " (60, 297, 303),\n",
       " (60, 448, 452),\n",
       " (60, 899, 901),\n",
       " (62, 960, 962),\n",
       " (63, 84, 105),\n",
       " (63, 216, 225),\n",
       " (63, 280, 287),\n",
       " (63, 660, 663),\n",
       " (64, 120, 136),\n",
       " (64, 252, 260),\n",
       " (64, 510, 514),\n",
       " (65, 72, 97),\n",
       " (65, 156, 169),\n",
       " (65, 420, 425),\n",
       " (66, 88, 110),\n",
       " (66, 112, 130),\n",
       " (66, 360, 366),\n",
       " (68, 285, 293),\n",
       " (68, 576, 580),\n",
       " (69, 92, 115),\n",
       " (69, 260, 269),\n",
       " (69, 792, 795),\n",
       " (70, 168, 182),\n",
       " (70, 240, 250),\n",
       " (72, 96, 120),\n",
       " (72, 135, 153),\n",
       " (72, 154, 170),\n",
       " (72, 210, 222),\n",
       " (72, 320, 328),\n",
       " (72, 429, 435),\n",
       " (72, 646, 650),\n",
       " (75, 100, 125),\n",
       " (75, 180, 195),\n",
       " (75, 308, 317),\n",
       " (75, 560, 565),\n",
       " (75, 936, 939),\n",
       " (76, 357, 365),\n",
       " (76, 720, 724),\n",
       " (77, 264, 275),\n",
       " (77, 420, 427),\n",
       " (78, 104, 130),\n",
       " (78, 160, 178),\n",
       " (78, 504, 510),\n",
       " (80, 84, 116),\n",
       " (80, 150, 170),\n",
       " (80, 192, 208),\n",
       " (80, 315, 325),\n",
       " (80, 396, 404),\n",
       " (80, 798, 802),\n",
       " (81, 108, 135),\n",
       " (81, 360, 369),\n",
       " (84, 112, 140),\n",
       " (84, 135, 159),\n",
       " (84, 187, 205),\n",
       " (84, 245, 259),\n",
       " (84, 288, 300),\n",
       " (84, 437, 445),\n",
       " (84, 585, 591),\n",
       " (84, 880, 884),\n",
       " (85, 132, 157),\n",
       " (85, 204, 221),\n",
       " (85, 720, 725),\n",
       " (87, 116, 145),\n",
       " (87, 416, 425),\n",
       " (88, 105, 137),\n",
       " (88, 165, 187),\n",
       " (88, 234, 250),\n",
       " (88, 480, 488),\n",
       " (88, 966, 970),\n",
       " (90, 120, 150),\n",
       " (90, 216, 234),\n",
       " (90, 400, 410),\n",
       " (90, 672, 678),\n",
       " (91, 312, 325),\n",
       " (91, 588, 595),\n",
       " (92, 525, 533),\n",
       " (93, 124, 155),\n",
       " (93, 476, 485),\n",
       " (95, 168, 193),\n",
       " (95, 228, 247),\n",
       " (95, 900, 905),\n",
       " (96, 110, 146),\n",
       " (96, 128, 160),\n",
       " (96, 180, 204),\n",
       " (96, 247, 265),\n",
       " (96, 280, 296),\n",
       " (96, 378, 390),\n",
       " (96, 572, 580),\n",
       " (96, 765, 771),\n",
       " (98, 336, 350),\n",
       " (99, 132, 165),\n",
       " (99, 168, 195),\n",
       " (99, 440, 451),\n",
       " (99, 540, 549),\n",
       " (100, 105, 145),\n",
       " (100, 240, 260),\n",
       " (100, 495, 505),\n",
       " (100, 621, 629),\n",
       " (102, 136, 170),\n",
       " (102, 280, 298),\n",
       " (102, 864, 870),\n",
       " (104, 153, 185),\n",
       " (104, 195, 221),\n",
       " (104, 330, 346),\n",
       " (104, 672, 680),\n",
       " (105, 140, 175),\n",
       " (105, 208, 233),\n",
       " (105, 252, 273),\n",
       " (105, 360, 375),\n",
       " (105, 608, 617),\n",
       " (105, 784, 791),\n",
       " (108, 144, 180),\n",
       " (108, 231, 255),\n",
       " (108, 315, 333),\n",
       " (108, 480, 492),\n",
       " (108, 725, 733),\n",
       " (108, 969, 975),\n",
       " (110, 264, 286),\n",
       " (110, 600, 610),\n",
       " (111, 148, 185),\n",
       " (111, 680, 689),\n",
       " (112, 180, 212),\n",
       " (112, 210, 238),\n",
       " (112, 384, 400),\n",
       " (112, 441, 455),\n",
       " (112, 780, 788),\n",
       " (114, 152, 190),\n",
       " (114, 352, 370),\n",
       " (115, 252, 277),\n",
       " (115, 276, 299),\n",
       " (116, 837, 845),\n",
       " (117, 156, 195),\n",
       " (117, 240, 267),\n",
       " (117, 520, 533),\n",
       " (117, 756, 765),\n",
       " (119, 120, 169),\n",
       " (119, 408, 425),\n",
       " (120, 126, 174),\n",
       " (120, 160, 200),\n",
       " (120, 182, 218),\n",
       " (120, 209, 241),\n",
       " (120, 225, 255),\n",
       " (120, 288, 312),\n",
       " (120, 350, 370),\n",
       " (120, 391, 409),\n",
       " (120, 442, 458),\n",
       " (120, 594, 606),\n",
       " (120, 715, 725),\n",
       " (120, 896, 904),\n",
       " (121, 660, 671),\n",
       " (123, 164, 205),\n",
       " (123, 836, 845),\n",
       " (124, 957, 965),\n",
       " (125, 300, 325),\n",
       " (126, 168, 210),\n",
       " (126, 432, 450),\n",
       " (126, 560, 574),\n",
       " (128, 240, 272),\n",
       " (128, 504, 520),\n",
       " (129, 172, 215),\n",
       " (129, 920, 929),\n",
       " (130, 144, 194),\n",
       " (130, 312, 338),\n",
       " (130, 840, 850),\n",
       " (132, 176, 220),\n",
       " (132, 224, 260),\n",
       " (132, 351, 375),\n",
       " (132, 385, 407),\n",
       " (132, 475, 493),\n",
       " (132, 720, 732),\n",
       " (133, 156, 205),\n",
       " (133, 456, 475),\n",
       " (135, 180, 225),\n",
       " (135, 324, 351),\n",
       " (135, 352, 377),\n",
       " (135, 600, 615),\n",
       " (136, 255, 289),\n",
       " (136, 273, 305),\n",
       " (136, 570, 586),\n",
       " (138, 184, 230),\n",
       " (138, 520, 538),\n",
       " (140, 147, 203),\n",
       " (140, 171, 221),\n",
       " (140, 225, 265),\n",
       " (140, 336, 364),\n",
       " (140, 480, 500),\n",
       " (140, 693, 707),\n",
       " (140, 975, 985),\n",
       " (141, 188, 235),\n",
       " (143, 780, 793),\n",
       " (143, 924, 935),\n",
       " (144, 165, 219),\n",
       " (144, 192, 240),\n",
       " (144, 270, 306),\n",
       " (144, 308, 340),\n",
       " (144, 420, 444),\n",
       " (144, 567, 585),\n",
       " (144, 640, 656),\n",
       " (144, 858, 870),\n",
       " (145, 348, 377),\n",
       " (145, 408, 433),\n",
       " (147, 196, 245),\n",
       " (147, 504, 525),\n",
       " (150, 200, 250),\n",
       " (150, 360, 390),\n",
       " (150, 616, 634),\n",
       " (152, 285, 323),\n",
       " (152, 345, 377),\n",
       " (152, 714, 730),\n",
       " (153, 204, 255),\n",
       " (153, 420, 447),\n",
       " (153, 680, 697),\n",
       " (154, 528, 550),\n",
       " (154, 840, 854),\n",
       " (155, 372, 403),\n",
       " (155, 468, 493),\n",
       " (156, 208, 260),\n",
       " (156, 320, 356),\n",
       " (156, 455, 481),\n",
       " (156, 495, 519),\n",
       " (156, 667, 685),\n",
       " (159, 212, 265),\n",
       " (160, 168, 232),\n",
       " (160, 231, 281),\n",
       " (160, 300, 340),\n",
       " (160, 384, 416),\n",
       " (160, 630, 650),\n",
       " (160, 792, 808),\n",
       " (161, 240, 289),\n",
       " (161, 552, 575),\n",
       " (162, 216, 270),\n",
       " (162, 720, 738),\n",
       " (165, 220, 275),\n",
       " (165, 280, 325),\n",
       " (165, 396, 429),\n",
       " (165, 532, 557),\n",
       " (165, 900, 915),\n",
       " (168, 224, 280),\n",
       " (168, 270, 318),\n",
       " (168, 315, 357),\n",
       " (168, 374, 410),\n",
       " (168, 425, 457),\n",
       " (168, 490, 518),\n",
       " (168, 576, 600),\n",
       " (168, 775, 793),\n",
       " (168, 874, 890),\n",
       " (170, 264, 314),\n",
       " (170, 408, 442),\n",
       " (171, 228, 285),\n",
       " (171, 528, 555),\n",
       " (171, 760, 779),\n",
       " (174, 232, 290),\n",
       " (174, 832, 850),\n",
       " (175, 288, 337),\n",
       " (175, 420, 455),\n",
       " (175, 600, 625),\n",
       " (176, 210, 274),\n",
       " (176, 330, 374),\n",
       " (176, 468, 500),\n",
       " (176, 693, 715),\n",
       " (176, 960, 976),\n",
       " (177, 236, 295),\n",
       " (180, 189, 261),\n",
       " (180, 240, 300),\n",
       " (180, 273, 327),\n",
       " (180, 299, 349),\n",
       " (180, 385, 425),\n",
       " (180, 432, 468),\n",
       " (180, 525, 555),\n",
       " (180, 663, 687),\n",
       " (180, 800, 820),\n",
       " (180, 891, 909),\n",
       " (182, 624, 650),\n",
       " (183, 244, 305),\n",
       " (184, 345, 391),\n",
       " (184, 513, 545),\n",
       " (185, 444, 481),\n",
       " (185, 672, 697),\n",
       " (186, 248, 310),\n",
       " (186, 952, 970),\n",
       " (189, 252, 315),\n",
       " (189, 340, 389),\n",
       " (189, 648, 675),\n",
       " (189, 840, 861),\n",
       " (190, 336, 386),\n",
       " (190, 456, 494),\n",
       " (192, 220, 292),\n",
       " (192, 256, 320),\n",
       " (192, 360, 408),\n",
       " (192, 494, 530),\n",
       " (192, 560, 592),\n",
       " (192, 756, 780),\n",
       " (195, 216, 291),\n",
       " (195, 260, 325),\n",
       " (195, 400, 445),\n",
       " (195, 468, 507),\n",
       " (195, 748, 773),\n",
       " (196, 315, 371),\n",
       " (196, 672, 700),\n",
       " (198, 264, 330),\n",
       " (198, 336, 390),\n",
       " (198, 880, 902),\n",
       " (200, 210, 290),\n",
       " (200, 375, 425),\n",
       " (200, 480, 520),\n",
       " (200, 609, 641),\n",
       " (201, 268, 335),\n",
       " (203, 396, 445),\n",
       " (203, 696, 725),\n",
       " (204, 253, 325),\n",
       " (204, 272, 340),\n",
       " (204, 560, 596),\n",
       " (204, 595, 629),\n",
       " (204, 855, 879),\n",
       " (205, 492, 533),\n",
       " (205, 828, 853),\n",
       " (207, 224, 305),\n",
       " (207, 276, 345),\n",
       " (207, 780, 807),\n",
       " (207, 920, 943),\n",
       " (208, 306, 370),\n",
       " (208, 390, 442),\n",
       " (208, 660, 692),\n",
       " (208, 819, 845),\n",
       " (210, 280, 350),\n",
       " (210, 416, 466),\n",
       " (210, 504, 546),\n",
       " (210, 720, 750),\n",
       " (213, 284, 355),\n",
       " (215, 516, 559),\n",
       " (215, 912, 937),\n",
       " (216, 288, 360),\n",
       " (216, 405, 459),\n",
       " (216, 462, 510),\n",
       " (216, 630, 666),\n",
       " (216, 713, 745),\n",
       " (216, 960, 984),\n",
       " (217, 456, 505),\n",
       " (217, 744, 775),\n",
       " (219, 292, 365),\n",
       " (220, 231, 319),\n",
       " (220, 459, 509),\n",
       " (220, 528, 572),\n",
       " (220, 585, 625),\n",
       " (222, 296, 370),\n",
       " (224, 360, 424),\n",
       " (224, 420, 476),\n",
       " (224, 768, 800),\n",
       " (224, 882, 910),\n",
       " (225, 272, 353),\n",
       " (225, 300, 375),\n",
       " (225, 540, 585),\n",
       " (225, 924, 951),\n",
       " (228, 304, 380),\n",
       " (228, 325, 397),\n",
       " (228, 665, 703),\n",
       " (228, 704, 740),\n",
       " (230, 504, 554),\n",
       " (230, 552, 598),\n",
       " (231, 308, 385),\n",
       " (231, 392, 455),\n",
       " (231, 520, 569),\n",
       " (231, 792, 825),\n",
       " (232, 435, 493),\n",
       " (232, 825, 857),\n",
       " (234, 312, 390),\n",
       " (234, 480, 534),\n",
       " (235, 564, 611),\n",
       " (237, 316, 395),\n",
       " (238, 240, 338),\n",
       " (238, 816, 850),\n",
       " (240, 252, 348),\n",
       " (240, 275, 365),\n",
       " (240, 320, 400),\n",
       " (240, 364, 436),\n",
       " (240, 418, 482),\n",
       " (240, 450, 510),\n",
       " (240, 551, 601),\n",
       " (240, 576, 624),\n",
       " (240, 700, 740),\n",
       " (240, 782, 818),\n",
       " (240, 884, 916),\n",
       " (240, 945, 975),\n",
       " (243, 324, 405),\n",
       " (245, 588, 637),\n",
       " (245, 840, 875),\n",
       " (246, 328, 410),\n",
       " (248, 465, 527),\n",
       " (248, 945, 977),\n",
       " (249, 332, 415),\n",
       " (250, 600, 650),\n",
       " (252, 275, 373),\n",
       " (252, 336, 420),\n",
       " (252, 405, 477),\n",
       " (252, 539, 595),\n",
       " (252, 561, 615),\n",
       " (252, 735, 777),\n",
       " (252, 864, 900),\n",
       " (255, 340, 425),\n",
       " (255, 396, 471),\n",
       " (255, 612, 663),\n",
       " (255, 700, 745),\n",
       " (256, 480, 544),\n",
       " (258, 344, 430),\n",
       " (259, 660, 709),\n",
       " (259, 888, 925),\n",
       " (260, 273, 377),\n",
       " (260, 288, 388),\n",
       " (260, 624, 676),\n",
       " (260, 651, 701),\n",
       " (260, 825, 865),\n",
       " (261, 348, 435),\n",
       " (261, 380, 461),\n",
       " (264, 315, 411),\n",
       " (264, 352, 440),\n",
       " (264, 448, 520),\n",
       " (264, 495, 561),\n",
       " (264, 702, 750),\n",
       " (264, 770, 814),\n",
       " (264, 950, 986),\n",
       " (265, 636, 689),\n",
       " (266, 312, 410),\n",
       " (266, 912, 950),\n",
       " (267, 356, 445),\n",
       " (270, 360, 450),\n",
       " (270, 648, 702),\n",
       " (270, 704, 754),\n",
       " (272, 510, 578),\n",
       " (272, 546, 610),\n",
       " (273, 364, 455),\n",
       " (273, 560, 623),\n",
       " (273, 736, 785),\n",
       " (273, 936, 975),\n",
       " (275, 660, 715),\n",
       " (276, 368, 460),\n",
       " (276, 493, 565),\n",
       " (276, 805, 851),\n",
       " (279, 372, 465),\n",
       " (279, 440, 521),\n",
       " (280, 294, 406),\n",
       " (280, 342, 442),\n",
       " (280, 351, 449),\n",
       " (280, 450, 530),\n",
       " (280, 525, 595),\n",
       " (280, 672, 728),\n",
       " (280, 759, 809),\n",
       " (282, 376, 470),\n",
       " (285, 380, 475),\n",
       " (285, 504, 579),\n",
       " (285, 684, 741),\n",
       " (285, 880, 925),\n",
       " (287, 816, 865),\n",
       " (288, 330, 438),\n",
       " (288, 384, 480),\n",
       " (288, 540, 612),\n",
       " (288, 616, 680),\n",
       " (288, 741, 795),\n",
       " (288, 840, 888),\n",
       " (290, 696, 754),\n",
       " (290, 816, 866),\n",
       " (291, 388, 485),\n",
       " (294, 392, 490),\n",
       " (295, 708, 767),\n",
       " (296, 555, 629),\n",
       " (297, 304, 425),\n",
       " (297, 396, 495),\n",
       " (297, 504, 585),\n",
       " (300, 315, 435),\n",
       " (300, 400, 500),\n",
       " (300, 455, 545),\n",
       " (300, 589, 661),\n",
       " (300, 720, 780),\n",
       " (300, 875, 925),\n",
       " (301, 900, 949),\n",
       " (303, 404, 505),\n",
       " (304, 570, 646),\n",
       " (304, 690, 754),\n",
       " (305, 732, 793),\n",
       " (306, 408, 510),\n",
       " (306, 840, 894),\n",
       " (308, 435, 533),\n",
       " (308, 495, 583),\n",
       " (308, 819, 875),\n",
       " (309, 412, 515),\n",
       " (310, 744, 806),\n",
       " (310, 936, 986),\n",
       " (312, 416, 520),\n",
       " (312, 459, 555),\n",
       " (312, 585, 663),\n",
       " (312, 640, 712),\n",
       " (312, 910, 962),\n",
       " (315, 420, 525),\n",
       " (315, 572, 653),\n",
       " (315, 624, 699),\n",
       " (315, 756, 819),\n",
       " (318, 424, 530),\n",
       " (319, 360, 481),\n",
       " (320, 336, 464),\n",
       " (320, 462, 562),\n",
       " (320, 600, 680),\n",
       " (320, 768, 832),\n",
       " (321, 428, 535),\n",
       " (322, 480, 578),\n",
       " (324, 432, 540),\n",
       " (324, 693, 765),\n",
       " (324, 945, 999),\n",
       " (325, 360, 485),\n",
       " (325, 780, 845),\n",
       " (327, 436, 545),\n",
       " (328, 615, 697),\n",
       " (330, 440, 550),\n",
       " (330, 560, 650),\n",
       " (330, 792, 858),\n",
       " (333, 444, 555),\n",
       " (333, 644, 725),\n",
       " (335, 804, 871),\n",
       " (336, 377, 505),\n",
       " (336, 385, 511),\n",
       " (336, 448, 560),\n",
       " (336, 527, 625),\n",
       " (336, 540, 636),\n",
       " (336, 630, 714),\n",
       " (336, 748, 820),\n",
       " (336, 850, 914),\n",
       " (339, 452, 565),\n",
       " (340, 357, 493),\n",
       " (340, 528, 628),\n",
       " (340, 816, 884),\n",
       " (341, 420, 541),\n",
       " (342, 456, 570),\n",
       " (344, 645, 731),\n",
       " (345, 460, 575),\n",
       " (345, 756, 831),\n",
       " (345, 828, 897),\n",
       " (348, 464, 580),\n",
       " (348, 805, 877),\n",
       " (350, 576, 674),\n",
       " (350, 840, 910),\n",
       " (351, 468, 585),\n",
       " (351, 720, 801),\n",
       " (352, 420, 548),\n",
       " (352, 660, 748),\n",
       " (354, 472, 590),\n",
       " (355, 852, 923),\n",
       " (357, 360, 507),\n",
       " (357, 476, 595),\n",
       " (360, 378, 522),\n",
       " (360, 480, 600),\n",
       " (360, 546, 654),\n",
       " (360, 598, 698),\n",
       " (360, 627, 723),\n",
       " (360, 675, 765),\n",
       " (360, 770, 850),\n",
       " (360, 864, 936),\n",
       " (363, 484, 605),\n",
       " (363, 616, 715),\n",
       " (364, 585, 689),\n",
       " (364, 627, 725),\n",
       " (365, 876, 949),\n",
       " (366, 488, 610),\n",
       " (368, 465, 593),\n",
       " (368, 690, 782),\n",
       " (369, 492, 615),\n",
       " (369, 800, 881),\n",
       " (370, 888, 962),\n",
       " (372, 496, 620),\n",
       " (372, 925, 997),\n",
       " (375, 500, 625),\n",
       " (375, 900, 975),\n",
       " (376, 705, 799),\n",
       " (378, 504, 630),\n",
       " (378, 680, 778),\n",
       " (380, 399, 551),\n",
       " (380, 672, 772),\n",
       " (380, 912, 988),\n",
       " (381, 508, 635),\n",
       " (384, 440, 584),\n",
       " (384, 512, 640),\n",
       " (384, 720, 816),\n",
       " (385, 552, 673),\n",
       " (387, 516, 645),\n",
       " (387, 884, 965),\n",
       " (390, 432, 582),\n",
       " (390, 520, 650),\n",
       " (390, 800, 890),\n",
       " (392, 630, 742),\n",
       " (392, 735, 833),\n",
       " (393, 524, 655),\n",
       " (396, 403, 565),\n",
       " (396, 528, 660),\n",
       " (396, 672, 780),\n",
       " (396, 847, 935),\n",
       " (399, 468, 615),\n",
       " (399, 532, 665),\n",
       " (400, 420, 580),\n",
       " (400, 561, 689),\n",
       " (400, 750, 850),\n",
       " (402, 536, 670),\n",
       " (405, 540, 675),\n",
       " (406, 792, 890),\n",
       " (407, 624, 745),\n",
       " (408, 506, 650),\n",
       " (408, 544, 680),\n",
       " (408, 765, 867),\n",
       " (408, 819, 915),\n",
       " (411, 548, 685),\n",
       " (414, 448, 610),\n",
       " (414, 552, 690),\n",
       " (416, 612, 740),\n",
       " (416, 780, 884),\n",
       " (417, 556, 695),\n",
       " (420, 441, 609),\n",
       " (420, 513, 663),\n",
       " (420, 560, 700),\n",
       " (420, 637, 763),\n",
       " (420, 675, 795),\n",
       " (420, 832, 932),\n",
       " (420, 851, 949),\n",
       " (423, 564, 705),\n",
       " (424, 795, 901),\n",
       " (425, 660, 785),\n",
       " (426, 568, 710),\n",
       " (429, 460, 629),\n",
       " (429, 572, 715),\n",
       " (429, 700, 821),\n",
       " (429, 728, 845),\n",
       " (429, 880, 979),\n",
       " (432, 495, 657),\n",
       " (432, 576, 720),\n",
       " (432, 665, 793),\n",
       " (432, 810, 918),\n",
       " (435, 580, 725),\n",
       " (438, 584, 730),\n",
       " (440, 462, 638),\n",
       " (440, 525, 685),\n",
       " (440, 825, 935),\n",
       " (441, 588, 735),\n",
       " (444, 592, 740),\n",
       " (447, 596, 745),\n",
       " (448, 720, 848),\n",
       " (448, 840, 952),\n",
       " (450, 544, 706),\n",
       " (450, 600, 750),\n",
       " (451, 780, 901),\n",
       " (453, 604, 755),\n",
       " (455, 504, 679),\n",
       " (455, 528, 697),\n",
       " (456, 608, 760),\n",
       " (456, 650, 794),\n",
       " (456, 855, 969),\n",
       " (459, 612, 765),\n",
       " (460, 483, 667),\n",
       " (462, 616, 770),\n",
       " (462, 784, 910),\n",
       " (464, 777, 905),\n",
       " (464, 870, 986),\n",
       " (465, 620, 775),\n",
       " (468, 595, 757),\n",
       " (468, 624, 780),\n",
       " (471, 628, 785),\n",
       " (473, 864, 985),\n",
       " (474, 632, 790),\n",
       " (475, 840, 965),\n",
       " (476, 480, 676),\n",
       " (476, 765, 901),\n",
       " (477, 636, 795),\n",
       " (480, 504, 696),\n",
       " (480, 550, 730),\n",
       " (480, 640, 800),\n",
       " (480, 693, 843),\n",
       " (480, 728, 872),\n",
       " (480, 836, 964),\n",
       " (481, 600, 769),\n",
       " (483, 644, 805),\n",
       " (483, 720, 867),\n",
       " (486, 648, 810),\n",
       " (489, 652, 815),\n",
       " (492, 656, 820),\n",
       " (495, 660, 825),\n",
       " (495, 840, 975),\n",
       " (498, 664, 830),\n",
       " (500, 525, 725),\n",
       " (501, 668, 835),\n",
       " (504, 550, 746),\n",
       " (504, 672, 840),\n",
       " (504, 703, 865),\n",
       " (504, 810, 954),\n",
       " (507, 676, 845),\n",
       " (510, 680, 850),\n",
       " (510, 792, 942),\n",
       " (513, 684, 855),\n",
       " (516, 688, 860),\n",
       " (519, 692, 865),\n",
       " (520, 546, 754),\n",
       " (520, 576, 776),\n",
       " (520, 765, 925),\n",
       " (522, 696, 870),\n",
       " (522, 760, 922),\n",
       " (525, 700, 875),\n",
       " (528, 605, 803),\n",
       " (528, 630, 822),\n",
       " (528, 704, 880),\n",
       " (531, 708, 885),\n",
       " (532, 624, 820),\n",
       " (533, 756, 925),\n",
       " (534, 712, 890),\n",
       " (537, 716, 895),\n",
       " (540, 567, 783),\n",
       " (540, 629, 829),\n",
       " (540, 720, 900),\n",
       " (540, 819, 981),\n",
       " (543, 724, 905),\n",
       " (546, 728, 910),\n",
       " (549, 732, 915),\n",
       " (552, 736, 920),\n",
       " (555, 572, 797),\n",
       " (555, 740, 925),\n",
       " (558, 744, 930),\n",
       " (560, 588, 812),\n",
       " (560, 684, 884),\n",
       " (560, 702, 898),\n",
       " (561, 748, 935),\n",
       " (564, 752, 940),\n",
       " (567, 756, 945),\n",
       " (570, 760, 950),\n",
       " (573, 764, 955),\n",
       " (576, 660, 876),\n",
       " (576, 768, 960),\n",
       " (579, 772, 965),\n",
       " (580, 609, 841),\n",
       " (580, 741, 941),\n",
       " (582, 776, 970),\n",
       " (585, 648, 873),\n",
       " (585, 780, 975),\n",
       " (588, 784, 980),\n",
       " (591, 788, 985),\n",
       " (594, 608, 850),\n",
       " (594, 792, 990),\n",
       " (595, 600, 845),\n",
       " (597, 796, 995),\n",
       " (600, 630, 870),\n",
       " (612, 759, 975),\n",
       " (615, 728, 953),\n",
       " (616, 663, 905),\n",
       " (616, 735, 959),\n",
       " (620, 651, 899),\n",
       " (621, 672, 915),\n",
       " (624, 715, 949),\n",
       " (638, 720, 962),\n",
       " (640, 672, 928),\n",
       " (650, 720, 970),\n",
       " (660, 693, 957),\n",
       " (680, 714, 986),\n",
       " (696, 697, 985)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[(x,y,z) for x in range(1,1000) for y in range(x,1000) for z in range(y,1000) if x**2 + y**2 == z**2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# or select device manually\n",
    "#device = torch.device(\"cuda:0\")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quad_triples_1(dim):\n",
    "    v = np.linspace(1,dim,dim)**2\n",
    "    T = torch.from_numpy(np.array(np.transpose([v]*dim) + [v]*dim))\n",
    "    idx = torch.unique(torch.sort(torch.where(torch.isin(T, torch.from_numpy(v)), T, torch.tensor([0])).nonzero() + torch.tensor([1]))[0], dim = 0)\n",
    "    L1 = idx[:,0]**2\n",
    "    L2 = idx[:,1]**2\n",
    "\n",
    "    return list(map(tuple, np.transpose(torch.sqrt(torch.stack((L1, L2, L1+L2))).int().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 10000\n",
    "triples = quad_triples_1(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12471\n"
     ]
    }
   ],
   "source": [
    "print(len(triples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
