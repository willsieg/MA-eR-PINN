{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Parquet Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>\n",
    "Version 1.3<br>\n",
    "Created: 09.09.2024  <br>\n",
    "William Siegle, Daimler Truck AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.stats import zscore, median_abs_deviation\n",
    "import pyarrow.parquet as pq \n",
    "\n",
    "from IPython.core.magic import register_cell_magic\n",
    "@register_cell_magic\n",
    "def skip(line, cell):   # cells can be skipped by using '%%skip' in the first line\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "C:\\Users\\SIEGLEW\\OneDrive - Daimler Truck\\MA\\Code\\MA-Data:\tprocessed, trips_processed_final, trips_processed_pickles, trips_processed_resampled, y_true\n",
      "C:\\Users\\SIEGLEW\\OneDrive - Daimler Truck\\MA\\Code\\MA-eR-PINN:\t.git, archive, data, project, ref, src, test\n"
     ]
    }
   ],
   "source": [
    "# ------------ LOCATE REPOSITORY/DATASTORAGE IN CURRENT SYSTEM ENVIRONMENT  --------------\n",
    "import sys, os; from pathlib import Path                                                #|\n",
    "global ROOT, DATA_PATH, IS_NOTEBOOK; IS_NOTEBOOK = True                                 #|\n",
    "ROOT = Path('..').resolve() if IS_NOTEBOOK else Path('.').resolve()                      #|\n",
    "sys.path.append(os.path.abspath(ROOT))                                                  #|\n",
    "from data import get_data_path  # paths set in \"data/__init__.py\"                       #|\n",
    "DATA_PATH = get_data_path()                                                             #|\n",
    "print(f\"{'-'*60}\\n{DATA_PATH}:\\t{', '.join([_.name for _ in DATA_PATH.glob('*/')])}\") #|\n",
    "print(f\"{ROOT}:\\t{', '.join([_.name for _ in ROOT.glob('*/')])}\")   \t                #|\n",
    "# ----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trip_data_info(relative_path):\n",
    "\n",
    "    from os import listdir, getcwd\n",
    "    from os.path import isfile, join, exists\n",
    "\n",
    "    # data base directory path:\n",
    "    data_dir = relative_path\n",
    "    cwd = getcwd()\n",
    "\n",
    "    if exists(join(cwd,data_dir)):\n",
    "        data_path = join(cwd,data_dir)\n",
    "    else:\n",
    "        print(\"Directory '\",data_dir,\"' not found!\")\n",
    "        print(\"Files and directories in '\", cwd, \"' :\") \n",
    "        print(listdir(cwd))\n",
    "        quit()\n",
    "\n",
    "    # create list of all parquet files:\n",
    "    files_list = [f for f in listdir(data_path) if (isfile(join(data_path, f)) and f.endswith(\".parquet\"))]\n",
    "\n",
    "    id_num_list,V_list = ([],[])\n",
    "    trips  = {}\n",
    "\n",
    "    for f in files_list:\n",
    "        f = f.strip(\"v_.parquet\")\n",
    "        x = f.split(\"_\",1)\n",
    "\n",
    "        id = x[0].split(\"V\")[0].strip(\"id\")\n",
    "        id_num_list.append(id)\n",
    "\n",
    "        V = \"V\" + x[0].split(\"V\")[1]\n",
    "        V_list.append(V)\n",
    "\n",
    "        trip = x[1]\n",
    "        if V not in trips.keys():\n",
    "            trips[V]= []\n",
    "        trips[V].append(trip)\n",
    "\n",
    "    vehicles = set(V_list)\n",
    "    ids = set(id_num_list)\n",
    "\n",
    "    trip_counts = trips.copy()\n",
    "\n",
    "    for V in trip_counts.keys():\n",
    "        trip_counts[V] = len(trips[V])\n",
    "\n",
    "    # Output results:\n",
    "    print(\"Volts Database Status:\")\n",
    "    print(\"-\"*50)\n",
    "    print(\"Directory:\",data_path)\n",
    "    print(\"Files:\",len(files_list),\"parquet files found.\")\n",
    "    print(\"Unique id values: \", ids)\n",
    "    print(\"Total number of vehicles: \", len(vehicles))\n",
    "    print(\"Total number of complete trips: \", sum(trip_counts.values()))\n",
    "    print(\"-\"*50)\n",
    "    print(\"Trips per vehicle:\")\n",
    "    for V in trip_counts.keys():\n",
    "        print(\"     \",V,\": \",trip_counts[V], \"complete trips\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    return files_list, trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volts Database Status:\n",
      "--------------------------------------------------\n",
      "Directory: C:\\Users\\SIEGLEW\\OneDrive - Daimler Truck\\MA\\Code\\MA-Data\\trips_processed_resampled\n",
      "Files: 2951 parquet files found.\n",
      "Unique id values:  {'983'}\n",
      "Total number of vehicles:  15\n",
      "Total number of complete trips:  2951\n",
      "--------------------------------------------------\n",
      "Trips per vehicle:\n",
      "      V101 :  213 complete trips\n",
      "      V102 :  3 complete trips\n",
      "      V10 :  2 complete trips\n",
      "      V11 :  52 complete trips\n",
      "      V12 :  261 complete trips\n",
      "      V13 :  302 complete trips\n",
      "      V14 :  575 complete trips\n",
      "      V15 :  198 complete trips\n",
      "      V16 :  304 complete trips\n",
      "      V17 :  262 complete trips\n",
      "      V18 :  301 complete trips\n",
      "      V19 :  146 complete trips\n",
      "      V1 :  141 complete trips\n",
      "      V2 :  12 complete trips\n",
      "      V4 :  179 complete trips\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "parquet_folder = Path(DATA_PATH, 'trips_processed_resampled')\n",
    "all_files, trip_by_vehicle = trip_data_info(parquet_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = parquet_folder\n",
    "cwd = os.getcwd()\n",
    "\n",
    "if os.path.exists(os.path.join(cwd,data_dir)):\n",
    "    data_path = os.path.join(cwd,data_dir)\n",
    "\n",
    "# Get the shape of the DataFrame (rows, columns)\n",
    "trip_size = []\n",
    "for f in all_files:\n",
    "    trip_rows = pq.read_metadata(os.path.join(data_path,f)).num_rows\n",
    "    trip_size.append(trip_rows)\n",
    "\n",
    "    #if pq.read_metadata(os.path.join(data_path,f)).num_columns != 114:\n",
    "    #    print(f)\n",
    "\n",
    "trips_sizes = pd.DataFrame(trip_size, all_files)\n",
    "\n",
    "trips_sizes.columns = ['trip_size']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>v_id983V16_trip216.parquet</th>\n",
       "      <td>513235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V14_trip300_2.parquet</th>\n",
       "      <td>484381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V14_trip364_2.parquet</th>\n",
       "      <td>464288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V14_trip363_2.parquet</th>\n",
       "      <td>462661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V14_trip358_2.parquet</th>\n",
       "      <td>440238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V101_trip74.parquet</th>\n",
       "      <td>1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V17_trip241.parquet</th>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V101_trip19.parquet</th>\n",
       "      <td>1277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V4_trip128.parquet</th>\n",
       "      <td>1238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V19_trip44.parquet</th>\n",
       "      <td>1236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2951 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              trip_size\n",
       "v_id983V16_trip216.parquet       513235\n",
       "v_id983V14_trip300_2.parquet     484381\n",
       "v_id983V14_trip364_2.parquet     464288\n",
       "v_id983V14_trip363_2.parquet     462661\n",
       "v_id983V14_trip358_2.parquet     440238\n",
       "...                                 ...\n",
       "v_id983V101_trip74.parquet         1288\n",
       "v_id983V17_trip241.parquet         1281\n",
       "v_id983V101_trip19.parquet         1277\n",
       "v_id983V4_trip128.parquet          1238\n",
       "v_id983V19_trip44.parquet          1236\n",
       "\n",
       "[2951 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_sizes.sort_values(by='trip_size', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>v_id983V14_trip300_2.parquet</th>\n",
       "      <td>71114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V14_trip364_2.parquet</th>\n",
       "      <td>53322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V16_trip216.parquet</th>\n",
       "      <td>52616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V14_trip322.parquet</th>\n",
       "      <td>51167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V14_trip363_2.parquet</th>\n",
       "      <td>50486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V13_trip167.parquet</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V101_trip19.parquet</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V101_trip74.parquet</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V101_trip166.parquet</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v_id983V17_trip241.parquet</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2951 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              trip_size\n",
       "v_id983V14_trip300_2.parquet      71114\n",
       "v_id983V14_trip364_2.parquet      53322\n",
       "v_id983V16_trip216.parquet        52616\n",
       "v_id983V14_trip322.parquet        51167\n",
       "v_id983V14_trip363_2.parquet      50486\n",
       "...                                 ...\n",
       "v_id983V13_trip167.parquet          137\n",
       "v_id983V101_trip19.parquet          135\n",
       "v_id983V101_trip74.parquet          131\n",
       "v_id983V101_trip166.parquet         131\n",
       "v_id983V17_trip241.parquet          129\n",
       "\n",
       "[2951 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips_sizes.sort_values(by='trip_size', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read through all trips and extract SOC-difference:\n",
    "trip_soc = []\n",
    "for f in all_files:\n",
    "    soc = pd.read_parquet(parquet_folder + \"/\" + f, engine='fastparquet', columns = [\"hv_bat_soc_cval_bms1\"])\n",
    "    d_soc = soc.iloc[soc.last_valid_index()] - soc.iloc[soc.first_valid_index()]    # considering first and last non-NaN value only!\n",
    "    trip_soc.append(d_soc.values)\n",
    "\n",
    "all_trips_soc = pd.DataFrame(trip_soc, all_files)\n",
    "all_trips_soc.insert(1,\"trip_size\", trips_sizes)\n",
    "all_trips_soc.columns = [\"soc_diff\", \"trip_size\"]\n",
    "\n",
    "trips_sizes = trips_sizes.sort_values(by=['trip_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if SOC-List is complete:\n",
    "if all_trips_soc.isnull().values.any():\n",
    "    print('SOC calculation failed for theses files:')\n",
    "    all_trips_soc.iloc[np.where(all_trips_soc.isnull().values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Volts.pickle', 'wb') as handle:\n",
    "    pickle.dump([all_files, all_trips_soc, trips_sizes, trip_by_vehicle], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/home/sieglew/data/Trips_processed/V19_trip43.pickle', 'wb') as handle:\n",
    "    pickle.dump([all_files, all_trips_soc, trips_sizes, trip_by_vehicle], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
