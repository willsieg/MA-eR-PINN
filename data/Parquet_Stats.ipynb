{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Parquet Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>\n",
    "Version 1.3<br>\n",
    "Created: 09.09.2024  <br>\n",
    "William Siegle, Daimler Truck AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify Data Location\n",
    "parquet_folder = '/home/sieglew/data/processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trip_data_info(relative_path):\n",
    "\n",
    "    from os import listdir, getcwd\n",
    "    from os.path import isfile, join, exists\n",
    "\n",
    "    # data base directory path:\n",
    "    data_dir = relative_path\n",
    "    cwd = getcwd()\n",
    "\n",
    "    if exists(join(cwd,data_dir)):\n",
    "        data_path = join(cwd,data_dir)\n",
    "    else:\n",
    "        print(\"Directory '\",data_dir,\"' not found!\")\n",
    "        print(\"Files and directories in '\", cwd, \"' :\") \n",
    "        print(listdir(cwd))\n",
    "        quit()\n",
    "\n",
    "    # create list of all parquet files:\n",
    "    files_list = [f for f in listdir(data_path) if (isfile(join(data_path, f)) and f.endswith(\".parquet\"))]\n",
    "\n",
    "    id_num_list,V_list = ([],[])\n",
    "    trips  = {}\n",
    "\n",
    "    for f in files_list:\n",
    "        f = f.strip(\"v_.parquet\")\n",
    "        x = f.split(\"_\",1)\n",
    "\n",
    "        id = x[0].split(\"V\")[0].strip(\"id\")\n",
    "        id_num_list.append(id)\n",
    "\n",
    "        V = \"V\" + x[0].split(\"V\")[1]\n",
    "        V_list.append(V)\n",
    "\n",
    "        trip = x[1]\n",
    "        if V not in trips.keys():\n",
    "            trips[V]= []\n",
    "        trips[V].append(trip)\n",
    "\n",
    "    vehicles = set(V_list)\n",
    "    ids = set(id_num_list)\n",
    "\n",
    "    trip_counts = trips.copy()\n",
    "\n",
    "    for V in trip_counts.keys():\n",
    "        trip_counts[V] = len(trips[V])\n",
    "\n",
    "    # Output results:\n",
    "    print(\"Volts Database Status:\")\n",
    "    print(\"-\"*50)\n",
    "    print(\"Directory:\",data_path)\n",
    "    print(\"Files:\",len(files_list),\"parquet files found.\")\n",
    "    print(\"Unique id values: \", ids)\n",
    "    print(\"Total number of vehicles: \", len(vehicles))\n",
    "    print(\"Total number of complete trips: \", sum(trip_counts.values()))\n",
    "    print(\"-\"*50)\n",
    "    print(\"Trips per vehicle:\")\n",
    "    for V in trip_counts.keys():\n",
    "        print(\"     \",V,\": \",trip_counts[V], \"complete trips\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    return files_list, trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volts Database Status:\n",
      "--------------------------------------------------\n",
      "Directory: /home/sieglew/data/processed\n",
      "Files: 3197 parquet files found.\n",
      "Unique id values:  {'983'}\n",
      "Total number of vehicles:  15\n",
      "Total number of complete trips:  3197\n",
      "--------------------------------------------------\n",
      "Trips per vehicle:\n",
      "      V17 :  276 complete trips\n",
      "      V14 :  578 complete trips\n",
      "      V19 :  158 complete trips\n",
      "      V13 :  310 complete trips\n",
      "      V18 :  303 complete trips\n",
      "      V15 :  199 complete trips\n",
      "      V101 :  222 complete trips\n",
      "      V1 :  183 complete trips\n",
      "      V4 :  186 complete trips\n",
      "      V12 :  262 complete trips\n",
      "      V16 :  333 complete trips\n",
      "      V11 :  59 complete trips\n",
      "      V2 :  57 complete trips\n",
      "      V10 :  68 complete trips\n",
      "      V102 :  3 complete trips\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "all_files, trip_by_vehicle = trip_data_info(parquet_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = parquet_folder\n",
    "cwd = os.getcwd()\n",
    "\n",
    "if os.path.exists(os.path.join(cwd,data_dir)):\n",
    "    data_path = os.path.join(cwd,data_dir)\n",
    "\n",
    "# Get the shape of the DataFrame (rows, columns)\n",
    "trip_size = []\n",
    "for f in all_files:\n",
    "    trip_rows = pq.read_metadata(os.path.join(data_path,f)).num_rows\n",
    "    trip_size.append(trip_rows)\n",
    "\n",
    "    #if pq.read_metadata(os.path.join(data_path,f)).num_columns != 114:\n",
    "    #    print(f)\n",
    "\n",
    "trips_sizes = pd.DataFrame(trip_size, all_files)\n",
    "\n",
    "trips_sizes.columns = ['trip_size']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read through all trips and extract SOC-difference:\n",
    "trip_soc = []\n",
    "for f in all_files:\n",
    "    soc = pd.read_parquet(parquet_folder + \"/\" + f, engine='fastparquet', columns = [\"hv_bat_soc_cval_bms1\"])\n",
    "    d_soc = soc.iloc[soc.last_valid_index()] - soc.iloc[soc.first_valid_index()]    # considering first and last non-NaN value only!\n",
    "    trip_soc.append(d_soc.values)\n",
    "\n",
    "all_trips_soc = pd.DataFrame(trip_soc, all_files)\n",
    "all_trips_soc.insert(1,\"trip_size\", trips_sizes)\n",
    "all_trips_soc.columns = [\"soc_diff\", \"trip_size\"]\n",
    "\n",
    "trips_sizes = trips_sizes.sort_values(by=['trip_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if SOC-List is complete:\n",
    "if all_trips_soc.isnull().values.any():\n",
    "    print('SOC calculation failed for theses files:')\n",
    "    all_trips_soc.iloc[np.where(all_trips_soc.isnull().values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Volts.pickle', 'wb') as handle:\n",
    "    pickle.dump([all_files, all_trips_soc, trips_sizes, trip_by_vehicle], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/home/sieglew/data/Trips_processed/V19_trip43.pickle', 'wb') as handle:\n",
    "    pickle.dump([all_files, all_trips_soc, trips_sizes, trip_by_vehicle], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
