------------------------------------------------------------
Total Files:	6626
Filtered Files:	6626
------------------------------------------------------------
               FileName  Length  Index
0       V13_T25.parquet   20843   3868
1      V13_T352.parquet   18308   3630
2     V18_T1224.parquet   16645   5939
3      V101_T37.parquet   16591   4718
4      V13_T486.parquet   16434   3811
...                 ...     ...    ...
6621  V17_T4757.parquet     645   2031
6622  V14_T1967.parquet     643   5314
6623    V4_T260.parquet     636   4530
6624    V4_T244.parquet     628   3798
6625  V14_T2036.parquet     625   3635

[6626 rows x 3 columns]
------------------------------------------------------------
Input Signals:	37
Target Signals:	1
Physical Prior Signals:	1
------------------------------------------------------------
 --> Warning: Removed the last 48 samples to ensure a balanced batch size
fitting Scalers: MinMaxScaler, MinMaxScaler, MinMaxScaler
	50% of the fitting done...
Done. Create DataSets and DataLoaders...
	Number of batches created: 22
	Number of batches created: 7
	Number of batches created: 4
------------------------------------------------------------
Train size:  19102987		(Files: 4400)
Val. size:   9013278		(Files: 1392)
Test size:   3317724		(Files: 786) 
 ------------------------------------------------------------
	Removed 48 file from the dataset
------------------------------------------------------------
------------------------------------------------------------
 DeepLSTM_v3(
  (lstm): LSTM(37, 100, num_layers=4, batch_first=True, dropout=0.05)
  (dropout_layer): Dropout(p=0.05, inplace=False)
  (fc1): Linear(in_features=100, out_features=200, bias=True)
  (bn1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2): Linear(in_features=200, out_features=100, bias=True)
  (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc3): Linear(in_features=100, out_features=50, bias=True)
  (bn3): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc4): Linear(in_features=50, out_features=1, bias=True)
  (relu): ReLU()
) ------------------------------------------------------------
Model state_dict:
------------------------------------------------------------
Training Started.	Process ID: 399236 
------------------------------------------------------------
Model: DeepLSTM_v3	Parameters on device: CUDA:0
------------------------------------------------------------
Train/Batch size:	22 / 22
Loss:			CustomLoss(
  (mse_loss): MSELoss()
)
Optimizer:		Adam
LR:			0.0003
Weight Decay:		1e-07
------------------------------------------------------------
  0%|          | 0/22 [00:00<?, ?batch/s]Epoch 1/2000:   0%|          | 0/22 [00:01<?, ?batch/s]                                                       Traceback (most recent call last):
  File "/home/sieglew/MA-eR-PINN/test/train_hot_cold/PTRAIN_EVAL_PINN.py", line 376, in <module>
    config = CONFIG)
          ^^^^^^^^^^^
  File "/home/sieglew/MA-eR-PINN/src/utils/Trainers.py", line 274, in train_model
    loss, loss_components = self.loss_fn_pinn(outputs.squeeze(), targets, priors, self.l_p)
    ^^^^^^^^^^^^^^^^^^^^^
  File "/home/sieglew/.conda/envs/sieglew/lib/python3.11/site-packages/torch/_tensor.py", line 1109, in __iter__
    raise TypeError("iteration over a 0-d tensor")
TypeError: iteration over a 0-d tensor
Exception ignored in atexit callback: <function _MultiProcessingDataLoaderIter._clean_up_worker at 0x7fb189342e80>
Traceback (most recent call last):
  File "/home/sieglew/.conda/envs/sieglew/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1598, in _clean_up_worker
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/home/sieglew/.conda/envs/sieglew/lib/python3.11/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sieglew/.conda/envs/sieglew/lib/python3.11/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sieglew/.conda/envs/sieglew/lib/python3.11/multiprocessing/connection.py", line 948, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/sieglew/.conda/envs/sieglew/lib/python3.11/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt: 
