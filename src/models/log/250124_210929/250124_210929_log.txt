------------------------------------------------------------
Training Started.	Process ID: 1879654 
------------------------------------------------------------
Model: DeepLSTM_v3	Parameters on device: CUDA:0
------------------------------------------------------------
Train/Batch size:	144 / 144
Loss:			CustomLoss(
  (mse_loss): MSELoss()
)
Optimizer:		Adam
LR:			0.0003
Weight Decay:		1e-07
------------------------------------------------------------

------------------------------------------------------------
Epoch         Iteration     Batch Loss      Train Loss    
------------------------------------------------------------
1             1             2.518050
1             144           0.019894		0.214935

Val           Validation Loss:				0.008484

------------------------------------------------------------
Epoch         Iteration     Batch Loss      Train Loss    
------------------------------------------------------------
l_p updated after epoch 2: 0.993 -> 0.992
2             1             0.017784
2             144           0.009607		0.014502

Val           Validation Loss:				0.003734

------------------------------------------------------------
Epoch         Iteration     Batch Loss      Train Loss    
------------------------------------------------------------
l_p updated after epoch 3: 0.992 -> 0.991
3             1             0.012803
3             144           0.007210		0.008370

Val           Validation Loss:				0.002959

------------------------------------------------------------
Epoch         Iteration     Batch Loss      Train Loss    
------------------------------------------------------------
l_p updated after epoch 4: 0.991 -> 0.990
4             1             0.006048
4             144           0.005070		0.006945

Val           Validation Loss:				0.004020

------------------------------------------------------------
Epoch         Iteration     Batch Loss      Train Loss    
------------------------------------------------------------
l_p updated after epoch 5: 0.990 -> 0.989
5             1             0.007233
5             144           0.003384		0.005224
