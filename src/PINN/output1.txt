------------------------------------------------------------
Directories:
  /home/sieglew/MA-eR-PINN:			project, .gitignore, LICENSE, ref, test, README.md, data, src, .git, archive
  /home/sieglew/MA-Data:			__init__.py, __pycache__, trips_processed_resampled, final, y_true, processed, TripSequences, trips_processed_pickles, final_2, trips_processed_final
------------------------------------------------------------
Running in script mode
CONFIG Dictionary:
---------------------------------------------------------------------------------------------------------------------------------
     Parameter        Value
--  ---------------  ------------------------------------------------------------------------------------------------------------
0   GPU_SELECT       3
1   ROOT             /home/sieglew/MA-eR-PINN
2   INPUT_LOCATION   TripSequences/trips_processed_pinn
3   OUTPUT_LOCATION  src/models/pth
4   SEED             55
5   PLOT_ACTIVE      True
6   TRAIN_VAL_TEST   [0.8, 0.15, 0.05]
7   MAX_FILES        None
8   SCALERS          {'feature_scaler': 'MaxAbsScaler()', 'target_scaler': 'MaxAbsScaler()', 'prior_scaler': 'MaxAbsScaler()'}
9   MIN_SEQ_LENGTH   600
10  FEATURES         ['vehspd_cval_cpc',
                      'altitude_cval_ippc',
                      'airtempoutsd_cval_cpc',
                      'roadgrad_cval_pt',
                      'vehweight_cval_pt',
                      'accelpdlposn_cval',
                      'bs_brk_cval',
                      'elcomp_pwrcons_cval',
                      'motortemperature_pti1',
                      'powerstagetemperature_pti1',
                      'epto_pwr_cval',
                      'airtempinsd_cval_hvac',
                      'brktempra_cval',
                      'selgr_rq_pt']
11  TARGETS          ['soc_gradient']
12  PRIORS           ['emot_pwr_pred']
13  HIDDEN_SIZE      400
14  NUM_LAYERS       2
15  DROPOUT          0.5
16  NUM_EPOCHS       8
17  BATCH_SIZE       16
18  LEARNING_RATE    0.001
19  OPTIMIZER        torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE, weight_decay = 1e-3)
20  LRSCHEDULER      torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience = 2, factor = 0.5, min_lr = 1e-7)
21  CRITERION        nn.SmoothL1Loss()
22  LOSS_FN          F.mse_loss(output, target)
23  MODE             train_mode
24  TRAIN_LOG        test1.txt 
---------------------------------------------------------------------------------------------------------------------------------

Torch version:  2.5.1+cu124
Using: -->  CUDA:3
------------------------------------------------------------
Total Files:	18629
Filtered Files:	14050
------------------------------------------------------------
                FileName  Length  Index
0        V13_T25.parquet   20843   1796
1       V18_T775.parquet   19425   5324
2       V13_T352.parquet   18308   1746
3       V18_T972.parquet   17858   7030
4      V16_T1629.parquet   17519   3550
...                  ...     ...    ...
14045   V12_T273.parquet     602  13860
14046   V16_T522.parquet     601   2893
14047  V18_T1549.parquet     601   6147
14048   V18_T883.parquet     601   8194
14049  V17_T3857.parquet     601   8206

[14050 rows x 3 columns]
------------------------------------------------------------
Input Signals:	14
Target Signals:	1
Physical Prior Signals:	1
------------------------------------------------------------
 LSTM1(
  (lstm): LSTM(14, 400, num_layers=2, batch_first=True, dropout=0.5)
  (relu): ReLU()
  (fc_test): Linear(in_features=400, out_features=1, bias=True)
) ------------------------------------------------------------
Model state_dict:
lstm.weight_ih_l0:	 torch.Size([1600, 14])
lstm.weight_hh_l0:	 torch.Size([1600, 400])
lstm.bias_ih_l0:	 torch.Size([1600])
lstm.bias_hh_l0:	 torch.Size([1600])
lstm.weight_ih_l1:	 torch.Size([1600, 400])
lstm.weight_hh_l1:	 torch.Size([1600, 400])
lstm.bias_ih_l1:	 torch.Size([1600])
lstm.bias_hh_l1:	 torch.Size([1600])
fc_test.weight:	 torch.Size([1, 400])
fc_test.bias:	 torch.Size([1])
fitting Scalers: MaxAbsScaler, MaxAbsScaler, MaxAbsScaler
	50% of the fitting done...
Done. Create DataSets and DataLoaders...
	Number of batches created: 703
	Number of batches created: 132
	Number of batches created: 44
------------------------------------------------------------
Train size:  36683135		(Files: 11241)
Val. size:   6768674		(Files: 2107)
Test size:   2425835		(Files: 702) 
 ------------------------------------------------------------
first 3 train files: ['V13_T25.parquet', 'V18_T775.parquet', 'V13_T352.parquet']
------------------------------------------------------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0.001
)
------------------------------------------------------------
LRScheduler: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>
------------------------------------------------------------
Loss_Fn: F.mse_loss(output, target)
------------------------------------------------------------
 Criterion: <class 'torch.nn.modules.loss.SmoothL1Loss'>
------------------------------------------------------------

------------------------------------------------------------
Training Started.	Process ID: 4004501 
------------------------------------------------------------
Model: LSTM1	Parameters on device: CUDA:3
------------------------------------------------------------
Train/Batch size:	703 / 1
Loss:			<function loss_fn_PINN_3 at 0x7fd2746da1f0>
Optimizer:		AdamW
LR:			0.001
Weight Decay:		0.001
------------------------------------------------------------
Epoch             Iteration         Batch Loss        Train Loss
1/8               1/703             0.001016

                  175               1.2e-05

                  350               4e-06

                  525               6e-06

                  703               3e-06             1.3e-05

Val               Validation Loss:  1.5e-05

2/8               1/703             3e-06

                  175               3e-06

                  350               6e-06

                  525               3e-06

                  703               3e-06             4e-06

Val               Validation Loss:  1.4e-05

3/8               1/703             4e-06

                  175               1e-06

                  350               3e-06

                  525               2e-06

                  703               4e-06             3e-06

Val               Validation Loss:  1.3e-05

4/8               1/703             2e-06

                  175               4e-06

                  350               2e-06

                  525               2e-06

                  703               2e-06             2e-06

Val               Validation Loss:  1.3e-05

5/8               1/703             1e-06

                  175               3e-06

                  350               1e-06

                  525               6e-06

                  703               5e-06             2e-06

Val               Validation Loss:  1.4e-05

6/8               1/703             3e-06

                  175               1e-06

                  350               2e-06

                  525               1e-06

                  703               1e-06             2e-06

Val               Validation Loss:  1.3e-05

7/8               1/703             1e-06

                  175               2e-06

                  350               2e-06

                  525               1e-06

                  703               1e-06             2e-06

Val               Validation Loss:  1.3e-05

8/8               1/703             1e-06

                  175               1e-06

                  350               1e-06

                  525               1e-06

                  703               1e-06             1e-06

Val               Validation Loss:  1.2e-05
------------------------------------------------------------
Training Completed.	Execution Time: 00:16:01
------------------------------------------------------------

Model saved to:	 /home/sieglew/MA-eR-PINN/src/models/pth/LSTM1_241211_210023.pth
------------------------------------------------------------
Size: 23.17 MB
------------------------------------------------------------
Model loaded from:	/home/sieglew/MA-eR-PINN/src/models/pth/LSTM1_241211_210023.pth
------------------------------------------------------------
Model: LSTM1	Parameters on device: cuda:3
------------------------------------------------------------
Train/Batch size:	703 / 1
Loss:			<function loss_fn_PINN_3 at 0x7fd2746da1f0>
Optimizer:		AdamW
LR:			0.001
Weight Decay:		0.001
------------------------------------------------------------
 LSTM1(
  (lstm): LSTM(14, 400, num_layers=2, batch_first=True, dropout=0.5)
  (relu): ReLU()
  (fc_test): Linear(in_features=400, out_features=1, bias=True)
)
Test Loss:  0.000001
RMSE: 0.0021
Standard Deviation: 0.0021
