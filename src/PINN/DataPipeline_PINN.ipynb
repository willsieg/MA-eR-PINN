{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------------------------------------------------------------------\n",
    "eRange Prediction with LSTM\n",
    "---------------------------------------------------------------------\n",
    "Version: V1.7       Modified: 06.11.2024        William Siegle\n",
    "---------------------------------------------------------------------\n",
    "(python -m) jupytext --to py FILENAME.ipynb\n",
    "------------------------------------------------------------------'''\n",
    "#import pathlib\n",
    "from pathlib import Path, WindowsPath, PosixPath\n",
    "\n",
    "# SETTINGS ------------------------------------------------------------------------\n",
    "CONFIG = {\n",
    "    # SYSTEM: ---------------------------------------------------------------------\n",
    "    \"GPU_SELECT\":       0, # {0,1,2,3, None: CPU only}\n",
    "    \"ROOT\":             Path('../..').resolve(),\n",
    "    \"INPUT_LOCATION\":   Path(\"TripSequences\", \"trips_processed_pinn_2\"), \n",
    "    \"OUTPUT_LOCATION\":  Path(\"src\", \"models\", \"pth\"),\n",
    "    \"SEED\"  :           1,\n",
    "    \"PLOT_ACTIVE\":      True,\n",
    "\n",
    "    # DATA PREPROCESSING: ---------------------------------------------------------\n",
    "    \"TRAIN_VAL_TEST\":   [0.8, 0.19, 0.01], # [train, val, test splits]\n",
    "    \"MAX_FILES\":        None, # None: all files\n",
    "    \"SCALERS\":          {'feature_scaler': 'MaxAbsScaler()',\n",
    "                         'target_scaler': 'MinMaxScaler(feature_range=(0, 1))',\n",
    "                         'prior_scaler': 'MinMaxScaler(feature_range=(0, 1))'},\n",
    "    \"MIN_SEQ_LENGTH\":   600, # minimum sequence length in s to be included in DataSets\n",
    "\n",
    "    # FEATURES: -------------------------------------------------------------------\n",
    "    \"FEATURES\":         ['actdrvtrnpwrprc_cval', \"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", \n",
    "                        'roadgrad_cval_pt', \"vehweight_cval_pt\", \"accelpdlposn_cval\", \"bs_brk_cval\", \"elcomp_pwrcons_cval\",\n",
    "                        \"motortemperature_pti1\", \"powerstagetemperature_pti1\",\"epto_pwr_cval\",\n",
    "                        'airtempinsd_cval_hvac', 'brktempra_cval', 'selgr_rq_pt', 'start_soc', 'actualtorque_pti1','brc_stat_brc1', 'actualspeed_pti1',\n",
    "                        'rmsmotorcurrent_pti1','currpwr_contendrnbrkresist_cval', 'elcomp_pwrcons_cval','hv_ptc_cabin1_pwr_cval',\n",
    "                        'maxrecuppwrprc_cval','txoiltemp_cval_tcm'], #['start_soc']\n",
    "                        \n",
    "    \"TARGETS\":          ['hv_bat_soc_cval_bms1'],   #['hv_bat_soc_cval_bms1', 'soc_gradient'],\n",
    "    \"PRIORS\":           ['emot_soc_pred'],  \n",
    "\n",
    "    # MODEL: -----------------------------------------------------------------------\n",
    "    \"HIDDEN_SIZE\":      400,    # features in the hidden state h\n",
    "    \"NUM_LAYERS\":       2,      # recurrent layers for stacked LSTMs. Default: 1\n",
    "    \"DROPOUT\":          0.5,\n",
    "    \n",
    "    # TRAINING & OPTIMIZER: --------------------------------------------------------\n",
    "    \"NUM_EPOCHS\":       10,\n",
    "    \"BATCH_SIZE\":       64,   # [16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768]\n",
    "    \"LEARNING_RATE\":    1e-3,   # 0.001 lr\n",
    "    \"OPTIMIZER\":        \"torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE, weight_decay = 1e-3)\",     \n",
    "                        # weight_decay = 1e-4     # weight decay coefficient (default: 1e-2)\n",
    "                        # betas = (0.9, 0.95),    # coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "                        # eps = 1e-8,             # term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "    \"LRSCHEDULER\":      \"torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience = 2, factor = 0.5, min_lr = 1e-7)\",\n",
    "\n",
    "    # LOSS FUNCTION: ---------------------------------------------------------------\n",
    "    \"CRITERION\":        \"nn.SmoothL1Loss()\", # ['nn.MSELoss()', 'nn.L1Loss()', 'nn.SmoothL1Loss()', 'nn.HuberLoss()', 'MASE()']\n",
    "    \"LOSS_FN\":          \"F.mse_loss(output, target)\", # ['F.mse_loss(output, target)', 'F.l1_loss(output, target)', 'F.smooth_l1_loss(output, target)', 'F.huber_loss(output, target)', 'F.mase_loss(output, target)']\n",
    "\n",
    "    # SAVE & LOAD: -----------------------------------------------------------------\n",
    "    \"MODE\":             \"train_mode\", # ['train_mode', 'test_mode']\n",
    "    \"TRAIN_LOG\":        \"test1.txt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "LOCATE DEVICES & SYSTEM FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Directories:\n",
      "  /home/sieglew/MA-eR-PINN:\t\t\tproject, ref, test, data, src, .git, archive\n",
      "  /home/sieglew/MA-Data:\t\t\t__pycache__, trips_processed_resampled, final, y_true, processed, TripSequences, trips_processed_pickles, final_2, trips_processed_final\n",
      "------------------------------------------------------------\n",
      "Running in notebook mode\n",
      "CONFIG Dictionary:\n",
      "---------------------------------------------------------------------------------------------------------------------------------\n",
      "     Parameter        Value\n",
      "--  ---------------  ------------------------------------------------------------------------------------------------------------\n",
      "0   GPU_SELECT       0\n",
      "1   ROOT             /home/sieglew/MA-eR-PINN\n",
      "2   INPUT_LOCATION   TripSequences/trips_processed_pinn_2\n",
      "3   OUTPUT_LOCATION  src/models/pth\n",
      "4   SEED             1\n",
      "5   PLOT_ACTIVE      True\n",
      "6   TRAIN_VAL_TEST   [0.8, 0.19, 0.01]\n",
      "7   MAX_FILES        None\n",
      "8   SCALERS          {'feature_scaler': 'MaxAbsScaler()',\n",
      "                      'target_scaler': 'MinMaxScaler(feature_range=(0,\n",
      "                      1))',\n",
      "                      'prior_scaler': 'MinMaxScaler(feature_range=(0,\n",
      "                      1))'}\n",
      "9   MIN_SEQ_LENGTH   600\n",
      "10  FEATURES         ['actdrvtrnpwrprc_cval',\n",
      "                      'vehspd_cval_cpc',\n",
      "                      'altitude_cval_ippc',\n",
      "                      'airtempoutsd_cval_cpc',\n",
      "                      'roadgrad_cval_pt',\n",
      "                      'vehweight_cval_pt',\n",
      "                      'accelpdlposn_cval',\n",
      "                      'bs_brk_cval',\n",
      "                      'elcomp_pwrcons_cval',\n",
      "                      'motortemperature_pti1',\n",
      "                      'powerstagetemperature_pti1',\n",
      "                      'epto_pwr_cval',\n",
      "                      'airtempinsd_cval_hvac',\n",
      "                      'brktempra_cval',\n",
      "                      'selgr_rq_pt',\n",
      "                      'start_soc',\n",
      "                      'actualtorque_pti1',\n",
      "                      'brc_stat_brc1',\n",
      "                      'actualspeed_pti1',\n",
      "                      'rmsmotorcurrent_pti1',\n",
      "                      'currpwr_contendrnbrkresist_cval',\n",
      "                      'elcomp_pwrcons_cval',\n",
      "                      'hv_ptc_cabin1_pwr_cval',\n",
      "                      'maxrecuppwrprc_cval',\n",
      "                      'txoiltemp_cval_tcm']\n",
      "11  TARGETS          ['hv_bat_soc_cval_bms1']\n",
      "12  PRIORS           ['emot_soc_pred']\n",
      "13  HIDDEN_SIZE      400\n",
      "14  NUM_LAYERS       2\n",
      "15  DROPOUT          0.5\n",
      "16  NUM_EPOCHS       10\n",
      "17  BATCH_SIZE       64\n",
      "18  LEARNING_RATE    0.001\n",
      "19  OPTIMIZER        torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE, weight_decay = 1e-3)\n",
      "20  LRSCHEDULER      torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience = 2, factor = 0.5, min_lr = 1e-7)\n",
      "21  CRITERION        nn.SmoothL1Loss()\n",
      "22  LOSS_FN          F.mse_loss(output, target)\n",
      "23  MODE             train_mode\n",
      "24  TRAIN_LOG        test1.txt \n",
      "---------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Torch version:  2.4.1+cu121\n",
      "Using: -->  CUDA:0\n"
     ]
    }
   ],
   "source": [
    "# LOCATE REPOSITORY/DATASTORAGE IN CURRENT SYSTEM ENVIRONMENT  ---------------------------\n",
    "# ----------------------------------------------------------------------------------------\n",
    "import sys, os\n",
    "for key in CONFIG: globals()[key] = CONFIG[key]\n",
    "if 'ROOT' not in globals(): ROOT = Path('../..').resolve()\n",
    "sys.path.append(os.path.abspath(ROOT))\n",
    "\n",
    "# INTERNAL MODULE IMPORTS ----------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------\n",
    "from src.__init__ import *\n",
    "from src.utils.data_utils import *\n",
    "from src.utils.preprocess_utils import *\n",
    "from src.utils.eval_utils import *\n",
    "from src.utils.Trainers import *\n",
    "#from src.LSTM.lstm_models import *\n",
    "\n",
    "# SETUP ENVIRONMENT ---------------------------------------------------------------------\n",
    "DATA_PATH, IS_NOTEBOOK, DEVICE = setup_environment(CONFIG, ROOT, SEED, GPU_SELECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Total Files:\t16116\n",
      "Filtered Files:\t12258\n",
      "------------------------------------------------------------\n",
      "                FileName  Length  Index\n",
      "0        V13_T25.parquet   20843   1568\n",
      "1       V18_T775.parquet   19425   4647\n",
      "2       V13_T352.parquet   18308   1521\n",
      "3       V18_T972.parquet   17858   6125\n",
      "4      V16_T1629.parquet   17519   3101\n",
      "...                  ...     ...    ...\n",
      "12253   V12_T273.parquet     602  12093\n",
      "12254   V16_T522.parquet     601   2517\n",
      "12255  V18_T1549.parquet     601   5368\n",
      "12256   V18_T883.parquet     601   7134\n",
      "12257  V17_T3857.parquet     601   7143\n",
      "\n",
      "[12258 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# FILE SOURCES ---------------------------------------------------------------\n",
    "input_folder = Path(DATA_PATH, INPUT_LOCATION) # Trip parquet files\n",
    "pth_folder = Path(ROOT, OUTPUT_LOCATION)\n",
    "files, trip_lengths, indices_by_length, sorted_trip_lengths, all_signals = prepare_data(input_folder, pth_folder, MAX_FILES, MIN_SEQ_LENGTH, ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT & TARGET SPECIFICATION ---------------------------------------------------\n",
    "# these signals are required for the physical Model calculation:\n",
    "base_signals = [\"signal_time\", \"hirestotalvehdist_cval_icuc\", \"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", \n",
    "                \"hv_batpwr_cval_bms1\", \"emot_pwr_cval\",\"bs_roadincln_cval\", \"roadgrad_cval_pt\"]\n",
    "\n",
    "# these signals have to be dropped (from Features) in order for appropriate training:\n",
    "columns_to_drop = [\"signal_time\",                       # works as index\n",
    "                    \"hirestotalvehdist_cval_icuc\",      # starts from 0, obtained by speed integration\n",
    "                    \"latitude_cval_ippc\",               # only GPS \n",
    "                    \"longitude_cval_ippc\",              # only GPS\n",
    "                    \"hv_batpwr_cval_bms1\",              # directly related to target (soc_gradient)\n",
    "                    \"hv_batmomavldischrgen_cval_1\",     # indirect target 1 in kWh\n",
    "                    \"hv_bat_soc_cval_bms1\",              # indirect target 2 in %SoC\n",
    "                    \"soc_gradient\",                     # actual target signal   \n",
    "                    \"emot_pwr_cval\",                    # replaced as physical prior for PINN\n",
    "                    \"emot_pwr_pred\",                    # actual physical prior for PINN\n",
    "                    ]\n",
    "\n",
    "# Ensure no element of \"columns_to_drop\" is included in \"FEATURES\"\n",
    "assert not any(col in FEATURES for col in columns_to_drop), \"Some columns to drop are still in FEATURES\"\n",
    "\n",
    "# ---------------------------------------------------\n",
    "selection_1 = [\"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", 'roadgrad_cval_pt', \"vehweight_cval_pt\", \"accelpdlposn_cval\", \"bs_brk_cval\", \"elcomp_pwrcons_cval\",\n",
    "               \"epto_pwr_cval\", \"motortemperature_pti1\", \"powerstagetemperature_pti1\", 'airtempinsd_cval_hvac', 'brktempra_cval', 'selgr_rq_pt']\n",
    "selection_2 = [\"hirestotalvehdist_cval_icuc\", \"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", \"hv_batpwr_cval_bms1\", \"emot_pwr_cval\", \"roadgrad_cval_pt\"]\n",
    "selection_3 = [\"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", \"vehweight_cval_pt\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Input Signals:\t25\n",
      "Target Signals:\t1\n",
      "Physical Prior Signals:\t1\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# FEATURE SELECTION  ----------------------------------------------------------------------------\n",
    "INPUT_COLUMNS = FEATURES\n",
    "TARGET_COLUMN = TARGETS\n",
    "PRIOR_COLUMN = PRIORS\n",
    "print(f\"{'-'*60}\\nInput Signals:\\t{len(FEATURES)}\\nTarget Signals:\\t{len(TARGETS)}\\nPhysical Prior Signals:\\t{len(PRIORS)}\\n{'-'*60}\")\n",
    "\n",
    "# FEATURE NORMALIZATION/SCALING -----------------------------------------------------------------\n",
    "scaler = eval(SCALERS['feature_scaler'])\n",
    "target_scaler = eval(SCALERS['target_scaler'])\n",
    "prior_scaler = eval(SCALERS['prior_scaler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['actdrvtrnpwrprc_cval',\n",
       "  'vehspd_cval_cpc',\n",
       "  'altitude_cval_ippc',\n",
       "  'airtempoutsd_cval_cpc',\n",
       "  'roadgrad_cval_pt',\n",
       "  'vehweight_cval_pt',\n",
       "  'accelpdlposn_cval',\n",
       "  'bs_brk_cval',\n",
       "  'elcomp_pwrcons_cval',\n",
       "  'motortemperature_pti1',\n",
       "  'powerstagetemperature_pti1',\n",
       "  'epto_pwr_cval',\n",
       "  'airtempinsd_cval_hvac',\n",
       "  'brktempra_cval',\n",
       "  'selgr_rq_pt',\n",
       "  'start_soc',\n",
       "  'actualtorque_pti1',\n",
       "  'brc_stat_brc1',\n",
       "  'actualspeed_pti1',\n",
       "  'rmsmotorcurrent_pti1',\n",
       "  'currpwr_contendrnbrkresist_cval',\n",
       "  'elcomp_pwrcons_cval',\n",
       "  'hv_ptc_cabin1_pwr_cval',\n",
       "  'maxrecuppwrprc_cval',\n",
       "  'txoiltemp_cval_tcm'],\n",
       " ['hv_bat_soc_cval_bms1'],\n",
       " ['emot_soc_pred'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_COLUMNS, TARGET_COLUMN, PRIOR_COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Warning: Removed the last 15 samples to ensure a balanced batch size\n",
      "fitting Scalers: MaxAbsScaler, MinMaxScaler, MinMaxScaler\n",
      "\t50% of the fitting done...\n",
      "Done. Create DataSets and DataLoaders...\n",
      "\tNumber of batches created: 153\n",
      "\tNumber of batches created: 37\n",
      "\tNumber of batches created: 2\n",
      "------------------------------------------------------------\n",
      "Train size:  31979834\t\t(Files: 9792)\n",
      "Val. size:   7307710\t\t(Files: 2329)\n",
      "Test size:   425819\t\t(Files: 122) \n",
      " ------------------------------------------------------------\n",
      "\tRemoved 15 file from the dataset\n",
      "------------------------------------------------------------\n",
      "first 3 train files: ['V18_T775.parquet', 'V13_T352.parquet', 'V18_T513.parquet']\n"
     ]
    }
   ],
   "source": [
    "# GENERATE DATALOADERS ---------------------------------------------------------------\n",
    "\n",
    "# DATA SET SPLITTING AND SORTING ----------------------------------------------------------------\n",
    "train_subset, val_subset, test_subset = random_split(files, TRAIN_VAL_TEST)\n",
    "\n",
    "# DATALOADER SETTINGS ------------------------------------------------------------------\n",
    "dataloader_settings = {\n",
    "    'batch_size': 1,                    # see *Note above\n",
    "    'shuffle': True,                    # shuffle the batches before each epoch\n",
    "    'collate_fn': collate_fn_PINN,      # include optional arguments\n",
    "    'num_workers': 4,                   # number of workers\n",
    "    'pin_memory': False if DEVICE.type == 'cpu' else True}\n",
    "\n",
    "# PREPARE TRAIN, VAL & TEST DATALOADERS  ------------------------------------------------------------\n",
    "train_subset, train_dataset, train_dataset_batches, train_loader = prepare_dataloader_PINN(train_subset, indices_by_length, \\\n",
    "    BATCH_SIZE, INPUT_COLUMNS, TARGET_COLUMN, PRIOR_COLUMN, scaler, target_scaler, prior_scaler, dataloader_settings, fit=True, drop_last=True)\n",
    "\n",
    "val_subset, val_dataset, val_dataset_batches, val_loader = prepare_dataloader_PINN(val_subset, indices_by_length, \\\n",
    "    BATCH_SIZE, INPUT_COLUMNS, TARGET_COLUMN, PRIOR_COLUMN, scaler, target_scaler, prior_scaler, dataloader_settings)\n",
    "\n",
    "test_subset, test_dataset, test_dataset_batches, test_loader = prepare_dataloader_PINN(test_subset, indices_by_length, \\\n",
    "    BATCH_SIZE, INPUT_COLUMNS, TARGET_COLUMN, PRIOR_COLUMN, scaler, target_scaler, prior_scaler, dataloader_settings)\n",
    "\n",
    "'''\n",
    "# PREPARE TRAIN, VAL & TEST DATALOADERS  ------------------------------------------------------------\n",
    "train_subset, train_dataset, train_dataset_batches, train_loader = prepare_dataloader(train_subset, indices_by_length, \\\n",
    "    BATCH_SIZE, INPUT_COLUMNS, TARGET_COLUMN, scaler, target_scaler, dataloader_settings, fit=True)\n",
    "\n",
    "val_subset, val_dataset, val_dataset_batches, val_loader = prepare_dataloader(val_subset, indices_by_length, \\\n",
    "    BATCH_SIZE, INPUT_COLUMNS, TARGET_COLUMN, scaler, target_scaler, dataloader_settings, fit=False)\n",
    "\n",
    "test_subset, test_dataset, test_dataset_batches, test_loader = prepare_dataloader(test_subset, indices_by_length, \\\n",
    "    BATCH_SIZE, INPUT_COLUMNS, TARGET_COLUMN, scaler, target_scaler, dataloader_settings, fit=False)\n",
    "'''\n",
    "# print dataset info\n",
    "subset_files = print_dataset_sizes(train_dataset, val_dataset, test_dataset, train_subset, val_subset, test_subset, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      " LSTM1_packed_old_version(\n",
      "  (lstm): LSTM(25, 400, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (relu): ReLU()\n",
      "  (fc_test): Linear(in_features=400, out_features=1, bias=True)\n",
      ") ------------------------------------------------------------\n",
      "Model state_dict:\n",
      "lstm.weight_ih_l0:\t torch.Size([1600, 25])\n",
      "lstm.weight_hh_l0:\t torch.Size([1600, 400])\n",
      "lstm.bias_ih_l0:\t torch.Size([1600])\n",
      "lstm.bias_hh_l0:\t torch.Size([1600])\n",
      "lstm.weight_ih_l1:\t torch.Size([1600, 400])\n",
      "lstm.weight_hh_l1:\t torch.Size([1600, 400])\n",
      "lstm.bias_ih_l1:\t torch.Size([1600])\n",
      "lstm.bias_hh_l1:\t torch.Size([1600])\n",
      "fc_test.weight:\t torch.Size([1, 400])\n",
      "fc_test.bias:\t torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "class LSTM1_packed_flatten(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, device=DEVICE):\n",
    "        super(LSTM1_packed_flatten, self).__init__()\n",
    "\n",
    "        self.input_size = input_size    # input size\n",
    "        self.hidden_size = hidden_size  # hidden state\n",
    "        self.num_layers = num_layers    # number of layers\n",
    "        self.dropout = dropout\n",
    "        #self.seq_length = seq_length    # sequence length\n",
    "\n",
    "        # LSTM CELL --------------------------------\n",
    "        self.lstm = nn.LSTM(\n",
    "            self.input_size,            # The number of expected features in the input x\n",
    "            self.hidden_size,           # The number of features in the hidden state h\n",
    "            self.num_layers,            # Number of recurrent layers for stacked LSTMs. Default: 1\n",
    "            batch_first=True,           # If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Default: False\n",
    "            bias=True,                  # If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "            dropout=self.dropout,       # usually: [0.2 - 0.5], introduces a Dropout layer on the outputs of each LSTM layer except the last layer, (dropout probability). Default: 0\n",
    "            bidirectional=False,        # If True, becomes a bidirectional LSTM. Default: False\n",
    "            proj_size=0,                # If > 0, will use LSTM with projections of corresponding size. Default: 0\n",
    "            device=device\n",
    "        )\n",
    "        self.lstm.flatten_parameters()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_test = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, packed_input, batch_size=None):\n",
    "        self.lstm.flatten_parameters()\n",
    "\n",
    "\n",
    "        # Propagate input through LSTM\n",
    "        packed_out, _ = self.lstm(packed_input)\n",
    "        #print(f\"LSTM: Output after LSTM: {packed_out.data.shape}, {type(packed_out)}\")\n",
    "\n",
    "        # Unpack the output\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        #print(f\"             after packing: {out.shape}, {type(out)}\")\n",
    "\n",
    "        # Output layers\n",
    "        out = self.relu(out)  # relu\n",
    "        #print(f\"             after relu: {out.shape}, {type(out)}\")\n",
    "\n",
    "        out = self.fc_test(out)  # Use all outputs for prediction\n",
    "        #print(f\"             after fc: {out.shape}, {type(out)}\")\n",
    "        \n",
    "        return out\n",
    "\n",
    "class LSTM1_packed_old_version(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, seq_length, dropout, device=DEVICE):\n",
    "        super(LSTM1_packed_old_version, self).__init__()\n",
    "\n",
    "        self.input_size = input_size    # input size\n",
    "        self.hidden_size = hidden_size  # hidden state\n",
    "        self.num_layers = num_layers    # number of layers\n",
    "        self.dropout = dropout\n",
    "        self.seq_length = seq_length    # sequence length\n",
    "\n",
    "        # LSTM CELL --------------------------------\n",
    "        self.lstm = nn.LSTM(\n",
    "            self.input_size,            # The number of expected features in the input x\n",
    "            self.hidden_size,           # The number of features in the hidden state h\n",
    "            self.num_layers,            # Number of recurrent layers for stacked LSTMs. Default: 1\n",
    "            batch_first=True,           # If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Default: False\n",
    "            bias=True,                  # If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "            dropout=self.dropout,       # usually: [0.2 - 0.5], introduces a Dropout layer on the outputs of each LSTM layer except the last layer, (dropout probability). Default: 0\n",
    "            bidirectional=False,        # If True, becomes a bidirectional LSTM. Default: False\n",
    "            proj_size=0,                # If > 0, will use LSTM with projections of corresponding size. Default: 0\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_test = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, packed_input, batch_size=None):\n",
    "        #self.lstm.flatten_parameters()\n",
    "        # Propagate input through LSTM\n",
    "        print(f\"{'-'*60}\\nLSTM: Input to LSTM: {packed_input.data.shape}, {type(packed_input)}\")\n",
    "        packed_out, lengths = self.lstm(packed_input)\n",
    "        print(f\"LSTM: Output after LSTM: {packed_out.data.shape}, {type(packed_out)}\")\n",
    "\n",
    "        # Unpack the output\n",
    "        out, lengths = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        print(f\"             after packing: {out.shape}, {type(out)}\")\n",
    "\n",
    "        # Output layers\n",
    "        out = self.relu(out)  # relu\n",
    "        print(f\"             after relu: {out.shape}, {type(out)}\")\n",
    "\n",
    "        out = self.fc_test(out)  # Use all outputs for prediction\n",
    "        print(f\"             after fc: {out.shape}, {type(out)}\")\n",
    "        \n",
    "        return out\n",
    "\n",
    "# INSTANTIATE MODEL --------------------\n",
    "# MODEL CONFIGURATION -----------------------------------------------------------------------\n",
    "\n",
    "# LAYERS --------------------------------\n",
    "input_size = len(INPUT_COLUMNS)     # expected features in the input x\n",
    "hidden_size = HIDDEN_SIZE           # features in the hidden state h\n",
    "num_layers = NUM_LAYERS             # recurrent layers for stacked LSTMs. Default: 1\n",
    "num_classes = 1                     # output classes (=1 for regression)\n",
    "\n",
    "# INSTANTIATE MODEL --------------------\n",
    "model = LSTM1_packed_old_version(input_size, HIDDEN_SIZE, NUM_LAYERS, 60, DROPOUT).to(DEVICE)\n",
    "print(f\"{'-'*60}\\n\", model, f\"{'-'*60}\\nModel state_dict:\")\n",
    "for param_tensor in model.state_dict(): print(f\"{param_tensor}:\\t {model.state_dict()[param_tensor].size()}\") \n",
    "# --> Note torch.Size([4*hidden_size, input_size]) for LSTM weights because of i,o,f,g params concatenated\n",
    "\n",
    "#model = LSTM1_packed_flatten(len(INPUT_COLUMNS), HIDDEN_SIZE, NUM_LAYERS, DROPOUT, DEVICE).to(DEVICE)\n",
    "#print_info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Shape of packed_inputs.data: torch.Size([431514, 27])\n",
      "Lengths: tensor([6852, 6852, 6851, 6849, 6838, 6836, 6833, 6832, 6826, 6822, 6819, 6818,\n",
      "        6813, 6812, 6811, 6811, 6799, 6796, 6794, 6793, 6792, 6789, 6784, 6782,\n",
      "        6782, 6772, 6768, 6767, 6766, 6764, 6753, 6735, 6733, 6729, 6728, 6724,\n",
      "        6714, 6711, 6708, 6705, 6704, 6691, 6688, 6686, 6686, 6683, 6683, 6682,\n",
      "        6678, 6670, 6670, 6669, 6668, 6664, 6664, 6659, 6659, 6656, 6655, 6651,\n",
      "        6650, 6649, 6645, 6641])\n"
     ]
    }
   ],
   "source": [
    "if IS_NOTEBOOK and True: \n",
    "    check_batch_PINN(train_loader)\n",
    "    #visualize_padding(BATCH_SIZE, trip_lengths, sorted_trip_lengths, train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0.001\n",
      ")\n",
      "------------------------------------------------------------\n",
      "LRScheduler: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TRAINING CONFIGURATION -----------------------------------------------------------------------\n",
    "\n",
    "# OPTIMIZER --------------------------------------------------------------------------------\n",
    "# common optimizers: ['torch.optim.Adam', 'torch.optim.SGD', 'torch.optim.RMSprop']\n",
    "if 'OPTIMIZER' in globals(): optimizer = eval(OPTIMIZER)\n",
    "else: optimizer = torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE,\n",
    "        weight_decay = 1e-4      # weight decay coefficient (default: 1e-2)\n",
    "        #betas = (0.9, 0.95),    # coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "        #eps = 1e-8,             # term added to the denominator to improve numerical stability (default: 1e-8)\n",
    ")\n",
    "print(f\"{'-'*60}\\n{optimizer}\\n{'-'*60}\")\n",
    "\n",
    "# LR SCHEDULER ----------------------------------------------------------------------------\n",
    "if 'LRSCHEDULER' in globals(): scheduler = eval(LRSCHEDULER)\n",
    "else: scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience = 2, factor = 0.5, min_lr = 1e-6)\n",
    "print(f\"LRScheduler: {scheduler.__class__}\\n{'-'*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss_Fn: F.mse_loss(output, target)\n",
      "------------------------------------------------------------\n",
      " Criterion: <class 'torch.nn.modules.loss.SmoothL1Loss'>\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LOSS FUNCTION ----------------------------------------------------------------\n",
    "def loss_fn(output, target):\n",
    "    if 'LOSS_FN' in globals(): loss = eval(LOSS_FN)\n",
    "    else: loss = F.mse_loss(output, target) # mean-squared error for regression\n",
    "    return loss\n",
    "\n",
    "def loss_fn_PINN_1(output, target, prior):\n",
    "    loss = F.mse_loss(output, target, reduction='mean') # mean-squared error for regression\n",
    "    return loss\n",
    "\n",
    "# or define criterion function:\n",
    "criterion_list = [nn.MSELoss(), nn.L1Loss(), nn.SmoothL1Loss(), nn.HuberLoss(), MASE()]\n",
    "\n",
    "if 'CRITERION' in globals(): criterion = eval(CRITERION)\n",
    "else: criterion = nn.SmoothL1Loss()\n",
    "print(f\"Loss_Fn: {LOSS_FN}\\n{'-'*60}\\n\", f\"Criterion: {criterion.__class__}\\n{'-'*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn_PINN_2(output, target, prior):\n",
    "    y_pred = output\n",
    "    y_true = target\n",
    "    y_phys = prior\n",
    "\n",
    "    mse_loss = F.mse_loss(y_pred, y_true)\n",
    "    phys_loss = F.mse_loss(y_pred, y_phys)\n",
    "\n",
    "    total_loss = mse_loss + phys_loss\n",
    "    return total_loss\n",
    "\n",
    "def loss_fn_PINN_3(output, target, prior):\n",
    "    l_p = 0.5\n",
    "\n",
    "    y_pred = output\n",
    "    y_true = target\n",
    "    y_phys = prior\n",
    "\n",
    "    total_loss = F.mse_loss(y_true, (l_p * y_phys + (1 - l_p) * y_pred))\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET NETWORK TRAINER -----------------------------------------------------------------\n",
    "TRAINER = PTrainer_PINN(  #PTrainer_Standard, PTrainer_PINN\n",
    "    model = model, \n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler, \n",
    "    loss_fn = loss_fn_PINN_1, \n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader,\n",
    "    test_loader = test_loader,\n",
    "    num_epochs = NUM_EPOCHS, \n",
    "    device = DEVICE, \n",
    "    is_notebook = IS_NOTEBOOK,\n",
    "    use_mixed_precision = False,\n",
    "    log_file = TRAIN_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Training Started.\tProcess ID: 405641 \n",
      "------------------------------------------------------------\n",
      "Model: LSTM1_packed_old_version\tParameters on device: CUDA:0\n",
      "------------------------------------------------------------\n",
      "Train/Batch size:\t153 / 1\n",
      "Loss:\t\t\t<function loss_fn_PINN_1 at 0x7f2a481adf80>\n",
      "Optimizer:\t\tAdamW\n",
      "LR:\t\t\t0.001\n",
      "Weight Decay:\t\t0.001\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"scrollable_table\" style=\"height: 300px; overflow-y: scroll;\">\n",
       "    <table id=\"training_table\" style=\"width:60%; border-collapse: collapse;\">\n",
       "        <thead style=\"position: sticky; top: 0; z-index: 1;\">\n",
       "            <tr>\n",
       "                <th style=\"font-weight:bold; width:15%; text-align:left; padding: 10px; background-color: #404040;\">Epoch</th>\n",
       "                <th style=\"font-weight:bold; width:25%; text-align:left; padding: 10px; background-color: #404040;\">Iteration</th>\n",
       "                <th style=\"font-weight:bold; width:30%; text-align:left; padding: 10px; background-color: #404040;\">Batch Loss</th>\n",
       "                <th style=\"font-weight:bold; width:30%; text-align:left; padding: 10px; background-color: #404040;\">Train Loss</th>\n",
       "            </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        </tbody>\n",
       "    </table>\n",
       "    <script>\n",
       "        function addRow(epoch, step, loss, running_loss) {\n",
       "            var table = document.getElementById(\"training_table\").getElementsByTagName('tbody')[0];\n",
       "            var row = table.insertRow(-1);\n",
       "            var cell1 = row.insertCell(0);\n",
       "            var cell2 = row.insertCell(1);\n",
       "            var cell3 = row.insertCell(2);\n",
       "            var cell4 = row.insertCell(3);\n",
       "            cell1.style.textAlign = \"left\";\n",
       "            cell2.style.textAlign = \"left\";\n",
       "            cell3.style.textAlign = \"left\";\n",
       "            cell4.style.textAlign = \"left\";\n",
       "            cell1.innerHTML = epoch;\n",
       "            cell2.innerHTML = step;\n",
       "            cell3.innerHTML = loss;\n",
       "            cell4.innerHTML = running_loss;\n",
       "            var scrollableDiv = document.getElementById(\"scrollable_table\");\n",
       "            scrollableDiv.scrollTop = scrollableDiv.scrollHeight;\n",
       "        }\n",
       "    </script>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fff9051d10749d188fd6492c44dc4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/153 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "LSTM: Input to LSTM: torch.Size([644537, 27]), <class 'torch.nn.utils.rnn.PackedSequence'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sieglew/.local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:920: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[43200, 1]' is invalid for input of size 40000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# START TRAINING -----------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m MODE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_mode\u001b[39m\u001b[38;5;124m'\u001b[39m: CHECKPOINT \u001b[38;5;241m=\u001b[39m TRAINER\u001b[38;5;241m.\u001b[39mtrain_model()\n",
      "File \u001b[0;32m~/MA-eR-PINN/src/utils/Trainers.py:211\u001b[0m, in \u001b[0;36mPTrainer_PINN.train_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()  \u001b[38;5;66;03m# Update the scale for next iteration\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# B) Normal precision calculation ------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# inputs are packed, outputs are not ! --> see forward method in model\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# -------------------------------------\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 79\u001b[0m, in \u001b[0;36mLSTM1_packed_old_version.forward\u001b[0;34m(self, packed_input, batch_size)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, packed_input, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m#self.lstm.flatten_parameters()\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# Propagate input through LSTM\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLSTM: Input to LSTM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpacked_input\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(packed_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m     packed_out, lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM: Output after LSTM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpacked_out\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(packed_out)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# Unpack the output\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/rnn.py:920\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    917\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    918\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 920\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m output \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    923\u001b[0m hidden \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[43200, 1]' is invalid for input of size 40000"
     ]
    }
   ],
   "source": [
    "# START TRAINING -----------------------------------------------------------------\n",
    "if MODE == 'train_mode': CHECKPOINT = TRAINER.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "CHECKPOINT, model_destination_path = save_checkpoint(TRAINER, train_loader, val_loader, test_loader, CHECKPOINT, CONFIG, subset_files, pth_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%skip\n",
    "# LOAD MODEL -----------------------------------------------------------------\n",
    "#model_destination_path = Path(pth_folder, \"LSTM1_241211_225933.pth\")\n",
    "CHECKPOINT = load_checkpoint(model_destination_path, DEVICE)\n",
    "\n",
    "# get model type:\n",
    "for key in CHECKPOINT.keys(): globals()[key] = CHECKPOINT[key]\n",
    "\n",
    "# load model and optimizer states\n",
    "model.load_state_dict(model_state_dict)\n",
    "optimizer.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "model.eval()  # set model to evaluation mode for inference\n",
    "print(f\"Model loaded from:\\t{model_destination_path}\\n{'-'*60}\\nModel: {model.__class__.__name__}\\tParameters on device: {next(model.parameters()).device}\"\n",
    "        f\"\\n{'-'*60}\\nTrain/Batch size:\\t{len(train_loader.dataset)} / {train_loader.batch_size}\\n\"\n",
    "        f\"Loss:\\t\\t\\t{loss_fn}\\nOptimizer:\\t\\t{optimizer.__class__.__name__}\\nLR:\\t\\t\\t\"\n",
    "        f\"{optimizer.param_groups[0]['lr']}\\nWeight Decay:\\t\\t{optimizer.param_groups[0]['weight_decay']}\\n{'-'*60}\\n\", model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAINING PERFORMANCE -----------------------------------------------------------------\n",
    "# get DataFrame of training metrics:\n",
    "keys = ['training_table', 'train_losses_per_iter', 'train_losses', 'val_losses', 'lr_history', 'train_batches']\n",
    "training_table, train_losses_per_iter, train_losses, val_losses, lr_history, train_batches = (CHECKPOINT[key] for key in keys)\n",
    "training_df = pd.DataFrame(training_table, columns=[\"Epoch\", \"Iteration\", \"Batch Loss\", \"Train Loss\"])\n",
    "\n",
    "# -------------------------------------\n",
    "NUM_EPOCHS = CONFIG['NUM_EPOCHS']\n",
    "plot_training_performance(training_df, train_losses_per_iter, train_losses, val_losses, lr_history, train_batches, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_outputs_targets_priors(outputs, targets, priors, original_lengths) -> tuple:\n",
    "    all_outputs, all_targets, all_priors, all_original_lengths = [], [], [], []\n",
    "    for batch_outputs, batch_targets, batch_priors, batch_lengths in zip(outputs, targets, priors, original_lengths):\n",
    "        all_outputs.extend(batch_outputs)\n",
    "        all_targets.extend(batch_targets)\n",
    "        all_priors.extend(batch_priors)\n",
    "        all_original_lengths.extend(batch_lengths)\n",
    "        return all_outputs, all_targets, all_priors, all_original_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION -----------------------------------------------------------------\n",
    "\n",
    "# get file list of test subset\n",
    "test_files = CHECKPOINT[\"test_files\"]\n",
    "# -------------------------------------\n",
    "# evaluate model on test set\n",
    "test_loss, outputs, targets, priors, original_lengths = TRAINER.evaluate_model()\n",
    "# -------------------------------------\n",
    "all_outputs, all_targets, all_priors, all_original_lengths = concat_outputs_targets_priors(outputs, targets, priors, original_lengths)\n",
    "\n",
    "# Inverse-transform on all outputs and targets for evaluation\n",
    "scaled_outputs = [target_scaler.inverse_transform(output_sequence.reshape(1, -1)).squeeze() for output_sequence in all_outputs]\n",
    "scaled_targets = [target_scaler.inverse_transform(target_sequence.reshape(1, -1)).squeeze() for target_sequence in all_targets]\n",
    "\n",
    "all_y_true,all_y_pred  = np.concatenate(scaled_targets), np.concatenate(scaled_outputs)\n",
    "\n",
    "# calculate evaluation metrics\n",
    "rmse = root_mean_squared_error(all_y_true, all_y_pred)\n",
    "avg_error = np.mean(np.abs(all_y_true - all_y_pred))\n",
    "std_dev = np.std(all_y_true - all_y_pred)\n",
    "mape = np.mean(np.abs((all_y_true - all_y_pred) / all_y_true)) * 100\n",
    "\n",
    "print(f\"Test Loss:  {test_loss:.6f}\\nRMSE: {rmse:.4f}\\nStandard Deviation: {std_dev:.4f}\\nAvg Err.  STD: {avg_error:.4f}  {std_dev:.4f} ({mape:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT RESULTS -----------------------------------------------------------------\n",
    "# get random sample sequence from test set\n",
    "# -------------------------------------\n",
    "sample_int = random.randint(1, len(scaled_outputs)-1)\n",
    "y_pred = scaled_outputs[sample_int]\n",
    "y_true = scaled_targets[sample_int]\n",
    "\n",
    "# -------------------------------------\n",
    "def plot_prediction(y_true, y_pred, plot_active=True):\n",
    "     if plot_active:\n",
    "          plt.figure(figsize=(18,4))\n",
    "          plt.xlabel('Time in s')\n",
    "          plt.ylabel('SOC Change Rate in %/s')\n",
    "          plt.title('Battery State of Charge: Prediction vs. Actual Data')\n",
    "          plt.plot(y_true, label='Actual Data')  # actual plot\n",
    "          plt.plot(np.arange(0, len(y_true), 1), y_pred, label='Predicted Data')  # predicted plot\n",
    "          plt.legend()\n",
    "          plt.text(0.01, 0.02, f\"RMSE: {root_mean_squared_error(y_true, y_pred):.4f}\\nStd Dev: {np.std(y_true - y_pred):.4f}\",\n",
    "          transform=plt.gca().transAxes, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "          plt.figure(figsize=(18,4))\n",
    "          plt.xlabel('Time in s')\n",
    "          plt.ylabel('SOC in %')\n",
    "          plt.plot(savgol_filter(y_true.flatten(), window_length=60, polyorder=3), label='Actual Data (Smoothed)')  # actual plot\n",
    "          plt.plot(np.arange(0, len(y_true), 1), savgol_filter(y_pred.flatten(), window_length=60, polyorder=3), label='Predicted Data (Smoothed)')  # predicted plot\n",
    "          plt.legend()\n",
    "\n",
    "          \n",
    "plot_prediction(y_true, y_pred, PLOT_ACTIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,4))\n",
    "plt.plot(np.cumsum(y_pred), label='SOC Predicted')\n",
    "plt.plot(np.cumsum(y_true), label='Actual SOC')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
