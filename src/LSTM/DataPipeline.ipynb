{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------------------------------------------------------------------\n",
    "eRange Prediction with LSTM\n",
    "---------------------------------------------------------------------\n",
    "Version: V1.7       Modified: 06.11.2024        William Siegle\n",
    "---------------------------------------------------------------------\n",
    "(python -m) jupytext --to py FILENAME.ipynb\n",
    "------------------------------------------------------------------'''\n",
    "#import pathlib\n",
    "from pathlib import Path, WindowsPath, PosixPath\n",
    "\n",
    "# SETTINGS ------------------------------------------------------------------------\n",
    "CONFIG = {\n",
    "    # SYSTEM: ---------------------------------------------------------------------\n",
    "    \"GPU_SELECT\":       2, # {0,1,2,3, None: CPU only}\n",
    "    \"ROOT\":             Path('../..').resolve(),\n",
    "    \"INPUT_LOCATION\":   Path(\"TripSequences\", \"trips_processed_final\"), \n",
    "    \"OUTPUT_LOCATION\":  Path(\"src\", \"models\", \"pth\"),\n",
    "    \"SEED\"  :           55,\n",
    "    \"PLOT_ACTIVE\":      False,\n",
    "\n",
    "    # DATA PREPROCESSING: ---------------------------------------------------------\n",
    "    \"TRAIN_VAL_TEST\":   [0.8, 0.15, 0.05], # [train, val, test splits]\n",
    "    \"MAX_FILES\":        200, # None: all files\n",
    "    \"SCALERS\":          {'feature_scaler': 'MaxAbsScaler()', 'target_scaler': 'MinMaxScaler(feature_range=(0, 1))'},\n",
    "    \"MIN_SEQ_LENGTH\":   600, # minimum sequence length in s to be included in DataSets\n",
    "\n",
    "    # FEATURES: -------------------------------------------------------------------\n",
    "    \"FEATURES\":         ['actdrvtrnpwrprc_cval','altitude_cval_ippc','motortemperature_pti1',\n",
    "                        'brktempra_cval','hv_batmaxdischrgpwrlim_cval_1',\n",
    "                        'emot_pwr_cval','actualtorque_pti1','powerstagetemperature_pti1',\n",
    "                        'accelpdlposn_cval','airtempoutsd_cval_cpc','airtempinsd_cval_hvac','actualdcvoltage_pti1','hv_batavcelltemp_cval_bms1',\n",
    "                        'epto_pwr_cval','maxtracpwrpct_cval','airtempinsd_rq','bs_brk_cval','brc_stat_brc1','vehspd_cval_cpc',\n",
    "                        'vehweight_cval_pt','actualspeed_pti1','selgr_rq_pt',\n",
    "                        'rmsmotorcurrent_pti1','roadgrad_cval_pt','currpwr_contendrnbrkresist_cval','elcomp_pwrcons_cval',\n",
    "                        'hv_ptc_cabin1_pwr_cval','maxrecuppwrprc_cval','txoiltemp_cval_tcm'],\n",
    "    \"TARGETS\":          ['hv_bat_soc_cval_bms1'],\n",
    "\n",
    "    # MODEL: -----------------------------------------------------------------------\n",
    "    \"HIDDEN_SIZE\":      400,    # features in the hidden state h\n",
    "    \"NUM_LAYERS\":       2,      # recurrent layers for stacked LSTMs. Default: 1\n",
    "    \"DROPOUT\":          0.5,\n",
    "    \n",
    "    # TRAINING & OPTIMIZER: --------------------------------------------------------\n",
    "    \"NUM_EPOCHS\":       1,\n",
    "    \"BATCH_SIZE\":       32,   # [16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768]\n",
    "    \"LEARNING_RATE\":    1e-2,   # 0.001 lr\n",
    "    \"OPTIMIZER\":        \"torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE, weight_decay = 1e-3)\",      \n",
    "                        # weight_decay = 1e-4     # weight decay coefficient (default: 1e-2)\n",
    "                        # betas = (0.9, 0.95),    # coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "                        # eps = 1e-8,             # term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "    \"LRSCHEDULER\":      \"torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience = 2, factor = 0.5, min_lr = 1e-7)\",\n",
    "\n",
    "    # LOSS FUNCTION: ---------------------------------------------------------------\n",
    "    \"CRITERION\":        \"nn.SmoothL1Loss()\", # ['nn.MSELoss()', 'nn.L1Loss()', 'nn.SmoothL1Loss()', 'nn.HuberLoss()', 'MASE()']\n",
    "    \"LOSS_FN\":          \"F.mse_loss(output, target)\", # ['F.mse_loss(output, target)', 'F.l1_loss(output, target)', 'F.smooth_l1_loss(output, target)', 'F.huber_loss(output, target)', 'F.mase_loss(output, target)']\n",
    "\n",
    "    # SAVE & LOAD: -----------------------------------------------------------------\n",
    "    \"MODE\":             \"train_mode\", # ['train_mode', 'test_mode']\n",
    "    \"TRAIN_LOG\":        \"test1.txt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "LOCATE DEVICES & SYSTEM FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Directories:\n",
      "  C:\\Users\\SIEGLEW\\OneDrive - Daimler Truck\\MA\\Code\\MA-eR-PINN:\t\t\t.git, archive, data, project, ref, src, test\n",
      "  C:\\Users\\SIEGLEW\\OneDrive - Daimler Truck\\MA\\Code\\MA-Data:\t\t\tOLD, processed, TripSequences\n",
      "------------------------------------------------------------\n",
      "Running in notebook mode\n",
      "CONFIG Dictionary:\n",
      "---------------------------------------------------------------------------------------------------------------------------------\n",
      "     Parameter        Value\n",
      "--  ---------------  ------------------------------------------------------------------------------------------------------------\n",
      "0   GPU_SELECT       2\n",
      "1   ROOT             C:\\Users\\SIEGLEW\\OneDrive - Daimler Truck\\MA\\Code\\MA-eR-PINN\n",
      "2   INPUT_LOCATION   TripSequences\\trips_processed_final\n",
      "3   OUTPUT_LOCATION  src\\models\\pth\n",
      "4   SEED             55\n",
      "5   PLOT_ACTIVE      False\n",
      "6   TRAIN_VAL_TEST   [0.8, 0.15, 0.05]\n",
      "7   MAX_FILES        200\n",
      "8   SCALERS          {'feature_scaler': 'MaxAbsScaler()', 'target_scaler': 'MinMaxScaler(feature_range=(0, 1))'}\n",
      "9   MIN_SEQ_LENGTH   600\n",
      "10  FEATURES         ['actdrvtrnpwrprc_cval',\n",
      "                      'altitude_cval_ippc',\n",
      "                      'motortemperature_pti1',\n",
      "                      'brktempra_cval',\n",
      "                      'hv_batmaxdischrgpwrlim_cval_1',\n",
      "                      'emot_pwr_cval',\n",
      "                      'actualtorque_pti1',\n",
      "                      'powerstagetemperature_pti1',\n",
      "                      'accelpdlposn_cval',\n",
      "                      'airtempoutsd_cval_cpc',\n",
      "                      'airtempinsd_cval_hvac',\n",
      "                      'actualdcvoltage_pti1',\n",
      "                      'hv_batavcelltemp_cval_bms1',\n",
      "                      'epto_pwr_cval',\n",
      "                      'maxtracpwrpct_cval',\n",
      "                      'airtempinsd_rq',\n",
      "                      'bs_brk_cval',\n",
      "                      'brc_stat_brc1',\n",
      "                      'vehspd_cval_cpc',\n",
      "                      'vehweight_cval_pt',\n",
      "                      'actualspeed_pti1',\n",
      "                      'selgr_rq_pt',\n",
      "                      'rmsmotorcurrent_pti1',\n",
      "                      'roadgrad_cval_pt',\n",
      "                      'currpwr_contendrnbrkresist_cval',\n",
      "                      'elcomp_pwrcons_cval',\n",
      "                      'hv_ptc_cabin1_pwr_cval',\n",
      "                      'maxrecuppwrprc_cval',\n",
      "                      'txoiltemp_cval_tcm']\n",
      "11  TARGETS          ['hv_bat_soc_cval_bms1']\n",
      "12  HIDDEN_SIZE      400\n",
      "13  NUM_LAYERS       2\n",
      "14  DROPOUT          0.5\n",
      "15  NUM_EPOCHS       1\n",
      "16  BATCH_SIZE       32\n",
      "17  LEARNING_RATE    0.01\n",
      "18  OPTIMIZER        torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE, weight_decay = 1e-3)\n",
      "19  LRSCHEDULER      torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience = 2, factor = 0.5, min_lr = 1e-7)\n",
      "20  CRITERION        nn.SmoothL1Loss()\n",
      "21  LOSS_FN          F.mse_loss(output, target)\n",
      "22  MODE             train_mode\n",
      "23  TRAIN_LOG        test1.txt \n",
      "---------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Torch version:  2.5.1+cpu\n",
      "Using: -->  CPU\n"
     ]
    }
   ],
   "source": [
    "# LOCATE REPOSITORY/DATASTORAGE IN CURRENT SYSTEM ENVIRONMENT  ---------------------------\n",
    "# ----------------------------------------------------------------------------------------\n",
    "import sys, os\n",
    "for key in CONFIG: globals()[key] = CONFIG[key]\n",
    "if 'ROOT' not in globals(): ROOT = Path('../..').resolve()\n",
    "sys.path.append(os.path.abspath(ROOT))\n",
    "\n",
    "# INTERNAL MODULE IMPORTS ----------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------\n",
    "from src.__init__ import *\n",
    "from src.utils.data_utils import *\n",
    "from src.utils.preprocess_utils import *\n",
    "from src.utils.eval_utils import *\n",
    "from src.utils.Trainer import *\n",
    "from src.LSTM.lstm_models import *\n",
    "\n",
    "# SETUP ENVIRONMENT ---------------------------------------------------------------------\n",
    "DATA_PATH, IS_NOTEBOOK, DEVICE = setup_environment(CONFIG, ROOT, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Total Files:\t200\n",
      "Filtered Files:\t142\n",
      "------------------------------------------------------------\n",
      "              FileName  Length  Index\n",
      "0      V13_T16.parquet   14754    129\n",
      "1    V18_T1396.parquet   13274     28\n",
      "2     V15_T433.parquet   13193     34\n",
      "3    V14_T1081.parquet   12233     21\n",
      "4     V14_T186.parquet   11593    112\n",
      "..                 ...     ...    ...\n",
      "137    V4_T149.parquet     722    113\n",
      "138  V14_T1045.parquet     696     38\n",
      "139   V19_T265.parquet     655     90\n",
      "140  V18_T1227.parquet     648     87\n",
      "141   V19_T322.parquet     647     72\n",
      "\n",
      "[142 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# FILE SOURCES ---------------------------------------------------------------\n",
    "input_folder = Path(DATA_PATH, INPUT_LOCATION) # Trip parquet files\n",
    "pth_folder = Path(ROOT, OUTPUT_LOCATION)\n",
    "\n",
    "files, trip_lengths, indices_by_length, sorted_trip_lengths, all_signals \\\n",
    "    = prepare_data(input_folder, pth_folder, MAX_FILES, MIN_SEQ_LENGTH, ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT & TARGET SPECIFICATION ---------------------------------------------------\n",
    "# these signals are required for the physical Model calculation:\n",
    "base_signals = [\"signal_time\", \"hirestotalvehdist_cval_icuc\", \"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", \n",
    "                \"hv_batpwr_cval_bms1\", \"emot_pwr_cval\",\"bs_roadincln_cval\", \"roadgrad_cval_pt\"]\n",
    "\n",
    "# these signals have to be dropped in order for appropriate training:\n",
    "columns_to_drop = [\"hv_batmomavldischrgen_cval_1\", \"latitude_cval_ippc\", \"longitude_cval_ippc\", \"signal_time\", \"hirestotalvehdist_cval_icuc\"]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "selection_1 = [\"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", 'roadgrad_cval_pt', \"vehweight_cval_pt\", \"accelpdlposn_cval\", \"bs_brk_cval\", \"elcomp_pwrcons_cval\",\n",
    "               \"epto_pwr_cval\", \"motortemperature_pti1\", \"powerstagetemperature_pti1\", 'airtempinsd_cval_hvac', 'brktempra_cval', 'selgr_rq_pt']\n",
    "selection_2 = [\"hirestotalvehdist_cval_icuc\", \"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", \"hv_batpwr_cval_bms1\", \"emot_pwr_cval\", \"roadgrad_cval_pt\"]\n",
    "selection_3 = [\"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", \"vehweight_cval_pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Input Signals:\t38\n",
      "Target Signals:\t1\n"
     ]
    }
   ],
   "source": [
    "# FEATURE SELECTION  ----------------------------------------------------------------------------\n",
    "TARGET_COLUMN = TARGETS\n",
    "INPUT_COLUMNS = FEATURES\n",
    "INPUT_COLUMNS = list(set(all_signals) - set(columns_to_drop) - set(TARGET_COLUMN))\n",
    "print(f\"{'-'*60}\\nInput Signals:\\t{len(INPUT_COLUMNS)}\\nTarget Signals:\\t{len(TARGET_COLUMN)}\")\n",
    "\n",
    "# FEATURE NORMALIZATION/SCALING -----------------------------------------------------------------\n",
    "scaler = eval(SCALERS['feature_scaler'])\n",
    "target_scaler = eval(SCALERS['target_scaler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      " LSTM1(\n",
      "  (relu): ReLU()\n",
      "  (fc_test): Linear(in_features=400, out_features=1, bias=True)\n",
      "  (lstm): LSTM(38, 400, num_layers=2, batch_first=True, dropout=0.5)\n",
      ") ------------------------------------------------------------\n",
      "Model state_dict:\n",
      "fc_test.weight:\t torch.Size([1, 400])\n",
      "fc_test.bias:\t torch.Size([1])\n",
      "lstm.weight_ih_l0:\t torch.Size([1600, 38])\n",
      "lstm.weight_hh_l0:\t torch.Size([1600, 400])\n",
      "lstm.bias_ih_l0:\t torch.Size([1600])\n",
      "lstm.bias_hh_l0:\t torch.Size([1600])\n",
      "lstm.weight_ih_l1:\t torch.Size([1600, 400])\n",
      "lstm.weight_hh_l1:\t torch.Size([1600, 400])\n",
      "lstm.bias_ih_l1:\t torch.Size([1600])\n",
      "lstm.bias_hh_l1:\t torch.Size([1600])\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATE MODEL --------------------\n",
    "model = LSTM1(len(INPUT_COLUMNS), HIDDEN_SIZE, NUM_LAYERS, DROPOUT, DEVICE).to(DEVICE)\n",
    "print_info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Warning: Removed the last 18 samples to ensure a balanced batch size\n",
      "fitting Scalers: MaxAbsScaler, MinMaxScaler\n",
      "\t50% of the fitting done...\n",
      "Done. Create DataSets and DataLoaders...\n",
      "\tNumber of batches created: 3\n",
      "\tNumber of batches created: 1\n",
      "\tNumber of batches created: 1\n",
      "------------------------------------------------------------\n",
      "Train size:  312470\t\t(Files: 96)\n",
      "Val. size:   86483\t\t(Files: 21)\n",
      "Test size:   39803\t\t(Files: 7) \n",
      " ------------------------------------------------------------\n",
      "\tRemoved 18 file from the dataset\n",
      "------------------------------------------------------------\n",
      "first 3 train files: ['V15_T433.parquet', 'V14_T1081.parquet', 'V14_T186.parquet']\n"
     ]
    }
   ],
   "source": [
    "# GENERATE DATALOADERS ---------------------------------------------------------------\n",
    "\n",
    "# DATA SET SPLITTING AND SORTING ----------------------------------------------------------------\n",
    "train_subset, val_subset, test_subset = random_split(files, TRAIN_VAL_TEST)\n",
    "\n",
    "# DATALOADER SETTINGS ------------------------------------------------------------------\n",
    "dataloader_settings = {\n",
    "    'batch_size': 1,                # see *Note above\n",
    "    'shuffle': True,                # shuffle the batches before each epoch\n",
    "    'collate_fn': collate_fn,       # include optional arguments\n",
    "    'num_workers': 4,               # number of workers\n",
    "    'pin_memory': False if DEVICE.type == 'cpu' else True}\n",
    "\n",
    "# PREPARE TRAIN, VAL & TEST DATALOADERS  ------------------------------------------------------------\n",
    "train_subset, train_dataset, train_dataset_batches, train_loader = prepare_dataloader(train_subset, indices_by_length, \\\n",
    "    BATCH_SIZE, INPUT_COLUMNS, TARGET_COLUMN, scaler, target_scaler, dataloader_settings, fit=True, drop_last=True)\n",
    "\n",
    "val_subset, val_dataset, val_dataset_batches, val_loader = prepare_dataloader(val_subset, indices_by_length, \\\n",
    "    BATCH_SIZE, INPUT_COLUMNS, TARGET_COLUMN, scaler, target_scaler, dataloader_settings)\n",
    "\n",
    "test_subset, test_dataset, test_dataset_batches, test_loader = prepare_dataloader(test_subset, indices_by_length, \\\n",
    "    BATCH_SIZE, INPUT_COLUMNS, TARGET_COLUMN, scaler, target_scaler, dataloader_settings)\n",
    "\n",
    "# print dataset info\n",
    "subset_files = print_dataset_sizes(train_dataset, val_dataset, test_dataset, train_subset, val_subset, test_subset, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_NOTEBOOK and PLOT_ACTIVE: \n",
    "    visualize_padding(BATCH_SIZE, trip_lengths, sorted_trip_lengths, train_loader, val_loader, test_loader)\n",
    "    check_batch(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0.001\n",
      ")\n",
      "------------------------------------------------------------\n",
      "LRScheduler: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\n",
      "------------------------------------------------------------\n",
      "Loss_Fn: F.mse_loss(output, target)\n",
      "------------------------------------------------------------\n",
      "Criterion: <class 'torch.nn.modules.loss.SmoothL1Loss'>\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAINING CONFIGURATION -----------------------------------------------------------------------\n",
    "\n",
    "# OPTIMIZER --------------------------------------------------------------------------------\n",
    "# common optimizers: ['torch.optim.Adam', 'torch.optim.SGD', 'torch.optim.RMSprop']\n",
    "if 'OPTIMIZER' in globals(): optimizer = eval(OPTIMIZER)\n",
    "else: optimizer = torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE,\n",
    "        weight_decay = 1e-4      # weight decay coefficient (default: 1e-2)\n",
    "        #betas = (0.9, 0.95),    # coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "        #eps = 1e-8,             # term added to the denominator to improve numerical stability (default: 1e-8)\n",
    ")\n",
    "print(f\"{'-'*60}\\n{optimizer}\\n{'-'*60}\")\n",
    "\n",
    "# LR SCHEDULER ----------------------------------------------------------------------------\n",
    "if 'LRSCHEDULER' in globals(): scheduler = eval(LRSCHEDULER)\n",
    "else: scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience = 2, factor = 0.5, min_lr = 1e-6)\n",
    "print(f\"LRScheduler: {scheduler.__class__}\\n{'-'*60}\")\n",
    "\n",
    "# LOSS FUNCTION ----------------------------------------------------------------\n",
    "def loss_fn(output, target):\n",
    "    if 'LOSS_FN' in globals(): loss = eval(LOSS_FN)\n",
    "    else: loss = F.mse_loss(output, target) # mean-squared error for regression\n",
    "    return loss\n",
    "\n",
    "# or define criterion function:\n",
    "criterion_list = [nn.MSELoss(), nn.L1Loss(), nn.SmoothL1Loss(), nn.HuberLoss(), MASE()]\n",
    "\n",
    "if 'CRITERION' in globals(): criterion = eval(CRITERION)\n",
    "else: criterion = nn.SmoothL1Loss()\n",
    "print(f\"Loss_Fn: {LOSS_FN}\\n{'-'*60}\")\n",
    "print(f\"Criterion: {criterion.__class__}\\n{'-'*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET NETWORK TRAINER -----------------------------------------------------------------\n",
    "TRAINER = PTrainer_Standard(\n",
    "    model = model, \n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler, \n",
    "    loss_fn = criterion, \n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader,\n",
    "    test_loader = test_loader,\n",
    "    num_epochs = NUM_EPOCHS, \n",
    "    device = DEVICE, \n",
    "    is_notebook = IS_NOTEBOOK,\n",
    "    use_mixed_precision = False,\n",
    "    log_file = TRAIN_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Training Started.\tProcess ID: 27200 \n",
      "------------------------------------------------------------\n",
      "Model: LSTM1\tParameters on device: CPU\n",
      "------------------------------------------------------------\n",
      "Train/Batch size:\t3 / 1\n",
      "Loss:\t\t\tSmoothL1Loss()\n",
      "Optimizer:\t\tAdamW\n",
      "LR:\t\t\t0.01\n",
      "Weight Decay:\t\t0.001\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"scrollable_table\" style=\"height: 300px; overflow-y: scroll;\">\n",
       "    <table id=\"training_table\" style=\"width:60%; border-collapse: collapse;\">\n",
       "        <thead style=\"position: sticky; top: 0; z-index: 1;\">\n",
       "            <tr>\n",
       "                <th style=\"font-weight:bold; width:15%; text-align:left; padding: 10px; background-color: #404040;\">Epoch</th>\n",
       "                <th style=\"font-weight:bold; width:25%; text-align:left; padding: 10px; background-color: #404040;\">Iteration</th>\n",
       "                <th style=\"font-weight:bold; width:30%; text-align:left; padding: 10px; background-color: #404040;\">Batch Loss</th>\n",
       "                <th style=\"font-weight:bold; width:30%; text-align:left; padding: 10px; background-color: #404040;\">Train Loss</th>\n",
       "            </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        </tbody>\n",
       "    </table>\n",
       "    <script>\n",
       "        function addRow(epoch, step, loss, running_loss) {\n",
       "            var table = document.getElementById(\"training_table\").getElementsByTagName('tbody')[0];\n",
       "            var row = table.insertRow(-1);\n",
       "            var cell1 = row.insertCell(0);\n",
       "            var cell2 = row.insertCell(1);\n",
       "            var cell3 = row.insertCell(2);\n",
       "            var cell4 = row.insertCell(3);\n",
       "            cell1.style.textAlign = \"left\";\n",
       "            cell2.style.textAlign = \"left\";\n",
       "            cell3.style.textAlign = \"left\";\n",
       "            cell4.style.textAlign = \"left\";\n",
       "            cell1.innerHTML = epoch;\n",
       "            cell2.innerHTML = step;\n",
       "            cell3.innerHTML = loss;\n",
       "            cell4.innerHTML = running_loss;\n",
       "            var scrollableDiv = document.getElementById(\"scrollable_table\");\n",
       "            scrollableDiv.scrollTop = scrollableDiv.scrollHeight;\n",
       "        }\n",
       "    </script>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb544fb5af5d4bc1bf78d917c19a6126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# START TRAINING -----------------------------------------------------------------\n",
    "if MODE == 'train_mode': CHECKPOINT = TRAINER.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "CHECKPOINT, model_path = save_checkpoint(TRAINER, train_loader, val_loader, test_loader, CHECKPOINT, CONFIG, subset_files, pth_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%skip\n",
    "# LOAD MODEL -----------------------------------------------------------------\n",
    "#model_destination_path = Path(pth_folder, \"LSTM1_packed_241206_155418.pth\")\n",
    "model, optimizer, checkpoint = load_checkpoint(model_destination_path, model, optimizer, DEVICE, GPU_SELECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAINING PERFORMANCE -----------------------------------------------------------------\n",
    "# get DataFrame of training metrics:\n",
    "training_df = pd.DataFrame(training_table, columns=[\"Epoch\", \"Iteration\", \"Batch Loss\", \"Train Loss\"])\n",
    "\n",
    "# -------------------------------------\n",
    "plot_training_performance(training_df, train_losses_per_iter, train_losses, val_losses, lr_history, train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION -----------------------------------------------------------------\n",
    "\n",
    "# get file list of test subset\n",
    "test_files = checkpoint[\"test_files\"]\n",
    "# -------------------------------------\n",
    "# evaluate model on test set\n",
    "test_loss, outputs, targets, original_lengths = TRAINER.evaluate_model()\n",
    "# -------------------------------------\n",
    "all_outputs, all_targets, all_original_lengths = [], [], []\n",
    "for batch_outputs, batch_targets, batch_lengths in zip(outputs, targets, original_lengths):\n",
    "    all_outputs.extend(batch_outputs)\n",
    "    all_targets.extend(batch_targets)\n",
    "    all_original_lengths.extend(batch_lengths)\n",
    "\n",
    "# Inverse-transform on all outputs and targets for evaluation\n",
    "scaled_outputs = [target_scaler.inverse_transform(output_sequence.reshape(1, -1)).squeeze() for output_sequence in all_outputs]\n",
    "scaled_targets = [target_scaler.inverse_transform(target_sequence.reshape(1, -1)).squeeze() for target_sequence in all_targets]\n",
    "\n",
    "print(f\"Test Loss:  {test_loss:.6f}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(np.concatenate(scaled_targets), np.concatenate(scaled_outputs)):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(np.concatenate(scaled_targets) - np.concatenate(scaled_outputs)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT RESULTS -----------------------------------------------------------------\n",
    "# get random sample sequence from test set\n",
    "# -------------------------------------\n",
    "sample_int = random.randint(1, len(scaled_outputs))\n",
    "y_pred = scaled_outputs[sample_int]\n",
    "y_true = scaled_targets[sample_int]\n",
    "\n",
    "###############################################\n",
    "# PLOT PREDICTION -----------------------------------------------------------------\n",
    "if PLOT_ACTIVE:\n",
    "     plt.figure(figsize=(18,4)); plt.xlabel('Time in s'); plt.ylabel('SOC in %'); plt.title('Battery State of Charge: Prediction vs. Actual Data') \n",
    "     plt.plot(y_true, label='Actual Data') # actual plot\n",
    "     plt.plot(np.arange(0, len(y_true), 1), y_pred, label='Predicted Data') # predicted plot\n",
    "     plt.legend()\n",
    "     plt.text(0.01, 0.02, f\"RMSE: {root_mean_squared_error(y_true, y_pred):.4f}\\nStd Dev: {np.std(y_true - y_pred):.4f}\",\\\n",
    "          transform=plt.gca().transAxes, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "     plt.figure(figsize=(18,4)); plt.xlabel('Time in s'); plt.ylabel('SOC in %')\n",
    "     plt.plot(savgol_filter(y_true.flatten(), window_length=60, polyorder=3), label='Actual Data (Smoothed)') # actual plot\n",
    "     plt.plot(np.arange(0, len(y_true), 1), savgol_filter(y_pred.flatten(), window_length=60, polyorder=3), label='Predicted Data (Smoothed)') # predicted plot\n",
    "     plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODOs: \n",
    "- check if keeping the hidden state between batches is necessary\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
