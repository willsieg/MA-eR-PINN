{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset -f -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: /home/sieglew/MA-eR-PINN\n"
     ]
    }
   ],
   "source": [
    "'''------------------------------------------------------------------\n",
    "---------------------------------------------------------------------\n",
    "LSTM Training\n",
    "---------------------------------------------------------------------\n",
    "Version: V1.7       Modified: 06.11.2024        William Siegle\n",
    "---------------------------------------------------------------------\n",
    "notebook can be converted to python script using: \n",
    "(python -m) jupytext --to py FILENAME.ipynb\n",
    "------------------------------------------------------------------'''\n",
    "from pathlib import Path\n",
    "\n",
    "# SETTINGS ------------------------------------------------------------------------\n",
    "CONFIG = {\n",
    "    # SYSTEM: ---------------------------------------------------------------------\n",
    "    \"ROOT\":             Path('../..').resolve(),\n",
    "    \"INPUT_LOCATION\":   Path(\"TripSequences\", \"trips_processed_final\"), \n",
    "    \"OUTPUT_LOCATION\":  Path(\"src\", \"models\", \"pth\"),\n",
    "    \"GPU_SELECT\":       0, # {0,1,2,3, None: CPU only}\n",
    "    \"TORCH_SEED\"  :     7,\n",
    "\n",
    "    # DATA PREPROCESSING: ---------------------------------------------------------\n",
    "    \"TRAIN_VAL_TEST\":   [0.8, 0.15, 0.05], # [train, val, test splits]\n",
    "    \"MAX_FILES\":        None, # None: all files\n",
    "    \"SCALERS\":          {'feature_scaler': 'MaxAbsScaler()', 'target_scaler': 'MinMaxScaler(feature_range=(0, 1))'},\n",
    "\n",
    "    # FEATURES: -------------------------------------------------------------------\n",
    "    \"FEATURES\":         [\"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", 'roadgrad_cval_pt', \"vehweight_cval_pt\", \"accelpdlposn_cval\", \n",
    "                         \"bs_brk_cval\", \"elcomp_pwrcons_cval\",\"epto_pwr_cval\", \"motortemperature_pti1\", \"powerstagetemperature_pti1\", 'airtempinsd_cval_hvac', \n",
    "                         'brktempra_cval', 'selgr_rq_pt'],\n",
    "    \"TARGETS\":          ['hv_bat_soc_cval_bms1'],\n",
    "\n",
    "    # MODEL: -----------------------------------------------------------------------\n",
    "    \"HIDDEN_SIZE\":      400,    # features in the hidden state h\n",
    "    \"NUM_LAYERS\":       2,      # recurrent layers for stacked LSTMs. Default: 1\n",
    "    \"DROPOUT\":          0.5,\n",
    "    \"SEQ_LENGTH\":       60,\n",
    "    \n",
    "    # TRAINING & OPTIMIZER: --------------------------------------------------------\n",
    "    \"NUM_EPOCHS\":       10,\n",
    "    \"BATCH_SIZE\":       16,   # [16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768]\n",
    "    \"LEARNING_RATE\":    2e-3,   # 0.001 lr\n",
    "    \"OPTIMIZER\":        \"torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE, weight_decay = 1e-3)\",      \n",
    "                            # weight_decay = 1e-4     # weight decay coefficient (default: 1e-2)\n",
    "                            # betas = (0.9, 0.95),    # coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "                            # eps = 1e-8,             # term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "    \"LRSCHEDULER\":      \"torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience = 2, factor = 0.5, min_lr = 1e-7)\",\n",
    "\n",
    "    # LOSS FUNCTION: ---------------------------------------------------------------\n",
    "    \"CRITERION\":        \"nn.SmoothL1Loss()\", #['nn.MSELoss()', 'nn.L1Loss()', 'nn.SmoothL1Loss()', 'nn.HuberLoss()', 'MASE()']\n",
    "\n",
    "\n",
    "    # METRICS: ---------------------------------------------------------------------\n",
    "\n",
    "    # SAVE & LOAD: -----------------------------------------------------------------\n",
    "\n",
    "}\n",
    "\n",
    "for key in CONFIG: globals()[key] = CONFIG[key]\n",
    "print(f\"ROOT: {ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "LOCATE DEVICES & SYSTEM FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Directories:\n",
      "  /home/sieglew/MA-eR-PINN:\t\t\tproject, ref, test, data, src, .git, archive\n",
      "  /home/sieglew/MA-Data:\t\t\t__pycache__, trips_processed_resampled, final, y_true, processed, TripSequences, trips_processed_pickles, final_2, trips_processed_final\n",
      "------------------------------------------------------------\n",
      "Running in notebook mode\n"
     ]
    }
   ],
   "source": [
    "# LOCATE REPOSITORY/DATASTORAGE IN CURRENT SYSTEM ENVIRONMENT  ---------------------------\n",
    "# ----------------------------------------------------------------------------------------\n",
    "import sys, os\n",
    "global ROOT, DATA_PATH\n",
    "if 'ROOT' not in globals(): ROOT = Path('../..').resolve()\n",
    "print(f\"{'-'*60}\\nDirectories:\\n  {ROOT}:\\t\\t\\t{', '.join([_.name for _ in ROOT.glob('*/')])}\")\n",
    "sys.path.append(os.path.abspath(ROOT))\n",
    "from data import get_data_path  # paths set in \"data/__init__.py\"\n",
    "DATA_PATH = get_data_path()\n",
    "print(f\"  {DATA_PATH}:\\t\\t\\t{', '.join([_.name for _ in DATA_PATH.glob('*/')])}\")\n",
    "\n",
    "# INTERNAL MODULE IMPORTS ----------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------\n",
    "from src.utils.TripDataset import *\n",
    "from src.utils.train_model import *\n",
    "\n",
    "# NOTEBOOK / SCRIPT SETTINGS -------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------\n",
    "global IS_NOTEBOOK\n",
    "IS_NOTEBOOK = False\n",
    "try:    # if running in IPython\n",
    "    shell = get_ipython().__class__.__name__ # type: ignore \n",
    "    from IPython.display import display, HTML, Javascript, clear_output\n",
    "    from IPython.core.magic import register_cell_magic\n",
    "    @register_cell_magic    # cells can be skipped by using '%%skip' in the first line\n",
    "    def skip(line, cell): return\n",
    "    from tqdm.notebook import tqdm as tqdm_nb\n",
    "    IS_NOTEBOOK = True\n",
    "    print(f\"{'-'*60}\\nRunning in notebook mode\")\n",
    "except (NameError, ImportError):    # if running in script\n",
    "    from tqdm import tqdm as tqdm\n",
    "    from tabulate import tabulate\n",
    "    print(f\"{'-'*60}\\nRunning in script mode\")\n",
    "    \n",
    "# GENERAL MODULE IMPORTS -----------------------------------------------------------------\n",
    "# ----------------------------------------------------------------------------------------\n",
    "import math, time, random, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt; plt.style.use('ggplot')\n",
    "import pyarrow.parquet as pq\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.compose import ColumnTransformer\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
    "from torchmetrics.functional import mean_squared_error\n",
    "torch.set_default_dtype(torch.float32); torch.manual_seed(TORCH_SEED);\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from pytorch_forecasting.metrics import MASE\n",
    "#from darts import TimeSeries\n",
    "#from darts.models import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Torch version:  2.4.1+cu121\n",
      "Using: -->  CUDA:0\n"
     ]
    }
   ],
   "source": [
    "# DEVICE SELECTION ---------------------------------------------------------------------\n",
    "global DEVICE\n",
    "print(f\"{'-'*60}\\nTorch version: \", torch.__version__)\n",
    "if not torch.cuda.is_available() or GPU_SELECT is None:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "else:\n",
    "    DEVICE = torch.device(f\"cuda:{GPU_SELECT}\")\n",
    "print(f\"Using: -->  {str(DEVICE).upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Input Data:\t/home/sieglew/MA-Data/TripSequences/trips_processed_final\n",
      "Store model in:\t/home/sieglew/MA-eR-PINN/src/models/pth\n",
      "------------------------------------------------------------\n",
      "Total Files:\t18629\n",
      "Filtered Files:\t15024\n",
      "------------------------------------------------------------\n",
      "                FileName  Length  Index\n",
      "0        V13_T25.parquet   20843   1920\n",
      "1       V18_T775.parquet   19425   5702\n",
      "2       V13_T352.parquet   18308   1869\n",
      "3       V18_T972.parquet   17858   7531\n",
      "4      V16_T1629.parquet   17519   3804\n",
      "...                  ...     ...    ...\n",
      "15019   V17_T975.parquet     402   6782\n",
      "15020    V1_T214.parquet     402  13653\n",
      "15021  V16_T1274.parquet     401    813\n",
      "15022   V18_T761.parquet     401   4795\n",
      "15023  V14_T1237.parquet     401  13221\n",
      "\n",
      "[15024 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# FILE SOURCES ---------------------------------------------------------------\n",
    "input_folder = Path(DATA_PATH, INPUT_LOCATION) # Trip parquet files\n",
    "pth_folder = Path(ROOT, OUTPUT_LOCATION)\n",
    "print(f\"{'-'*60}\\nInput Data:\\t{input_folder}\\nStore model in:\\t{pth_folder}\")\n",
    "\n",
    "# PREPARE TRAIN & TEST SET ---------------------------------------------------\n",
    "all_files = [Path(input_folder, f) for f in os.listdir(input_folder) if f.endswith(\".parquet\")]\n",
    "files = all_files[:MAX_FILES]\n",
    "print(f\"{'-'*60}\\nTotal Files:\\t{len(files)}\")\n",
    "# ---------------------------------------------------\n",
    "df = pd.read_parquet(Path(input_folder, random.choice(files)), engine='fastparquet')\n",
    "all_signals = df.columns\n",
    "assert len(all_signals) == 44\n",
    "\n",
    "# FILTER INPUT FILES --------------------------------------------------------\n",
    "# generate lengths of all files by reading metadata or using presaved lengths\n",
    "try:\n",
    "    presaved_lengths = pd.read_pickle(Path(ROOT, 'data', 'df_files_lengths.pickle'))\n",
    "    presaved_lengths = presaved_lengths.set_index('FileName').to_dict()['Length']\n",
    "    trip_lengths = [presaved_lengths[file.name] for file in files]\n",
    "except:\n",
    "    print(f\"{'-'*60}\\nObtaining sequence lengths... (may take up to 5 minutes)\")\n",
    "    trip_lengths = [pq.read_metadata(file).num_rows for file in files]\n",
    "\n",
    "# discard all items shorter than min_seq_length\n",
    "min_seq_length = 400\n",
    "filtered_files = []\n",
    "filtered_lengths = []\n",
    "for file, length in zip(files, trip_lengths):\n",
    "    if length > min_seq_length: \n",
    "        filtered_files.append(file)\n",
    "        filtered_lengths.append(length)\n",
    "\n",
    "# replace lists with only filtered items\n",
    "files = filtered_files\n",
    "trip_lengths = filtered_lengths\n",
    "print(f\"Filtered Files:\\t{len(files)}\\n{'-'*60}\")\n",
    "\n",
    "# SORT INPUT FILES BY SEQUENCE LENGTH --------------------------------------\n",
    "# this is needed in order to later sort the sequence by their length\n",
    "file_length_mapping = sorted([(file.name, length, idx) for idx, (file, length) in enumerate(zip(files, trip_lengths))], \\\n",
    "    key=lambda x: x[1], reverse=True)\n",
    "\n",
    "file_length_df = pd.DataFrame(file_length_mapping, columns=['FileName', 'Length', 'Index'])\n",
    "print(file_length_df)\n",
    "\n",
    "indices_by_length = file_length_df['Index'].to_list()\n",
    "sorted_trip_lengths = file_length_df['Length'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "def plot_sequence_lengths(batch_size, trip_lengths):\n",
    "    # Calculate the number of batches\n",
    "    num_batches = int(np.ceil(len(trip_lengths) / batch_size))\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(18, 6))\n",
    "    ratios = []\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, len(trip_lengths))\n",
    "        batch_lengths = trip_lengths[start_idx:end_idx]\n",
    "\n",
    "        ax.bar(range(start_idx, end_idx), batch_lengths, color='blue', edgecolor='blue') # Plot the actual sequence lengths\n",
    "\n",
    "        max_length = max(batch_lengths)\n",
    "        blue_area = sum(batch_lengths)\n",
    "        orange_area = sum(max_length - length for length in batch_lengths)\n",
    "        ratio = orange_area / (blue_area + orange_area)\n",
    "        ratios.append(ratio)\n",
    "\n",
    "        # Highlight the padded parts\n",
    "        for j in range(start_idx, end_idx): ax.bar(j, max_length - batch_lengths[j - start_idx], bottom=batch_lengths[j - start_idx], color='orange', edgecolor='orange')\n",
    "\n",
    "        # Add vertical red dashed lines at batch boundaries\n",
    "        if i > 0: ax.axvline(x=start_idx, color='red', linestyle='--')\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Sequence Number')\n",
    "    ax.set_ylabel('Sequence Length (Number of Rows)')\n",
    "    ax.set_title('Diagram of Sequence Lengths with Padded Parts Highlighted')\n",
    "    handles = [plt.Rectangle((0,0),1,1,color=c,ec=\"k\") if c != \"red\" else plt.Line2D([0], [0], color=c, linestyle='--') for c in [\"blue\", \"orange\", \"red\"]]\n",
    "    labels = [\"sequence data\", \"padding\", \"batch boundaries\"]\n",
    "    ax.legend(handles, labels, loc=\"upper right\"); ax.grid(False); plt.show();\n",
    "\n",
    "    return ratios\n",
    "\n",
    "ratios_1 = plot_sequence_lengths(BATCH_SIZE, trip_lengths)\n",
    "ratios_2 = plot_sequence_lengths(BATCH_SIZE, sorted_trip_lengths)\n",
    "\n",
    "# Calculate and print the ratio between blue and orange areas for both diagrams\n",
    "print(f\"padding values (unsorted) = {np.mean(ratios_1)*100:.0f} %\")\n",
    "print(f\"padding values (sorted) = {np.mean(ratios_2)*100:.0f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT & TARGET SPECIFICATION ---------------------------------------------------\n",
    "# these signals are required for the physical Model calculation:\n",
    "base_signals = [\"signal_time\", \"hirestotalvehdist_cval_icuc\", \"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", \n",
    "\"hv_batpwr_cval_bms1\", \"emot_pwr_cval\",\"bs_roadincln_cval\", \"roadgrad_cval_pt\"]\n",
    "\n",
    "# these signals have to be dropped in order for appropriate training:\n",
    "columns_to_drop = [\"hv_batmomavldischrgen_cval_1\", \"latitude_cval_ippc\", \"longitude_cval_ippc\", \"signal_time\", \"hirestotalvehdist_cval_icuc\"]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "selection_1 = [\"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", 'roadgrad_cval_pt', \"vehweight_cval_pt\", \"accelpdlposn_cval\", \"bs_brk_cval\", \"elcomp_pwrcons_cval\",\n",
    "               \"epto_pwr_cval\", \"motortemperature_pti1\", \"powerstagetemperature_pti1\", 'airtempinsd_cval_hvac', 'brktempra_cval', 'selgr_rq_pt']\n",
    "selection_2 = [\"hirestotalvehdist_cval_icuc\", \"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", \"hv_batpwr_cval_bms1\", \"emot_pwr_cval\", \"roadgrad_cval_pt\"]\n",
    "selection_3 = [\"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", \"vehweight_cval_pt\"]\n",
    "\n",
    "# FEATURE SELECTION  --------------------------------------\n",
    "# ---------------------------------------------------------\n",
    "target_column = TARGETS\n",
    "input_columns = FEATURES\n",
    "input_columns = list(set(all_signals) - set(columns_to_drop) - set(target_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE NORMALIZATION/SCALING -----------------------------------------------------------------\n",
    "scaler = eval(SCALERS['feature_scaler'])\n",
    "target_scaler = eval(SCALERS['target_scaler'])\n",
    "\n",
    "# DATA SET SPLITTING -----------------------------------------------------------------------\n",
    "train_subset, val_subset, test_subset = random_split(files, TRAIN_VAL_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting Scalers: MaxAbsScaler, MinMaxScaler\n",
      "\t50% of the fitting done...\n",
      "Done. Create DataSets and DataLoaders...\n"
     ]
    }
   ],
   "source": [
    "# GENERATE DATALOADERS  ---------------------------------------------------------------\n",
    "'''\n",
    "Notes: for each of the three subsets, the following steps are performed:\n",
    "    1. Sort each subset by descending sequence lengths based on the obtained indices\n",
    "    2. Create a (custom) TripDataset object to select the input and target columns and apply the scalers. In case\n",
    "         of the training subset, the scalers will be fitted to the training set first.\n",
    "    3. Create a (custom) BatchDataset object of the corresponding TripDataset to handle the sequence padding before using \n",
    "            the DataLoader to create the batches.\n",
    "    4. The DataLoader will then be used to iterate over the batches during training. To use the integrated collate_fn function\n",
    "            of the DataLoader, the batch_size has to be set to 1. The actual batch size is then handled by the BatchDataset object.\n",
    "    5. The collate_fn that is integrated in the DataLoader will automatically handle the shuffling, padding and packing\n",
    "            of the sequences. The DataLoader will return a tuple of (packed_inputs, padded_targets, lengths), where\n",
    "            the packed_inputs are PackedSequence objects that can be efficiently processed by RNNs.\n",
    "            [Output tuple of types (<class 'torch.nn.utils.rnn.PackedSequence'>, <class 'torch.Tensor'>, <class 'torch.Tensor'>)]\n",
    "\n",
    "Note: shuffling will be done batchwise, however inside each batch the sequences  will remain sorted by length\n",
    "\n",
    "*Note: Because of the BatchDataset object in the train loader, \"batch_size\" refers to the number of batches to feed, not the \n",
    "number of samples in a batch. Also, the \"drop_last\" argument is useless due to this.\n",
    "'''\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "dataloader_settings = {\n",
    "    'batch_size': 1,                # see *Note above\n",
    "    'shuffle': True,                # shuffle the batches before each epoch\n",
    "    'collate_fn': collate_fn,       # include optional arguments\n",
    "    'num_workers': 4,               # number of workers\n",
    "    'pin_memory': False if DEVICE.type == 'cpu' else True\n",
    "}\n",
    "\n",
    "# TRAIN  ------------------------------------------------------------\n",
    "train_subset.indices = [i for i in indices_by_length if i in set(list(train_subset.indices))]\n",
    "train_dataset = TripDataset(train_subset, input_columns, target_column, scaler, target_scaler, fit=True)\n",
    "train_dataset_batches = create_batches(train_dataset, BATCH_SIZE)\n",
    "train_loader = DataLoader(train_dataset_batches, **dataloader_settings)\n",
    "\n",
    "# VAL --------------------------------------------------------------\n",
    "val_subset.indices = [i for i in indices_by_length if i in set(list(val_subset.indices))]\n",
    "val_dataset = TripDataset(val_subset, input_columns, target_column, scaler, target_scaler, fit=False)\n",
    "val_dataset_batches = create_batches(val_dataset, BATCH_SIZE)\n",
    "val_loader = DataLoader(val_dataset_batches, **dataloader_settings)\n",
    "\n",
    "# TEST -------------------------------------------------------------\n",
    "test_subset.indices = [i for i in indices_by_length if i in set(list(test_subset.indices))]\n",
    "test_dataset = TripDataset(test_subset, input_columns, target_column, scaler, target_scaler, fit=False)\n",
    "test_dataset_batches = create_batches(test_dataset, BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset_batches, **dataloader_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Train size:  9009694\t\t(Files: 2109)\n",
      "Val. size:   1666855\t\t(Files: 396)\n",
      "Test size:   499588\t\t(Files: 131) \n",
      " ------------------------------------------------------------\n",
      "first 3 train files: ['V13_T25.parquet', 'V16_T1629.parquet', 'V101_T37.parquet']\n"
     ]
    }
   ],
   "source": [
    "# Print the size of the datasets ----------------------------------\n",
    "print(f\"{'-'*60}\\nTrain size:  {len(train_dataset)}\\t\\t(Files: {len(train_subset)})\")\n",
    "print(f'Val. size:   {len(val_dataset)}\\t\\t(Files: {len(val_subset)})')\n",
    "print(f'Test size:   {len(test_dataset)}\\t\\t(Files: {len(test_subset)}) \\n {\"-\"*60}')\n",
    "if train_dataset.__len__() != sum(len(data) for data in train_dataset.data): print(\"Warning: Train Dataset Length Mismatch\")\n",
    "\n",
    "subset_files = {\"train\":    list(train_dataset.file_list),\n",
    "                \"val\":      list(val_dataset.file_list),\n",
    "                \"test\":     list(test_dataset.file_list)}\n",
    "print(f\"first 3 train files: {[os.path.basename(_) for _ in subset_files['train'][:3]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%skip\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "ratios = []\n",
    "for batch_idx, (padded_inputs, padded_targets, lengths) in enumerate(train_loader):\n",
    "    start_idx = batch_idx * BATCH_SIZE\n",
    "    end_idx = start_idx + len(lengths)\n",
    "    \n",
    "    # Plot the actual sequence lengths\n",
    "    ax.bar(range(start_idx, end_idx), lengths, color='blue', edgecolor='blue')\n",
    "    \n",
    "    # Highlight the padded parts\n",
    "    max_length = max(lengths)\n",
    "    blue_area = sum(lengths)\n",
    "    orange_area = sum(max_length - length for length in lengths)\n",
    "    ratio = orange_area / (blue_area + orange_area)\n",
    "    ratios.append(ratio)\n",
    "\n",
    "    for j in range(start_idx, end_idx): ax.bar(j, max_length - lengths[j - start_idx], bottom=lengths[j - start_idx], color='orange', edgecolor='orange')\n",
    "\n",
    "    # Add vertical red dashed lines at batch boundaries\n",
    "    if batch_idx > 0: ax.axvline(x=start_idx, color='red', linestyle='--')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Sequence Number')\n",
    "ax.set_ylabel('Sequence Length (Number of Rows)')\n",
    "ax.set_title('Diagram of Sequence Lengths with Padded Parts Highlighted')\n",
    "handles = [plt.Rectangle((0,0),1,1,color=c,ec=\"k\") if c != \"red\" else plt.Line2D([0], [0], color=c, linestyle='--') for c in [\"blue\", \"orange\", \"red\"]]\n",
    "labels = [\"sequence data\", \"padding\", \"batch boundaries\"]\n",
    "ax.legend(handles, labels, loc=\"upper right\"); ax.grid(False); plt.show(); \n",
    "\n",
    "# Calculate and print the ratio between blue and orange areas\n",
    "print(f\"padding values = {np.mean(ratios)*100:.0f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of packed_inputs: <class 'torch.nn.utils.rnn.PackedSequence'>, Type of packed_inputs.data: <class 'torch.Tensor'>, Type of packed_inputs.batch_sizes: <class 'torch.Tensor'>\n",
      "Type of padded_targets: <class 'torch.Tensor'>, Type of lengths: <class 'torch.Tensor'>\n",
      "Shape of packed_inputs.data: torch.Size([23041, 40])\n",
      "Length of packed_inputs.batch_sizes: 1445\n",
      "Lengths: tensor([1445, 1445, 1444, 1444, 1444, 1443, 1440, 1440, 1439, 1439, 1439, 1438,\n",
      "        1437, 1436, 1434, 1434])\n",
      "tensor(23041)\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the train_loader and print an example of a PackedSequence\n",
    "for batch_idx, (packed_inputs, padded_targets, lengths) in enumerate(train_loader):\n",
    "    #print(f\"Packed Inputs (Batch {batch_idx}):\\n{packed_inputs}\")\n",
    "    print(f\"Type of packed_inputs: {type(packed_inputs)}, Type of packed_inputs.data: {type(packed_inputs.data)}, Type of packed_inputs.batch_sizes: {type(packed_inputs.batch_sizes)}\")\n",
    "    print(f\"Type of padded_targets: {type(padded_targets)}, Type of lengths: {type(lengths)}\")\n",
    "    print(f\"Shape of packed_inputs.data: {packed_inputs.data.shape}\")\n",
    "    print(f\"Length of packed_inputs.batch_sizes: {len(packed_inputs.batch_sizes)}\")\n",
    "    print(f\"Lengths: {lengths}\")\n",
    "    print(sum(lengths))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM NETWORK -----------------------------------------------------------------------\n",
    "class LSTM1_packed(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, seq_length, dropout, device=DEVICE):\n",
    "        super(LSTM1_packed, self).__init__()\n",
    "\n",
    "        self.input_size = input_size    # input size\n",
    "        self.hidden_size = hidden_size  # hidden state\n",
    "        self.num_layers = num_layers    # number of layers\n",
    "        self.dropout = dropout\n",
    "        self.seq_length = seq_length    # sequence length\n",
    "\n",
    "        # LSTM CELL --------------------------------\n",
    "        self.lstm = nn.LSTM(\n",
    "            self.input_size,            # The number of expected features in the input x\n",
    "            self.hidden_size,           # The number of features in the hidden state h\n",
    "            self.num_layers,            # Number of recurrent layers for stacked LSTMs. Default: 1\n",
    "            batch_first=True,           # If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Default: False\n",
    "            bias=True,                  # If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "            dropout=self.dropout,       # usually: [0.2 - 0.5], introduces a Dropout layer on the outputs of each LSTM layer except the last layer, (dropout probability). Default: 0\n",
    "            bidirectional=False,        # If True, becomes a bidirectional LSTM. Default: False\n",
    "            proj_size=0,                # If > 0, will use LSTM with projections of corresponding size. Default: 0\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_test = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, packed_input, batch_size=None):\n",
    "        # Propagate input through LSTM\n",
    "        packed_out, _ = self.lstm(packed_input)\n",
    "        #print(f\"LSTM: Output after LSTM: {packed_out.data.shape}, {type(packed_out)}\")\n",
    "\n",
    "        # Unpack the output\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        #print(f\"             after packing: {out.shape}, {type(out)}\")\n",
    "\n",
    "        # Output layers\n",
    "        out = self.relu(out)  # relu\n",
    "        #print(f\"             after relu: {out.shape}, {type(out)}\")\n",
    "\n",
    "        out = self.fc_test(out)  # Use all outputs for prediction\n",
    "        #print(f\"             after fc: {out.shape}, {type(out)}\")\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      " LSTM1_packed(\n",
      "  (lstm): LSTM(40, 400, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (relu): ReLU()\n",
      "  (fc_test): Linear(in_features=400, out_features=1, bias=True)\n",
      ")\n",
      "------------------------------------------------------------\n",
      "Model state_dict:\n",
      "lstm.weight_ih_l0:\t torch.Size([1600, 40])\n",
      "lstm.weight_hh_l0:\t torch.Size([1600, 400])\n",
      "lstm.bias_ih_l0:\t torch.Size([1600])\n",
      "lstm.bias_hh_l0:\t torch.Size([1600])\n",
      "lstm.weight_ih_l1:\t torch.Size([1600, 400])\n",
      "lstm.weight_hh_l1:\t torch.Size([1600, 400])\n",
      "lstm.bias_ih_l1:\t torch.Size([1600])\n",
      "lstm.bias_hh_l1:\t torch.Size([1600])\n",
      "fc_test.weight:\t torch.Size([1, 400])\n",
      "fc_test.bias:\t torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# MODEL CONFIGURATION -----------------------------------------------------------------------\n",
    "\n",
    "# LAYERS --------------------------------\n",
    "input_size = len(input_columns)     # expected features in the input x\n",
    "hidden_size = HIDDEN_SIZE           # features in the hidden state h\n",
    "num_layers = NUM_LAYERS             # recurrent layers for stacked LSTMs. Default: 1\n",
    "num_classes = 1                     # output classes (=1 for regression)\n",
    "\n",
    "# INSTANTIATE MODEL --------------------\n",
    "model = LSTM1_packed(input_size, HIDDEN_SIZE, NUM_LAYERS, SEQ_LENGTH, DROPOUT).to(DEVICE)\n",
    "print(f\"{'-'*60}\\n\", model)\n",
    "print(f\"{'-'*60}\\nModel state_dict:\")\n",
    "for param_tensor in model.state_dict(): print(f\"{param_tensor}:\\t {model.state_dict()[param_tensor].size()}\") \n",
    "# --> Note torch.Size([4*hidden_size, input_size]) for LSTM weights because of i,o,f,g params concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.003\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAINING CONFIGURATION -----------------------------------------------------------------------\n",
    "\n",
    "# OPTIMIZER -----------------------------\n",
    "# common optimizers: ['torch.optim.Adam', 'torch.optim.SGD', 'torch.optim.RMSprop']\n",
    "if 'OPTIMIZER' in globals(): optimizer = eval(OPTIMIZER)\n",
    "else: optimizer = torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE,\n",
    "        weight_decay = 1e-4      # weight decay coefficient (default: 1e-2)\n",
    "        #betas = (0.9, 0.95),    # coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "        #eps = 1e-8,             # term added to the denominator to improve numerical stability (default: 1e-8)\n",
    ")\n",
    "\n",
    "# LR SCHEDULER -----------------------------\n",
    "if 'LRSCHEDULER' in globals(): scheduler = eval(LRSCHEDULER)\n",
    "else: scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience = 2, factor = 0.5, min_lr = 1e-6)\n",
    "\n",
    "# LOSS FUNCTION ----------------------------------------------------------------\n",
    "def loss_fn(model_output, target):\n",
    "    loss = F.mse_loss(model_output, target) # mean-squared error for regression\n",
    "    return loss\n",
    "\n",
    "# or define criterion function:\n",
    "criterion_list = [nn.MSELoss(), nn.L1Loss(), nn.SmoothL1Loss(), nn.HuberLoss(), MASE()]\n",
    "\n",
    "if 'CRITERION' in globals(): criterion = eval(CRITERION)\n",
    "else: criterion = nn.SmoothL1Loss()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# print Model and Optimizer state_dicts\n",
    "print(f\"{'-'*60}\\n{optimizer}\\n{'-'*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "######################## \n",
    "# ------------->  TO BE INCLUDED IN train_model.py'''\n",
    "\n",
    "if torch.cuda.is_available(): from torch.amp import GradScaler, autocast\n",
    "#############################################################################################################\n",
    "# -----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "class Trainer_packed():\n",
    "\n",
    "    def __init__(self, model: nn.Module, optimizer: torch.optim.Optimizer, loss_fn: nn.Module, \n",
    "                 train_loader: DataLoader, num_epochs: int, device: torch.device, \n",
    "                 is_notebook: bool = False, val_loader: DataLoader = None, test_loader: DataLoader = None, \n",
    "                 scheduler: torch.optim.lr_scheduler._LRScheduler = None, state: dict = None, \n",
    "                 use_mixed_precision: bool = False, clip_value = None):\n",
    "\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.train_loader = train_loader\n",
    "        self.num_epochs = num_epochs\n",
    "        self.device = device\n",
    "        self.is_notebook = is_notebook\n",
    "        self.val_loader = val_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.scheduler = scheduler\n",
    "        self.state = state\n",
    "        self.use_mixed_precision = use_mixed_precision if torch.cuda.is_available() else False\n",
    "        if self.use_mixed_precision: self.scaler = GradScaler('cuda')  # Initialize GradScaler\n",
    "        self.clip_value = clip_value\n",
    "\n",
    "    # EVALUATION ROUTINE DEFINITION -----------------------------------------------------------------\n",
    "    def evaluate_model(self) -> tuple:\n",
    "        if self.test_loader is None: print(\"No test data available.\"); return None\n",
    "        else:\n",
    "            self.model.eval()  # Set model to evaluation mode\n",
    "            test_loss = 0.0\n",
    "            all_outputs, all_targets, all_original_lengths = [], [], []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets, original_lengths in self.test_loader:\n",
    "                    inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                    # -------------------------------------\n",
    "                    if self.use_mixed_precision:\n",
    "                        with autocast(device_type='cuda'):\n",
    "                            outputs = self.model(inputs)  # inputs are packed, outputs are not ! --> see forward method in model\n",
    "                            outputs = outputs.squeeze()\n",
    "                            if outputs.dim() > 1:\n",
    "                                mask = torch.arange(outputs.size(1))[None, :] < original_lengths[:, None]\n",
    "                            else:\n",
    "                                print(\"shape: \", outputs.shape), print(outputs.size(0), outputs.size(1))\n",
    "                            outputs_masked = outputs[mask]\n",
    "                            targets_masked = targets[mask]\n",
    "                            loss = self.loss_fn(outputs_masked.squeeze(), targets_masked).mean()\n",
    "                            test_loss += loss.item()\n",
    "                    else:\n",
    "                        outputs = self.model(inputs)  # inputs are packed, outputs are not ! --> see forward method in model\n",
    "                        outputs = outputs.squeeze()\n",
    "                        mask = torch.arange(outputs.size(1))[None, :] < original_lengths[:, None]\n",
    "                        outputs_masked = outputs[mask]\n",
    "                        targets_masked = targets[mask]\n",
    "                        loss = self.loss_fn(outputs_masked.squeeze(), targets_masked).mean()\n",
    "                        test_loss += loss.item()\n",
    "                    # -------------------------------------\n",
    "                    # Detach tensors from the computation graph and move them to CPU\n",
    "                    outputs = outputs.detach().cpu().numpy()\n",
    "                    targets = targets.detach().cpu().numpy()\n",
    "                    # Remove the padded endings of each sequence and restore their original lengths\n",
    "                    unpadded_outputs = [output[:length] for output, length in zip(outputs, original_lengths)]\n",
    "                    unpadded_targets = [target[:length] for target, length in zip(targets, original_lengths)]\n",
    "                    # -------------------------------------\n",
    "                    # Collect all outputs and targets\n",
    "                    all_outputs.append(unpadded_outputs)\n",
    "                    all_targets.append(unpadded_targets)\n",
    "                    all_original_lengths.append(original_lengths.detach().cpu().numpy())\n",
    "            # -------------------------------------\n",
    "            test_loss /= len(self.test_loader)  # Calculate average test loss\n",
    "            return test_loss, all_outputs, all_targets, all_original_lengths\n",
    "\n",
    "    # VALIDATION ROUTINE DEFINITION -----------------------------------------------------------------\n",
    "    def validate_model(self, epoch: int) -> float:\n",
    "        if self.val_loader is None: print(\"No validation data available.\"); return None\n",
    "        else:\n",
    "            self.model.eval()  # Set model to evaluation mode\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():  # Disable gradient calculation\n",
    "                for inputs, targets, original_lengths in self.val_loader:\n",
    "                    inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                    # -------------------------------------\n",
    "                    if self.use_mixed_precision:\n",
    "                        with autocast(device_type='cuda'):\n",
    "                            outputs = self.model(inputs)  # inputs are packed, outputs are not ! --> see forward method in model\n",
    "                            outputs = outputs.squeeze()\n",
    "                            mask = torch.arange(outputs.size(1))[None, :] < original_lengths[:, None]\n",
    "                            outputs = outputs[mask]\n",
    "                            targets = targets[mask]\n",
    "                            loss = self.loss_fn(outputs.squeeze(), targets).mean()\n",
    "                            val_loss += loss.item()\n",
    "                    else:\n",
    "                        outputs = self.model(inputs)  # inputs are packed, outputs are not ! --> see forward method in model\n",
    "                        outputs = outputs.squeeze()\n",
    "                        mask = torch.arange(outputs.size(1))[None, :] < original_lengths[:, None]\n",
    "                        outputs = outputs[mask]\n",
    "                        targets = targets[mask]\n",
    "                        loss = self.loss_fn(outputs.squeeze(), targets).mean()\n",
    "                        val_loss += loss.item()\n",
    "            # -------------------------------------          \n",
    "            val_loss /= len(self.val_loader)  # Calculate average validation loss\n",
    "            if self.scheduler:\n",
    "                lr1 = self.scheduler.get_last_lr()[0]\n",
    "                self.scheduler.step(val_loss)  # Adjust learning rate based on validation loss\n",
    "                lr2 = self.scheduler.get_last_lr()[0]\n",
    "                self.lr_history.append(lr2)\n",
    "                if lr1 != lr2: print(f\"Learning rate updated after epoch {epoch}: {lr1} -> {lr2}\")\n",
    "            return val_loss\n",
    "\n",
    "    # TRAINING ROUTINE DEFINITION -----------------------------------------------------------------\n",
    "    def train_model(self) -> dict:\n",
    "       # output info on training process\n",
    "        print(f\"{'-'*60}\\nTraining Started.\\tProcess ID: {os.getpid()} \\n{'-'*60}\\n\"\n",
    "              f\"Model: {self.model.__class__.__name__}\\t\\tParameters on device: {str(next(self.model.parameters()).device).upper()}\\n{'-'*60}\\n\"\n",
    "              f\"Train/Batch size:\\t{len(self.train_loader.dataset)} / {self.train_loader.batch_size}\\n\"\n",
    "              f\"Loss:\\t\\t\\t{self.loss_fn}\\nOptimizer:\\t\\t{self.optimizer.__class__.__name__}\\nLR:\\t\\t\\t\"\n",
    "              f\"{self.optimizer.param_groups[0]['lr']}\\nWeight Decay:\\t\\t{self.optimizer.param_groups[0]['weight_decay']}\\n{'-'*60}\")\n",
    "        \n",
    "        # Load state dict if provided\n",
    "        start_epoch = 1\n",
    "        if self.state:\n",
    "            self.model.load_state_dict(self.state['model_state_dict'])\n",
    "            self.optimizer.load_state_dict(self.state['optimizer_state_dict'])\n",
    "            self.train_losses = self.state['train_losses']\n",
    "            self.train_losses_per_iter = self.state['train_losses_per_iter']\n",
    "            self.lr_history = self.state['lr_history']\n",
    "            self.val_losses = self.state['val_losses']\n",
    "            self.training_table = self.state['training_table']\n",
    "            start_epoch = self.state['epoch'] + 1\n",
    "        else:\n",
    "            self.train_losses = [] \n",
    "            self.train_losses_per_iter = []\n",
    "            self.val_losses = []  \n",
    "            self.training_table = []  \n",
    "            self.lr_history = []\n",
    "            if self.is_notebook: display_html(HTML(initialize_table()))\n",
    "\n",
    "        # TRAINING LOOP:\n",
    "        start_time = time.perf_counter()\n",
    "        for epoch in range(start_epoch, self.num_epochs + 1):\n",
    "            self.model.train()  # set model to training mode\n",
    "            running_loss = 0.0\n",
    "            num_iterations = math.ceil(len(self.train_loader.dataset) / self.train_loader.batch_size)\n",
    "            header_printed = False\n",
    "\n",
    "            tqdm_version = tqdm_nb if self.is_notebook else tqdm\n",
    "            with tqdm_version(enumerate(self.train_loader, 1), unit=\"batch\", total=num_iterations, leave=False) as tepoch:\n",
    "                for iter, (inputs, targets, original_lengths) in tepoch:  # ----> note: (packed_inputs, padded_targets, lengths)\n",
    "                    tepoch.set_description(f\"Epoch {epoch}/{self.num_epochs}\")\n",
    "                    print(\"Dataloader: \", type(inputs), type(targets), type(original_lengths))\n",
    "                    print(f\"Shape of inputs: {inputs.data.shape}, {type(inputs)}\")\n",
    "                    print(f\"Shape of targets: {targets.shape}, {type(targets)}\")\n",
    "                    print(f\"Shape of original_lengths: {original_lengths.shape}, {type(original_lengths)}\")\n",
    "                    # -------------------------------------------------------------\n",
    "                    # Move data to the GPU\n",
    "                    inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "\n",
    "                    # zero gradients -> forward pass -> obtain loss function -> apply backpropagation -> update weights:\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                    # A) use mixed precision calculation ------------------------------------------------------------------------------\n",
    "                    if self.use_mixed_precision:\n",
    "                        with autocast(device_type='cuda'):  # Enable autocast for mixed precision training\n",
    "                            outputs = self.model(inputs)   # inputs are packed, outputs are not ! --> see forward method in model\n",
    "                            outputs = outputs.squeeze()\n",
    "                            mask = torch.arange(outputs.size(1))[None, :] < original_lengths[:, None]\n",
    "                            outputs = outputs[mask]\n",
    "                            targets = targets[mask]\n",
    "                            loss = self.loss_fn(outputs.squeeze(), targets).mean()\n",
    "                        self.scaler.scale(loss).backward()  # Scale the loss and perform backward pass\n",
    "                        if self.clip_value is not None:\n",
    "                            nn.utils.clip_grad_value_(self.model.parameters(), clip_value=self.clip_value)  # optional: Gradient Value Clipping\n",
    "                        self.scaler.step(self.optimizer)  # Update model parameters\n",
    "                        self.scaler.update()  # Update the scale for next iteration\n",
    "\n",
    "                    # B) Normal precision calculation ------------------------------------------------------------------------------\n",
    "                    else:\n",
    "                        print(\"Forwarding.\")\n",
    "                        outputs = self.model(inputs)  # inputs are packed, outputs are not ! --> see forward method in model\n",
    "                        # -------------------------------------\n",
    "                        print(f\"Shape of outputs: {outputs.shape}, {type(outputs)}\")\n",
    "                        outputs = outputs.squeeze()\n",
    "                        mask = torch.arange(outputs.size(1))[None, :] < original_lengths[:, None]\n",
    "\n",
    "                        print(f\"Shape of mask: {mask.shape}, {type(mask)}\")\n",
    "                        print(f\"Masking.\")\n",
    "                        outputs = outputs[mask]\n",
    "                        targets = targets[mask]\n",
    "                        # -------------------------------------\n",
    "                        print(f\"Shape of outputs after mask: {outputs.shape}, {type(outputs)}\")\n",
    "                        print(f\"Shape of targets after mask: {targets.shape}, {type(targets)}\")\n",
    "\n",
    "                        loss = self.loss_fn(outputs.squeeze(), targets).mean()\n",
    "                        loss.backward()\n",
    "                        if self.clip_value is not None:\n",
    "                            nn.utils.clip_grad_value_(self.model.parameters(), clip_value=self.clip_value)  # optional: Gradient Value Clipping\n",
    "                        self.optimizer.step()\n",
    "\n",
    "                    # -------------------------------------------------------------\n",
    "                    # Update the performance table\n",
    "                    if iter % (num_iterations // 4) == 0 and iter != num_iterations // 4 * 4:\n",
    "                        add_row(self.training_table, f\" \", f\"{iter}\", f\"{loss.item():.6f}\", \" \")\n",
    "                        if self.is_notebook:\n",
    "                            display_html(HTML(f\"\"\"<script>addRow(\"\", \"{iter}\", \"{loss.item():.6f}\", \"\");</script>\"\"\"))\n",
    "                        else:\n",
    "                            print_row(self.training_table)\n",
    "                    elif iter == 1:\n",
    "                        add_row(self.training_table, f\"{epoch}/{self.num_epochs}\", f\"{iter}/{num_iterations}\", f\"{loss.item():.6f}\", \" \")\n",
    "                        if self.is_notebook:\n",
    "                            display_html(HTML(f\"\"\"<script>addRow(\"<b>{epoch}/{self.num_epochs}\", \"{iter}/{num_iterations}\", \"{loss.item():.6f}\", \"\");</script>\"\"\"))\n",
    "                        else:\n",
    "                            print_row(self.training_table)\n",
    "\n",
    "                    # -------------------------------------------------------------\n",
    "                    # Update running loss and progress bar\n",
    "                    self.train_losses_per_iter.append(loss.item())\n",
    "                    running_loss += loss.item()  # accumulate loss for epoch\n",
    "                    tepoch.set_postfix(loss=loss.item()); tepoch.update(1)\n",
    "\n",
    "            # Calculate average training loss for the epoch\n",
    "            avg_train_loss = running_loss / len(self.train_loader)\n",
    "            self.train_losses.append(avg_train_loss)\n",
    "\n",
    "            # Update the performance table\n",
    "            add_row(self.training_table, f\" \", f\"{iter}\", f\"{loss.item():.6f}\", f\"{avg_train_loss:.6f}\")\n",
    "            if self.is_notebook:\n",
    "                display_html(HTML(f\"\"\"<script>addRow(\"\", \"{iter}\", \"{loss.item():.6f}\", \"<b>{avg_train_loss:.6f}\");</script>\"\"\"))\n",
    "            else:\n",
    "                print_row(self.training_table)\n",
    "\n",
    "            # VALIDATION\n",
    "            if self.val_loader:\n",
    "                val_loss = self.validate_model(epoch)\n",
    "                self.val_losses.append(val_loss)\n",
    "                # Update the performance table\n",
    "                add_row(self.training_table, f\"Val\", f\"Validation Loss:\", f\"{val_loss:.6f}\", \"\")\n",
    "                if self.is_notebook:\n",
    "                    display_html(HTML(f\"\"\"<script>addRow(\"<b>Val\", \"Validation Loss:\", \"<b>{val_loss:.6f}\", \"\");</script>\"\"\"))\n",
    "                else:\n",
    "                    print_row(self.training_table)\n",
    "\n",
    "        elapsed_time = round(time.perf_counter() - start_time)\n",
    "        print(f\"{'-'*60}\\nTraining Completed.\\tExecution Time: {time.strftime('%H:%M:%S', time.gmtime(elapsed_time))}\\n{'-'*60}\\n\")\n",
    "        return {\n",
    "            # model and optimizer states\n",
    "            \"model\": self.model,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "            # training performance\n",
    "            \"training_table\": self.training_table,\n",
    "            \"train_losses\": self.train_losses,\n",
    "            \"train_losses_per_iter\": list(self.train_losses_per_iter),\n",
    "            \"val_losses\": self.val_losses,\n",
    "            'lr_history': self.lr_history,\n",
    "            # settings and meta data\n",
    "            \"loss_fn\": self.loss_fn,\n",
    "            \"epoch\": epoch,\n",
    "            \"elapsed_train_time\": elapsed_time\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Training Started.\tProcess ID: 44051 \n",
      "------------------------------------------------------------\n",
      "Model: LSTM1_packed\t\tParameters on device: CUDA:0\n",
      "------------------------------------------------------------\n",
      "Train/Batch size:\t132 / 1\n",
      "Loss:\t\t\tSmoothL1Loss()\n",
      "Optimizer:\t\tAdamW\n",
      "LR:\t\t\t0.003\n",
      "Weight Decay:\t\t0.0001\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"scrollable_table\" style=\"height: 300px; overflow-y: scroll;\">\n",
       "    <table id=\"training_table\" style=\"width:60%; border-collapse: collapse;\">\n",
       "        <thead style=\"position: sticky; top: 0; z-index: 1;\">\n",
       "            <tr>\n",
       "                <th style=\"font-weight:bold; width:15%; text-align:left; padding: 10px; background-color: #404040;\">Epoch</th>\n",
       "                <th style=\"font-weight:bold; width:25%; text-align:left; padding: 10px; background-color: #404040;\">Iteration</th>\n",
       "                <th style=\"font-weight:bold; width:30%; text-align:left; padding: 10px; background-color: #404040;\">Batch Loss</th>\n",
       "                <th style=\"font-weight:bold; width:30%; text-align:left; padding: 10px; background-color: #404040;\">Train Loss</th>\n",
       "            </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        </tbody>\n",
       "    </table>\n",
       "    <script>\n",
       "        function addRow(epoch, step, loss, running_loss) {\n",
       "            var table = document.getElementById(\"training_table\").getElementsByTagName('tbody')[0];\n",
       "            var row = table.insertRow(-1);\n",
       "            var cell1 = row.insertCell(0);\n",
       "            var cell2 = row.insertCell(1);\n",
       "            var cell3 = row.insertCell(2);\n",
       "            var cell4 = row.insertCell(3);\n",
       "            cell1.style.textAlign = \"left\";\n",
       "            cell2.style.textAlign = \"left\";\n",
       "            cell3.style.textAlign = \"left\";\n",
       "            cell4.style.textAlign = \"left\";\n",
       "            cell1.innerHTML = epoch;\n",
       "            cell2.innerHTML = step;\n",
       "            cell3.innerHTML = loss;\n",
       "            cell4.innerHTML = running_loss;\n",
       "            var scrollableDiv = document.getElementById(\"scrollable_table\");\n",
       "            scrollableDiv.scrollTop = scrollableDiv.scrollHeight;\n",
       "        }\n",
       "    </script>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b02bcb89263400ebfc3c0174aaa46f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28765, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1806]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>1/10\", \"1/132\", \"0.220917\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([127006, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8024]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23224, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1456]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27657, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1737]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60126, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3782]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([114894, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7256]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([100459, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6319]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19640, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1233]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([48629, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3063]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([39683, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2506]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([194202, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 12550]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1266]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([77965, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4919]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19855, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1245]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([105821, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6700]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([71198, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4491]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37101, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2336]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([32859, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2079]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29080, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1825]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([52087, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3316]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([111774, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7066]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21766, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1364]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([63572, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3997]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38845, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2449]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21079, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1322]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([206589, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 13221]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([153399, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9662]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([88034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5573]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60787, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3821]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22598, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1421]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([155172, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9735]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24184, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1520]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2414]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"33\", \"0.029009\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19443, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1219]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29619, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1868]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21569, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1355]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27057, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1698]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35015, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2213]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46121, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2902]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31078, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1966]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([42111, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2656]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25580, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1610]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([90615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5754]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([74557, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([58310, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3672]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([135540, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8564]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22381, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1405]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([44359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2798]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([55730, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3515]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24734, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1553]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([176196, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11287]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1501]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1344]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([54776, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3451]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([36426, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2297]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([102908, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6510]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([62666, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([86185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5423]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([140382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8817]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23041, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1445]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([53615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3388]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([59191, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3729]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([76084, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4801]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1576]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23484, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1476]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([169324, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10725]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"66\", \"0.020162\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([69665, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4393]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26362, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1659]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27925, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1756]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30494, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1920]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22166, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1391]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([45338, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2857]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22835, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1433]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([15677, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([13, 1210]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([13]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35748, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2252]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([247273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 20843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([117810, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7458]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([138031, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8683]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([108763, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23709, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1489]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([92755, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5829]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([47705, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3021]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([129543, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8188]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([145257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9127]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([160022, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10158]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([164072, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10376]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20000, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1255]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20753, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1301]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31892, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2018]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26702, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1675]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([83813, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5323]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([80948, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5168]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25316, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1587]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([68235, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4312]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([65586, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4154]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([124749, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7875]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([94389, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5980]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28391, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1783]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([61685, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"99\", \"0.004176\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([57109, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([184917, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46794, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([49638, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3124]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([121122, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7702]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([43273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2732]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([50686, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3205]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([150877, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9504]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([64497, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4053]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27309, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([149016, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9351]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([72961, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4598]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([219507, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 14285]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([98029, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6216]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([40359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2548]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20347, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1276]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1537]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21957, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1379]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([67090, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4226]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30093, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1889]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([132343, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8357]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([33615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2122]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([156920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9883]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20520, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1292]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([96546, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6067]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([147175, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9261]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([34257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2159]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1631]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37836, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2385]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([41334, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21250, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1332]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20881, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1309]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([142371, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8972]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"132\", \"0.007663\", \"<b>0.031729\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>Val\", \"Validation Loss:\", \"<b>0.004420\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec4c4255e5b40bd98fc76774cd4b3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([41334, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>2/10\", \"1/132\", \"0.003611\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([47705, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3021]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37836, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2385]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([140382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8817]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([72961, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4598]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([76084, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4801]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28391, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1783]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([65586, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4154]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([90615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5754]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([32859, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2079]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21569, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1355]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([164072, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10376]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([219507, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 14285]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([184917, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27309, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23709, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1489]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21957, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1379]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38845, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2449]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2414]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27657, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1737]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21250, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1332]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([42111, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2656]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27057, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1698]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20881, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1309]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([50686, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3205]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([147175, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9261]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([83813, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5323]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21079, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1322]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([67090, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4226]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60126, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3782]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([132343, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8357]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([160022, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10158]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([206589, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 13221]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"33\", \"0.002203\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([63572, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3997]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22835, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1433]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26702, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1675]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([58310, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3672]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([156920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9883]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26362, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1659]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([53615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3388]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([59191, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3729]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30093, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1889]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([155172, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9735]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([74557, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1501]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60787, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3821]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1266]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([71198, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4491]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24734, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1553]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([61685, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([88034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5573]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([145257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9127]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([117810, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7458]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([149016, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9351]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23484, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1476]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([135540, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8564]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([98029, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6216]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28765, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1806]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([57109, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1631]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20347, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1276]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([52087, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3316]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([92755, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5829]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([150877, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9504]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1576]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25580, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1610]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"66\", \"0.001642\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46121, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2902]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([105821, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6700]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24184, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1520]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20000, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1255]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([43273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2732]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22381, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1405]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([111774, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7066]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([68235, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4312]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([86185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5423]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([124749, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7875]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19640, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1233]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35015, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2213]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([247273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 20843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35748, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2252]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([94389, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5980]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19443, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1219]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([100459, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6319]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30494, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1920]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([36426, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2297]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([108763, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27925, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1756]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29619, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1868]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20520, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1292]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([194202, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 12550]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20753, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1301]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23224, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1456]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([69665, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4393]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46794, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([96546, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6067]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([49638, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3124]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([15677, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([13, 1210]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([13]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31078, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1966]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([62666, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"99\", \"0.000899\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([45338, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2857]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([40359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2548]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([44359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2798]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([129543, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8188]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([138031, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8683]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([114894, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7256]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([39683, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2506]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22598, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1421]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([77965, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4919]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19855, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1245]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([127006, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8024]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([80948, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5168]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([64497, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4053]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([34257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2159]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([169324, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10725]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22166, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1391]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1344]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([102908, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6510]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29080, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1825]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25316, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1587]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37101, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2336]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([142371, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8972]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21766, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1364]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([48629, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3063]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([54776, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3451]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([153399, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9662]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([55730, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3515]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23041, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1445]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([33615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2122]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1537]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([121122, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7702]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31892, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2018]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([176196, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11287]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"132\", \"0.000601\", \"<b>0.002669\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>Val\", \"Validation Loss:\", \"<b>0.000583\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd180d9352a4bde848b39c008d9a312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27925, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1756]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>3/10\", \"1/132\", \"0.000576\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([61685, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37836, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2385]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35748, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2252]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28391, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1783]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22381, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1405]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24184, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1520]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([33615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2122]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35015, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2213]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([68235, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4312]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([36426, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2297]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([164072, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10376]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46121, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2902]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23484, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1476]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([155172, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9735]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20753, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1301]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60126, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3782]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([194202, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 12550]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1266]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([86185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5423]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([176196, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11287]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([149016, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9351]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([45338, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2857]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([88034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5573]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([41334, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25580, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1610]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20000, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1255]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([142371, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8972]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24734, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1553]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([15677, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([13, 1210]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([13]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([52087, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3316]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([147175, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9261]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([98029, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6216]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"33\", \"0.001307\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([94389, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5980]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21569, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1355]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60787, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3821]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([54776, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3451]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([49638, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3124]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([62666, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([156920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9883]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([59191, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3729]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([83813, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5323]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19443, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1219]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23041, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1445]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([105821, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6700]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([92755, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5829]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19855, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1245]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([129543, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8188]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([135540, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8564]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([150877, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9504]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20520, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1292]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23224, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1456]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([55730, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3515]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([77965, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4919]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1576]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([58310, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3672]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([117810, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7458]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27657, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1737]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2414]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([100459, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6319]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([44359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2798]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26702, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1675]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([57109, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([76084, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4801]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29619, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1868]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29080, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1825]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"66\", \"0.000592\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25316, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1587]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([124749, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7875]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([42111, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2656]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([206589, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 13221]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20347, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1276]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([219507, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 14285]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([169324, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10725]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([96546, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6067]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([145257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9127]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([138031, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8683]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37101, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2336]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28765, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1806]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20881, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1309]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30093, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1889]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([47705, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3021]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([34257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2159]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([63572, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3997]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1631]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([108763, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([160022, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10158]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([65586, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4154]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27309, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31892, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2018]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38845, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2449]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([43273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2732]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([39683, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2506]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22835, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1433]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([153399, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9662]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22598, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1421]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27057, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1698]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([72961, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4598]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30494, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1920]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([71198, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4491]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"99\", \"0.000544\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1501]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([132343, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8357]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([127006, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8024]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([40359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2548]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([121122, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7702]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22166, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1391]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19640, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1233]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([140382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8817]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21079, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1322]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([247273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 20843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23709, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1489]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([69665, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4393]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([184917, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26362, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1659]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([64497, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4053]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([111774, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7066]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([48629, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3063]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21766, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1364]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([80948, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5168]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([114894, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7256]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([90615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5754]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21250, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1332]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31078, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1966]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21957, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1379]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([74557, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([53615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3388]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46794, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([50686, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3205]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([102908, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6510]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([32859, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2079]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([67090, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4226]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1344]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1537]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"132\", \"0.000755\", \"<b>0.000742\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>Val\", \"Validation Loss:\", \"<b>0.000495\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a04c44a37a74f5680cdc9e0cdebb201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20520, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1292]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>4/10\", \"1/132\", \"0.000578\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28765, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1806]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([194202, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 12550]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([71198, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4491]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([135540, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8564]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27925, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1756]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([59191, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3729]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21766, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1364]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([92755, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5829]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([80948, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5168]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([49638, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3124]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([42111, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2656]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22835, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1433]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([149016, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9351]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25316, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1587]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27057, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1698]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29619, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1868]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([176196, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11287]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31892, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2018]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26362, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1659]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28391, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1783]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([61685, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([155172, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9735]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([64497, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4053]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46121, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2902]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([129543, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8188]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([132343, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8357]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21957, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1379]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([247273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 20843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([184917, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23041, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1445]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([47705, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3021]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([57109, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"33\", \"0.000512\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([140382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8817]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([219507, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 14285]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([206589, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 13221]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([117810, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7458]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([105821, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6700]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21569, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1355]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1344]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21079, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1322]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([83813, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5323]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([72961, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4598]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24184, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1520]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([40359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2548]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([145257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9127]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31078, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1966]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23709, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1489]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60126, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3782]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([88034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5573]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27657, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1737]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([67090, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4226]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([127006, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8024]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22598, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1421]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35015, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2213]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22166, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1391]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60787, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3821]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1576]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([150877, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9504]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([52087, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3316]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([62666, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([44359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2798]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19443, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1219]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23224, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1456]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([90615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5754]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([160022, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10158]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"66\", \"0.000306\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([53615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3388]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([86185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5423]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([169324, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10725]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([111774, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7066]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([100459, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6319]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([142371, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8972]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([77965, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4919]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21250, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1332]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22381, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1405]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29080, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1825]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([153399, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9662]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([50686, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3205]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([98029, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6216]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46794, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26702, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1675]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([138031, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8683]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1631]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([74557, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20347, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1276]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23484, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1476]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([41334, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([124749, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7875]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([43273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2732]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38845, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2449]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1266]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([32859, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2079]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([55730, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3515]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([33615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2122]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1501]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27309, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([54776, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3451]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([63572, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3997]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([121122, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7702]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"99\", \"0.000444\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([76084, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4801]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([15677, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([13, 1210]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([13]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35748, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2252]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([36426, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2297]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19855, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1245]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([108763, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([69665, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4393]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([48629, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3063]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20753, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1301]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([45338, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2857]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1537]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20881, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1309]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2414]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20000, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1255]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37836, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2385]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([164072, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10376]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([65586, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4154]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25580, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1610]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([156920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9883]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([102908, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6510]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([114894, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7256]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30093, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1889]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30494, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1920]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19640, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1233]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([39683, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2506]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([147175, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9261]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([34257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2159]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([96546, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6067]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37101, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2336]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([58310, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3672]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([68235, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4312]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24734, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1553]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([94389, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5980]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"132\", \"0.000212\", \"<b>0.000471\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>Val\", \"Validation Loss:\", \"<b>0.000210\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8b561ae2b6453090f299862fe8232d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([98029, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6216]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>5/10\", \"1/132\", \"0.000343\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([153399, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9662]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([41334, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([88034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5573]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25316, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1587]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([59191, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3729]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([68235, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4312]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([49638, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3124]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20753, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1301]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29619, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1868]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([150877, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9504]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23709, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1489]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([77965, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4919]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([76084, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4801]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20347, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1276]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22381, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1405]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([63572, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3997]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([102908, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6510]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([45338, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2857]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60787, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3821]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21079, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1322]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([48629, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3063]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([50686, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3205]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([124749, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7875]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([71198, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4491]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31892, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2018]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([156920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9883]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([247273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 20843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19855, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1245]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([74557, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37101, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2336]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2414]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1344]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"33\", \"0.000385\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20000, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1255]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([145257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9127]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([100459, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6319]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([36426, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2297]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([138031, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8683]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60126, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3782]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([111774, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7066]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([96546, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6067]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([55730, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3515]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24734, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1553]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([114894, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7256]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29080, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1825]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([53615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3388]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([86185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5423]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([54776, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3451]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([61685, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([140382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8817]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([58310, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3672]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1537]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23041, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1445]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([52087, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3316]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([83813, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5323]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([169324, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10725]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([40359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2548]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35748, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2252]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26362, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1659]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([129543, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8188]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([67090, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4226]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27057, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1698]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([47705, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3021]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([94389, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5980]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46121, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2902]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([39683, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2506]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"66\", \"0.000706\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([44359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2798]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([15677, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([13, 1210]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([13]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([43273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2732]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37836, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2385]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20881, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1309]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22835, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1433]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([62666, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([127006, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8024]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([34257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2159]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([132343, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8357]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23224, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1456]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([92755, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5829]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46794, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([90615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5754]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([69665, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4393]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28391, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1783]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([64497, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4053]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27657, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1737]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23484, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1476]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([42111, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2656]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1576]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21569, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1355]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([194202, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 12550]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28765, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1806]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([160022, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10158]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([57109, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([206589, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 13221]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21957, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1379]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([149016, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9351]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([65586, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4154]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22166, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1391]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([135540, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8564]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([108763, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"99\", \"0.000857\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([72961, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4598]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([121122, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7702]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25580, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1610]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([33615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2122]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26702, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1675]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1501]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([32859, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2079]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35015, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2213]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1631]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19443, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1219]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([155172, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9735]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30093, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1889]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([142371, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8972]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27925, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1756]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1266]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([176196, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11287]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([117810, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7458]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20520, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1292]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([80948, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5168]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([219507, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 14285]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22598, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1421]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31078, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1966]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19640, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1233]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30494, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1920]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21766, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1364]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24184, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1520]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38845, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2449]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21250, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1332]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27309, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([164072, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10376]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([184917, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([105821, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6700]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([147175, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9261]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"132\", \"0.000246\", \"<b>0.000430\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>Val\", \"Validation Loss:\", \"<b>0.000240\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9aeac3e8ba94b0abf25f93235acccea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([114894, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7256]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>6/10\", \"1/132\", \"0.000530\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([32859, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2079]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27309, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([88034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5573]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2414]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([138031, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8683]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([50686, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3205]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([102908, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6510]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26702, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1675]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([57109, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1576]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20881, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1309]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([149016, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9351]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35748, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2252]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19443, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1219]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([76084, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4801]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20347, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1276]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([62666, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([53615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3388]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60787, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3821]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25316, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1587]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([219507, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 14285]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([74557, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19855, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1245]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([108763, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25580, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1610]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([160022, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10158]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46121, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2902]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([90615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5754]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([100459, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6319]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([59191, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3729]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31892, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2018]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([124749, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7875]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"33\", \"0.000227\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22598, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1421]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([47705, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3021]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19640, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1233]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22835, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1433]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([41334, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([247273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 20843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([40359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2548]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20520, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1292]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35015, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2213]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31078, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1966]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([155172, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9735]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([194202, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 12550]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29080, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1825]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([164072, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10376]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([42111, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2656]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([176196, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11287]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([147175, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9261]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22381, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1405]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([39683, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2506]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24184, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1520]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([86185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5423]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46794, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60126, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3782]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20753, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1301]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([61685, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26362, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1659]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([64497, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4053]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([49638, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3124]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([142371, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8972]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([129543, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8188]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([145257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9127]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([117810, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7458]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21957, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1379]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"66\", \"0.000220\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([150877, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9504]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([34257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2159]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21250, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1332]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21079, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1322]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([67090, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4226]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37101, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2336]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([83813, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5323]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27925, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1756]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([80948, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5168]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1537]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([92755, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5829]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([43273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2732]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38845, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2449]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([69665, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4393]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([77965, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4919]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1344]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27057, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1698]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24734, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1553]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([127006, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8024]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([55730, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3515]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([98029, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6216]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23484, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1476]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30093, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1889]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([105821, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6700]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([132343, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8357]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1501]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([15677, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([13, 1210]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([13]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([63572, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3997]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1631]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([156920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9883]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([121122, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7702]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([111774, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7066]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([54776, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3451]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"99\", \"0.000219\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23224, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1456]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([140382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8817]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28391, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1783]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([52087, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3316]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([94389, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5980]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([65586, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4154]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([36426, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2297]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30494, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1920]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([48629, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3063]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20000, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1255]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37836, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2385]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([184917, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([45338, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2857]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([72961, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4598]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28765, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1806]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([153399, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9662]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([44359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2798]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22166, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1391]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([33615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2122]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([96546, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6067]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23709, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1489]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([71198, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4491]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([206589, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 13221]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21569, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1355]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([68235, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4312]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21766, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1364]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23041, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1445]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([169324, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10725]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([58310, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3672]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29619, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1868]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27657, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1737]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([135540, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8564]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1266]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"132\", \"0.001315\", \"<b>0.000289\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>Val\", \"Validation Loss:\", \"<b>0.001152\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9abeea9bb9450e8d114fb085b6a221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([129543, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8188]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>7/10\", \"1/132\", \"0.001043\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([206589, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 13221]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27925, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1756]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([111774, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7066]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2414]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21957, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1379]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29619, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1868]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([140382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8817]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([105821, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6700]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([54776, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3451]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([52087, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3316]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([194202, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 12550]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([176196, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11287]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26362, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1659]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([156920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9883]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([62666, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([80948, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5168]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([48629, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3063]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([160022, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10158]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([57109, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([34257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2159]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1537]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([164072, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10376]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([219507, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 14285]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([86185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5423]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46794, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([63572, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3997]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1344]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([121122, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7702]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19640, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1233]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22835, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1433]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([149016, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9351]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20347, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1276]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"33\", \"0.000644\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([39683, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2506]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([72961, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4598]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23224, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1456]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21766, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1364]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1576]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([61685, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([92755, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5829]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1501]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([36426, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2297]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([50686, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3205]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([88034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5573]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([67090, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4226]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([69665, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4393]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31078, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1966]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([142371, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8972]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21569, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1355]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([117810, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7458]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1631]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21250, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1332]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([145257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9127]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([76084, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4801]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35748, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2252]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25316, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1587]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([77965, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4919]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([100459, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6319]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21079, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1322]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([40359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2548]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([43273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2732]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22598, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1421]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30093, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1889]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20753, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1301]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([55730, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3515]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([138031, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8683]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"66\", \"0.000590\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30494, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1920]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37836, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2385]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27057, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1698]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([94389, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5980]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([150877, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9504]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35015, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2213]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23709, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1489]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31892, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2018]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([65586, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4154]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60126, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3782]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([184917, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22166, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1391]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([44359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2798]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([98029, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6216]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23041, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1445]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([96546, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6067]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19443, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1219]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([132343, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8357]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([102908, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6510]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37101, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2336]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20881, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1309]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29080, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1825]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([68235, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4312]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19855, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1245]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26702, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1675]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([135540, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8564]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([90615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5754]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([147175, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9261]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([71198, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4491]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([49638, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3124]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([64497, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4053]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22381, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1405]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([33615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2122]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"99\", \"0.000228\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23484, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1476]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([42111, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2656]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([59191, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3729]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38845, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2449]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46121, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2902]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([247273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 20843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([45338, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2857]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25580, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1610]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([53615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3388]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([15677, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([13, 1210]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([13]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([32859, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2079]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60787, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3821]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20520, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1292]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28765, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1806]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20000, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1255]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([74557, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([169324, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10725]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([108763, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([114894, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7256]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([124749, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7875]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27309, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1266]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([41334, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([58310, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3672]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([155172, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9735]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([153399, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9662]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([83813, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5323]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24734, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1553]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28391, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1783]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27657, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1737]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([127006, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8024]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24184, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1520]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([47705, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3021]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"132\", \"0.000203\", \"<b>0.000506\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate updated after epoch 7: 0.003 -> 0.0015\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>Val\", \"Validation Loss:\", \"<b>0.000216\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcaab24bfc7c481082ccae96ff1a6936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([142371, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8972]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>8/10\", \"1/132\", \"0.000588\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31892, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2018]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26362, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1659]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([156920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9883]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([69665, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4393]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37101, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2336]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([114894, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7256]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19855, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1245]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([74557, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([42111, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2656]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31078, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1966]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1344]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([150877, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9504]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19443, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1219]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([132343, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8357]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38845, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2449]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([138031, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8683]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([72961, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4598]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([48629, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3063]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([111774, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7066]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([184917, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([108763, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22835, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1433]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19640, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1233]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([71198, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4491]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20753, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1301]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([33615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2122]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60126, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3782]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28765, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1806]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25580, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1610]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20000, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1255]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21957, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1379]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([52087, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3316]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"33\", \"0.000103\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22598, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1421]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([15677, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([13, 1210]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([13]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23709, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1489]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([129543, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8188]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([105821, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6700]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29080, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1825]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24184, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1520]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([145257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9127]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([63572, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3997]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35748, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2252]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([76084, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4801]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([147175, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9261]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([77965, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4919]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([59191, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3729]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([100459, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6319]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([90615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5754]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([58310, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3672]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1537]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([98029, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6216]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46794, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21250, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1332]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21766, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1364]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([68235, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4312]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26702, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1675]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([247273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 20843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([155172, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9735]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1631]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20347, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1276]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([50686, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3205]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30494, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1920]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21569, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1355]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([80948, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5168]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([121122, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7702]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"66\", \"0.000127\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1266]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([41334, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([160022, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10158]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23041, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1445]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([169324, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10725]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([61685, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([127006, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8024]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([164072, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10376]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25316, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1587]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([64497, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4053]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22381, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1405]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([176196, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11287]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([62666, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22166, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1391]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([53615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3388]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([49638, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3124]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1576]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([67090, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4226]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27057, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1698]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([140382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8817]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([153399, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9662]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37836, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2385]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35015, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2213]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([57109, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([124749, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7875]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20881, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1309]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21079, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1322]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([55730, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3515]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([117810, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7458]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1501]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27657, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1737]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([92755, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5829]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([40359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2548]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"99\", \"0.000107\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([44359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2798]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([83813, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5323]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60787, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3821]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2414]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([43273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2732]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([54776, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3451]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([94389, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5980]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([88034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5573]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23224, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1456]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([219507, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 14285]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27925, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1756]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([36426, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2297]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([47705, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3021]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([86185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5423]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([34257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2159]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([45338, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2857]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([102908, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6510]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46121, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2902]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([32859, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2079]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([149016, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9351]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([39683, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2506]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([194202, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 12550]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20520, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1292]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([96546, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6067]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30093, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1889]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28391, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1783]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24734, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1553]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27309, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([135540, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8564]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([206589, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 13221]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23484, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1476]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([65586, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4154]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29619, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1868]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"132\", \"0.000190\", \"<b>0.000179\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>Val\", \"Validation Loss:\", \"<b>0.000091\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47a1fbd361549059b2e9f37f0ec0342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30093, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1889]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>9/10\", \"1/132\", \"0.000189\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19640, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1233]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19443, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1219]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([156920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9883]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([45338, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2857]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46794, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([100459, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6319]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25316, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1587]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26702, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1675]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([176196, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11287]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1501]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46121, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2902]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([55730, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3515]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([153399, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9662]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([68235, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4312]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27657, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1737]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([105821, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6700]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([169324, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10725]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1344]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([80948, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5168]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23484, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1476]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21250, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1332]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60126, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3782]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([132343, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8357]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([48629, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3063]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([138031, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8683]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([32859, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2079]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([57109, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([150877, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9504]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([194202, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 12550]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([49638, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3124]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([88034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5573]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2414]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"33\", \"0.000123\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29619, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1868]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([34257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2159]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22598, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1421]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([36426, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2297]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([145257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9127]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([206589, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 13221]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23224, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1456]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27925, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1756]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([96546, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6067]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21957, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1379]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21079, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1322]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20753, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1301]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([74557, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([121122, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7702]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([219507, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 14285]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([117810, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7458]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([33615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2122]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([149016, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9351]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([52087, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3316]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([160022, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10158]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21569, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1355]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([58310, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3672]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25580, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1610]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1576]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([92755, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5829]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22381, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1405]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([72961, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4598]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([63572, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3997]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20881, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1309]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([62666, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([140382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8817]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([15677, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([13, 1210]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([13]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20000, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1255]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"66\", \"0.000121\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([142371, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8972]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([90615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5754]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([102908, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6510]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([40359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2548]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1631]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22166, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1391]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35015, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2213]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([42111, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2656]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([94389, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5980]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([44359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2798]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35748, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2252]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([76084, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4801]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([124749, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7875]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([64497, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4053]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26362, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1659]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([111774, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7066]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21766, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1364]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23709, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1489]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([147175, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9261]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20347, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1276]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([129543, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8188]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([71198, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4491]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60787, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3821]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([61685, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([47705, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3021]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([67090, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4226]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([53615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3388]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28765, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1806]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24734, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1553]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37836, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2385]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19855, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1245]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30494, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1920]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28391, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1783]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"99\", \"0.000121\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1537]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([114894, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7256]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([108763, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([65586, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4154]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24184, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1520]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22835, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1433]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1266]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31078, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1966]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([50686, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3205]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([69665, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4393]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([83813, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5323]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([127006, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8024]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([43273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2732]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27309, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([184917, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([54776, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3451]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31892, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2018]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23041, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1445]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27057, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1698]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20520, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1292]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([247273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 20843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([39683, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2506]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([77965, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4919]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([41334, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38845, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2449]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([155172, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9735]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([164072, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10376]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([59191, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3729]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([98029, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6216]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([135540, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8564]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([86185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5423]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37101, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2336]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29080, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1825]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"132\", \"0.000127\", \"<b>0.000120\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>Val\", \"Validation Loss:\", \"<b>0.000048\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a67a14d4c354454b2f3941271a2c608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([64497, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4053]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>10/10\", \"1/132\", \"0.000098\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([49638, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3124]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([124749, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7875]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23709, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1489]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30093, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1889]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([63572, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3997]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([155172, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9735]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([74557, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([219507, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 14285]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([247273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 20843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46121, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2902]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29619, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1868]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27925, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1756]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([46794, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21079, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1322]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27057, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1698]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([83813, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5323]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([138031, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8683]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20881, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1309]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([30494, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1920]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19443, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1219]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([129543, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8188]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1344]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([33615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2122]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22381, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1405]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60126, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3782]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25580, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1610]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22598, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1421]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([117810, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7458]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([184917, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11843]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25316, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1587]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([71198, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4491]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37836, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2385]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"33\", \"0.000108\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([86185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5423]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35015, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2213]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([156920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9883]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([67090, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4226]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([65586, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4154]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([105821, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6700]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([102908, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6510]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([145257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9127]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([41334, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([76084, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4801]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([32859, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2079]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([140382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8817]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([90615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5754]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([69665, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4393]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24184, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1520]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([55730, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3515]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([44359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2798]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([96546, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6067]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([29080, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1825]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23224, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1456]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24434, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1537]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([53615, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3388]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([34257, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2159]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19855, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1245]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([52087, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3316]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21957, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1379]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([40359, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2548]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([132343, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8357]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23484, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1476]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1631]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([59191, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3729]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([60787, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3821]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([35748, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2252]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"66\", \"0.000091\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([72961, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4598]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([98029, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6216]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([37101, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2336]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([19640, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1233]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([39683, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2506]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([164072, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10376]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([68235, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4312]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28391, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1783]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([15677, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([13, 1210]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([13]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20347, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1276]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([24734, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1553]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([47705, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3021]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22166, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1391]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([57109, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3605]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([36426, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2297]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([92755, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5829]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([80948, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5168]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31078, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1966]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38382, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2414]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([100459, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6319]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([153399, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9662]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21250, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1332]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([135540, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8564]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([58310, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3672]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([169324, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10725]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([114894, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7256]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([28765, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1806]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26362, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1659]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([149016, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9351]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([43273, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2732]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20520, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1292]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([38845, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2449]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([111774, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7066]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"99\", \"0.000082\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([25034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1576]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([147175, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9261]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([77965, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 4919]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([62666, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3946]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23041, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1445]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([23920, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1501]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([61685, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20185, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1266]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([142371, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8972]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([127006, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 8024]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([108763, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 6879]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20000, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1255]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([31892, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2018]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27309, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1714]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([150877, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 9504]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([54776, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3451]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([42111, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2656]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([194202, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 12550]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([48629, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3063]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([176196, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 11287]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21569, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1355]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([160022, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 10158]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([121122, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 7702]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([27657, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1737]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([21766, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1364]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([206589, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 13221]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([88034, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5573]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([50686, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 3205]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([20753, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1301]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([94389, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 5980]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([26702, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1675]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([22835, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 1433]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n",
      "Dataloader:  <class 'torch.nn.utils.rnn.PackedSequence'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "Shape of inputs: torch.Size([45338, 40]), <class 'torch.nn.utils.rnn.PackedSequence'>\n",
      "Shape of targets: torch.Size([16, 2857]), <class 'torch.Tensor'>\n",
      "Shape of original_lengths: torch.Size([16]), <class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"\", \"132\", \"0.000082\", \"<b>0.000105\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script>addRow(\"<b>Val\", \"Validation Loss:\", \"<b>0.000056\", \"\");</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Training Completed.\tExecution Time: 00:03:05\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NETWORK TRAINING -----------------------------------------------------------------\n",
    "trainer = Trainer_packed(\n",
    "    model = model, \n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler, \n",
    "    loss_fn = criterion, \n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader,\n",
    "    test_loader = test_loader,\n",
    "    num_epochs = NUM_EPOCHS, \n",
    "    device = DEVICE, \n",
    "    is_notebook = IS_NOTEBOOK,\n",
    "    use_mixed_precision = True\n",
    "    )\n",
    "    \n",
    "trained = trainer.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to:\t /home/sieglew/MA-eR-PINN/src/models/pth/LSTM1_packed_241129_170639.pth\n",
      "------------------------------------------------------------\n",
      "Size: 23.00 MB\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# COLLECTING RESULTS AND META DATA ---------------------------------------------------\n",
    "trained['CONFIG'] = CONFIG\n",
    "trained['subset_files'] = subset_files\n",
    "# SAVE   -----------------------------------------------------------------\n",
    "# create unique model name\n",
    "model_name = f'{model.__class__.__name__}_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}'\n",
    "model_destination_path = Path(pth_folder, model_name + \".pth\")\n",
    "\n",
    "# save object & print info\n",
    "torch.save(trained, model_destination_path)\n",
    "print(f\"Model saved to:\\t {model_destination_path}\\n{'-'*60}\\nSize: {os.path.getsize(model_destination_path) / 1024**2:.2f} MB\\n{'-'*60}\")\n",
    "if os.path.getsize(model_destination_path) > 100 * 1024**2: print(\"--> Warning: The saved model size exceeds 100MB!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from:\t /home/sieglew/MA-eR-PINN/src/models/pth/LSTM1_packed_241129_170639.pth\n",
      "------------------------------------------------------------\n",
      "Model: LSTM1_packed\t\tParameters on device: cuda:0\n",
      "------------------------------------------------------------\n",
      "Train/Batch size:\t132 / 1\n",
      "Loss:\t\t\tSmoothL1Loss()\n",
      "Optimizer:\t\tAdamW\n",
      "LR:\t\t\t0.0015\n",
      "Weight Decay:\t\t0.0001\n",
      "------------------------------------------------------------\n",
      " LSTM1_packed(\n",
      "  (lstm): LSTM(40, 400, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (relu): ReLU()\n",
      "  (fc_test): Linear(in_features=400, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# LOAD FROM CHECKPOINT -----------------------------------------------------------------\n",
    "#model_destination_path = Path(pth_folder, \"LSTM1_241118_184156.pth\")\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "checkpoint = torch.load(model_destination_path, weights_only=False, map_location=DEVICE if torch.cuda.is_available() else torch.device('cpu'))\n",
    "for key in [\"model\", \"loss_fn\", \"training_table\", \"train_losses\", \"train_losses_per_iter\", \"val_losses\", \"epoch\", \"lr_history\"]: \n",
    "    exec(f\"{key} = checkpoint[key]\")\n",
    "\n",
    "# configure model and optimizer:\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Move the model and its parameters to the CPU      -->  necessary?\n",
    "try:\n",
    "    if torch.cuda.is_available() and GPU_SELECT is not None:\n",
    "        model.to(DEVICE)\n",
    "    else:\n",
    "        model.to(torch.device(\"cpu\"))\n",
    "except:\n",
    "    model.to(torch.device(\"cpu\"))\n",
    "\n",
    "model.eval(); # set model to evaluation mode for inference\n",
    "print(f\"Model loaded from:\\t {model_destination_path}\\n{'-'*60}\")\n",
    "print(f\"Model: {model.__class__.__name__}\\t\\tParameters on device: {next(model.parameters()).device}\\n{'-'*60}\\n\"\n",
    "        f\"Train/Batch size:\\t{len(train_loader.dataset)} / {train_loader.batch_size}\\n\"\n",
    "        f\"Loss:\\t\\t\\t{loss_fn}\\nOptimizer:\\t\\t{optimizer.__class__.__name__}\\nLR:\\t\\t\\t\"\n",
    "        f\"{optimizer.param_groups[0]['lr']}\\nWeight Decay:\\t\\t{optimizer.param_groups[0]['weight_decay']}\\n{'-'*60}\\n\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get DataFrame of training metrics:\n",
    "training_df = pd.DataFrame(training_table, columns=[\"Epoch\", \"Iteration\", \"Batch Loss\", \"Train Loss\"])\n",
    "# Extract the 'Train Loss' column and compare with the train_losses list\n",
    "train_loss_column = training_df['Train Loss'].replace(['',' '], np.nan).dropna().astype(float).values\n",
    "if any(abs(train_loss_column - train_losses) > 1e-3):  print(\"Extracted and original Train Losses are not equal. Please check metrics table.\")\n",
    "\n",
    "# -------------------------------------\n",
    "# plot training performance:\n",
    "fig, ax1 = plt.subplots(figsize=(10,4))\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_xticks(range(1, NUM_EPOCHS + 1))\n",
    "\n",
    "assert len(train_losses_per_iter) == NUM_EPOCHS * len(train_loader), \"Length of train_losses_per_iter might not match the number of iterations.\"\n",
    "plt.plot(np.linspace(1, NUM_EPOCHS, len(train_losses_per_iter)), train_losses_per_iter, label='batch_loss', color='lightblue')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), train_losses, label='train_loss', color='blue')\n",
    "plt.plot(range(1, NUM_EPOCHS + 1), val_losses, label='val_loss', color='red')\n",
    "\n",
    "plt.yscale('log'); fig.tight_layout(); plt.legend();\n",
    "\n",
    "plt.text(0.86, 0.6, f\"Train: {train_losses[-1]:.3e}\\nVal:    {val_losses[-1]:.3e}\", \\\n",
    "    transform=plt.gca().transAxes, fontsize=10, bbox=dict(facecolor='white', alpha=0.5));\n",
    "\n",
    "if pd.Series(lr_history).nunique() > 1:\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(range(1, NUM_EPOCHS + 1), lr_history, label='lr', color='green', linestyle='--')\n",
    "    ax2.set_ylabel('Learning Rate', color='green')\n",
    "    ax2.tick_params(axis='y', labelcolor='green')\n",
    "    ax2.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.0001\n",
      "RMSE: 0.8836\n",
      "Standard Deviation: 0.7904\n"
     ]
    }
   ],
   "source": [
    "# EVALUATION -----------------------------------------------------------------\n",
    "# get file list of test subset\n",
    "test_files = checkpoint[\"subset_files\"][\"test\"]\n",
    "# -------------------------------------\n",
    "test_loss, outputs, targets, original_lengths = trainer.evaluate_model()\n",
    "# -------------------------------------\n",
    "all_outputs, all_targets, all_original_lengths = [], [], []\n",
    "for batch_outputs, batch_targets, batch_lengths in zip(outputs, targets, original_lengths):\n",
    "    all_outputs.extend(batch_outputs)\n",
    "    all_targets.extend(batch_targets)\n",
    "    all_original_lengths.extend(batch_lengths)\n",
    "\n",
    "# Inverse-transform on all outputs and targets for evaluation\n",
    "#scaled_outputs = target_scaler.inverse_transform(np.concatenate(all_outputs, axis=0).reshape(-1, 1))\n",
    "#scaled_targets = target_scaler.inverse_transform(np.concatenate(all_targets, axis=0).reshape(-1, 1))\n",
    "\n",
    "# Inverse-transform on all outputs and targets for evaluation\n",
    "scaled_outputs = [target_scaler.inverse_transform(output_sequence.reshape(1, -1)).squeeze() for output_sequence in all_outputs]\n",
    "scaled_targets = [target_scaler.inverse_transform(target_sequence.reshape(1, -1)).squeeze() for target_sequence in all_targets]\n",
    "\n",
    "\n",
    "print(f\"Test Loss:  {test_loss:.4f}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(np.concatenate(scaled_targets), np.concatenate(scaled_outputs)):.4f}\")\n",
    "print(f\"Standard Deviation: {np.std(np.concatenate(scaled_targets) - np.concatenate(scaled_outputs)):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get random sample sequence from test set\n",
    "# -------------------------------------\n",
    "random_int = random.randint(1, len(scaled_outputs))\n",
    "y_pred = scaled_outputs[random_int]\n",
    "y_true = scaled_targets[random_int]\n",
    "###############################################\n",
    "# PLOT PREDICTION -----------------------------------------------------------------\n",
    "plt.figure(figsize=(18,4)); plt.xlabel('Time in s'); plt.ylabel('Battery Energy in kWh'); plt.title('Time-Series Prediction')\n",
    "plt.plot(y_true, label='Actual Data') # actual plot\n",
    "plt.plot(np.arange(0, len(y_true), 1), y_pred, label='Predicted Data') # predicted plot\n",
    "plt.legend()\n",
    "plt.text(0.01, 0.02, f\"RMSE: {root_mean_squared_error(y_true, y_pred):.4f}\", transform=plt.gca().transAxes, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "plt.figure(figsize=(18,4)); plt.xlabel('Time in s'); plt.ylabel('Battery Energy in kWh'); plt.title('Time-Series Prediction (Smoothed)')\n",
    "plt.plot(savgol_filter(y_true.flatten(), window_length=60, polyorder=3), label='Actual Data (Smoothed)') # actual plot\n",
    "plt.plot(np.arange(0, len(y_true), 1), savgol_filter(y_pred.flatten(), window_length=60, polyorder=3), label='Predicted Data (Smoothed)') # predicted plot\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODOs\n",
    "    - check if any batch contains only one sequence. If so, discard it before training\n",
    "''';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
