ROOT: /home/sieglew/MA-eR-PINN
------------------------------------------------------------
Directories:
  /home/sieglew/MA-eR-PINN:			project, .gitignore, LICENSE, ref, test, README.md, data, src, .git, archive
  /home/sieglew/MA-Data:			__init__.py, __pycache__, trips_processed_resampled, final, y_true, processed, TripSequences, trips_processed_pickles, final_2, trips_processed_final
------------------------------------------------------------
Running in script mode
------------------------------------------------------------
Torch version:  2.5.1+cu124
Using: -->  CUDA:0
------------------------------------------------------------
Input Data:	/home/sieglew/MA-Data/TripSequences/trips_processed_final
Store model in:	/home/sieglew/MA-eR-PINN/src/models/pth
------------------------------------------------------------
Total Files:	18629
Filtered Files:	18629
------------------------------------------------------------
                FileName  Length  Index
0        V13_T25.parquet   20843   2363
1       V18_T775.parquet   19425   7027
2       V13_T352.parquet   18308   2305
3       V18_T972.parquet   17858   9319
4      V16_T1629.parquet   17519   4678
...                  ...     ...    ...
18624  V17_T4908.parquet     112   5745
18625   V13_T127.parquet     112   8688
18626   V16_T523.parquet     112  13704
18627   V101_T80.parquet     110   5040
18628    V4_T515.parquet     110  12047

[18629 rows x 3 columns]
fitting Scalers: MaxAbsScaler, MinMaxScaler
	50% of the fitting done...
Done. Create DataSets and DataLoaders...
	Number of batches created: 466
	Number of batches created: 111
	Number of batches created: 6
------------------------------------------------------------
Train size:  37524829		(Files: 14904)
Val. size:   9078477		(Files: 3539)
Test size:   526889		(Files: 186) 
 ------------------------------------------------------------
first 3 train files: ['V13_T25.parquet', 'V18_T775.parquet', 'V18_T972.parquet']
------------------------------------------------------------
 LSTM1_packed(
  (lstm): LSTM(38, 400, num_layers=2, batch_first=True, dropout=0.5)
  (relu): ReLU()
  (fc_test): Linear(in_features=400, out_features=1, bias=True)
) ------------------------------------------------------------
Model state_dict:
lstm.weight_ih_l0:	 torch.Size([1600, 38])
lstm.weight_hh_l0:	 torch.Size([1600, 400])
lstm.bias_ih_l0:	 torch.Size([1600])
lstm.bias_hh_l0:	 torch.Size([1600])
lstm.weight_ih_l1:	 torch.Size([1600, 400])
lstm.weight_hh_l1:	 torch.Size([1600, 400])
lstm.bias_ih_l1:	 torch.Size([1600])
lstm.bias_hh_l1:	 torch.Size([1600])
fc_test.weight:	 torch.Size([1, 400])
fc_test.bias:	 torch.Size([1])
------------------------------------------------------------
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.01
    maximize: False
    weight_decay: 0.001
)
------------------------------------------------------------
LRScheduler: <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>
------------------------------------------------------------
Loss_Fn: F.mse_loss(output, target)
------------------------------------------------------------
Criterion: <class 'torch.nn.modules.loss.SmoothL1Loss'>
------------------------------------------------------------

------------------------------------------------------------
Training Started.	Process ID: 3613416 
------------------------------------------------------------
Model: LSTM1_packed	Parameters on device: CUDA:0
------------------------------------------------------------
Train/Batch size:	466 / 1
Loss:			SmoothL1Loss()
Optimizer:		AdamW
LR:			0.01
Weight Decay:		0.001
------------------------------------------------------------
Epoch             Iteration         Batch Loss        Train Loss
1/30              1/466             0.189923

                  116               0.018416

                  232               0.00725

                  348               0.002542

                  466               0.001444          0.019024

Val               Validation Loss:  0.002456

2/30              1/466             0.004271

                  116               0.002585

                  232               0.001783

                  348               0.000914

                  466               0.002153          0.001864

Val               Validation Loss:  0.001548

3/30              1/466             0.001737

                  116               0.001429

                  232               0.000868

                  348               0.000762

                  466               0.001051          0.001437

Val               Validation Loss:  0.000904

4/30              1/466             0.001359

                  116               0.000809

                  232               0.001149

                  348               0.000681

                  466               0.000981          0.001235

Val               Validation Loss:  0.001199

5/30              1/466             0.001328

                  116               0.00097

                  232               0.000611

                  348               0.000854

                  466               0.001746          0.001113

Val               Validation Loss:  0.001257

6/30              1/466             0.001242

                  116               0.000449

                  232               0.000545

                  348               0.001027

                  466               0.000504          0.000962

Val               Validation Loss:  0.000644

7/30              1/466             0.000977

                  116               0.002582

                  232               0.001368

                  348               0.000719

                  466               0.001015          0.000813

Val               Validation Loss:  0.000741

8/30              1/466             0.000959

                  116               0.002827

                  232               0.000914

                  348               0.000328

                  466               0.000592          0.000971

Val               Validation Loss:  0.000754

9/30              1/466             0.001556

                  116               0.000273

                  232               0.000572

                  348               0.000323

                  466               0.000675          0.000604
Learning rate updated after epoch 9: 0.01 -> 0.005

Val               Validation Loss:  0.00085

10/30             1/466             0.00086

                  116               0.000332

                  232               0.000414

                  348               0.00076

                  466               0.000233          0.000453

Val               Validation Loss:  0.000325

11/30             1/466             0.000119

                  116               0.000345

                  232               0.000315

                  348               0.000309

                  466               0.000345          0.000402

Val               Validation Loss:  0.000623

12/30             1/466             0.000293

                  116               0.000321

                  232               0.000255

                  348               0.000339

                  466               0.000174          0.000364

Val               Validation Loss:  0.000259

13/30             1/466             0.000126

                  116               0.000341

                  232               0.000218

                  348               0.000497

                  466               0.00048           0.00037

Val               Validation Loss:  0.000437

14/30             1/466             0.000439

                  116               0.000183

                  232               0.000435

                  348               0.000251

                  466               0.000263          0.000382

Val               Validation Loss:  0.000279

15/30             1/466             0.000199

                  116               8.5e-05

                  232               0.000288

                  348               0.00019

                  466               0.000455          0.000321
Learning rate updated after epoch 15: 0.005 -> 0.0025

Val               Validation Loss:  0.000522

16/30             1/466             0.00045

                  116               0.000214

                  232               0.00019

                  348               0.000101

                  466               0.000121          0.000199

Val               Validation Loss:  0.000171

17/30             1/466             0.000245

                  116               0.000189

                  232               0.000103

                  348               7.7e-05

                  466               0.000435          0.00016

Val               Validation Loss:  0.000282

18/30             1/466             0.000353

                  116               0.000137

                  232               0.000122

                  348               0.000147

                  466               8.4e-05           0.000146

Val               Validation Loss:  0.000125

19/30             1/466             0.000137

                  116               9.5e-05

                  232               0.000258

                  348               0.00014

                  466               0.001043          0.000166

Val               Validation Loss:  0.000332

20/30             1/466             0.000274

                  116               0.000242

                  232               0.000113

                  348               0.000104

                  466               0.000155          0.000149

Val               Validation Loss:  0.000128

21/30             1/466             6.5e-05

                  116               0.000113

                  232               0.000183

                  348               0.000154

                  466               0.000237          0.000161
Learning rate updated after epoch 21: 0.0025 -> 0.00125

Val               Validation Loss:  0.000134

22/30             1/466             8.1e-05

                  116               0.000258

                  232               6.3e-05

                  348               8.8e-05

                  466               3.8e-05           8.8e-05

Val               Validation Loss:  0.0001

23/30             1/466             3.3e-05

                  116               0.000204

                  232               6.7e-05

                  348               5.3e-05

                  466               0.000103          8.5e-05

Val               Validation Loss:  8.9e-05

24/30             1/466             4.7e-05

                  116               0.00012

                  232               5e-05

                  348               7.9e-05

                  466               3.9e-05           8.4e-05

Val               Validation Loss:  7.9e-05

25/30             1/466             7.1e-05

                  116               6.9e-05

                  232               3e-05

                  348               5.8e-05

                  466               7.4e-05           9.1e-05

Val               Validation Loss:  0.000188

26/30             1/466             0.0001

                  116               6.5e-05

                  232               0.000121

                  348               7.7e-05

                  466               6.7e-05           8.9e-05

Val               Validation Loss:  9.8e-05

27/30             1/466             0.000129

                  116               2.6e-05

                  232               6.8e-05

                  348               7.8e-05

                  466               6e-05             7.6e-05

Val               Validation Loss:  7.9e-05

28/30             1/466             6.3e-05

                  116               4.1e-05

                  232               4.1e-05

                  348               5.3e-05

                  466               0.000228          7.7e-05

Val               Validation Loss:  0.000143

29/30             1/466             0.000298

                  116               9.2e-05

                  232               7.3e-05

                  348               0.000204

                  466               2.4e-05           8.4e-05

Val               Validation Loss:  6.5e-05

30/30             1/466             6.7e-05

                  116               5.7e-05

                  232               0.000114

                  348               6.5e-05

                  466               0.000151          7.4e-05

Val               Validation Loss:  9.6e-05
------------------------------------------------------------
Training Completed.	Execution Time: 00:39:37
------------------------------------------------------------

Model saved to:	 /home/sieglew/MA-eR-PINN/src/models/pth/LSTM1_packed_241205_220003.pth
------------------------------------------------------------
Size: 23.94 MB
------------------------------------------------------------
Model loaded from:	 /home/sieglew/MA-eR-PINN/src/models/pth/LSTM1_packed_241205_220003.pth
------------------------------------------------------------
Model: LSTM1_packed		Parameters on device: cuda:0
------------------------------------------------------------
Train/Batch size:	466 / 1
Loss:			SmoothL1Loss()
Optimizer:		AdamW
LR:			0.00125
Weight Decay:		0.001
------------------------------------------------------------
 LSTM1_packed(
  (lstm): LSTM(38, 400, num_layers=2, batch_first=True, dropout=0.5)
  (relu): ReLU()
  (fc_test): Linear(in_features=400, out_features=1, bias=True)
)
Test Loss:  0.0001
RMSE: 1.2815
Standard Deviation: 0.9020
