{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfaf8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset -f -s\n",
    "'''------------------------------------------------------------------\n",
    "MA-eR-PINN: eRange Prediction using Physics-Informed Neural Networks\n",
    "---------------------------------------------------------------------\n",
    "Version: V2.0      Modified: 12.01.2025        William Siegle\n",
    "---------------------------------------------------------------------\n",
    "PTRAIN - Standard Pipeline Framework for Training the PINN\n",
    "+ OPTUNA - Hyperparameter Optimization using Optuna\n",
    "------------------------------------------------------------------''';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55581895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MA-eR-PINN: CONFIGURATION FILE -------------------------------------------------\n",
    "from pathlib import Path\n",
    "CONFIG = {\n",
    "    # SYSTEM: ---------------------------------------------------------------------\n",
    "    \"GPU_SELECT\":       0, # {0,1,2,3, None: CPU only}\n",
    "    \"ROOT\":             Path('../..').resolve(),\n",
    "    \"INPUT_LOCATION\":   Path(\"TripSequences\", \"trips_processed_pinn_2\"), \n",
    "    \"OUTPUT_LOCATION\":  Path(\"src\", \"models\", \"pth\"),\n",
    "    \"SEED\"  :           25,\n",
    "    \"PLOT_ACTIVE\":      True,\n",
    "\n",
    "    # DATA PREPROCESSING: ---------------------------------------------------------\n",
    "    \"TRAIN_VAL_TEST\":   [0.8, 0.19, 0.01], # [train, val, test splits]\n",
    "    \"MAX_FILES\":        None, # None: all files\n",
    "    \"MIN_SEQ_LENGTH\":   600, # minimum sequence length in s to be included in DataSets\n",
    "    \"SCALERS\":          {'feature_scaler': 'MaxAbsScaler()','target_scaler': 'MinMaxScaler(feature_range=(0, 1))','prior_scaler': 'MinMaxScaler(feature_range=(0, 1))'},\n",
    "\n",
    "    # FEATURES: -------------------------------------------------------------------\n",
    "    \"FEATURES\":         ['accelpdlposn_cval','actdrvtrnpwrprc_cval','actualdcvoltage_pti1','actualspeed_pti1','actualtorque_pti1',\n",
    "                        'airtempinsd_cval_hvac','airtempinsd_rq','airtempoutsd_cval_cpc','altitude_cval_ippc','brc_stat_brc1','brktempra_cval',\n",
    "                        'bs_brk_cval','currpwr_contendrnbrkresist_cval','elcomp_pwrcons_cval','epto_pwr_cval','hv_bat_dc_momvolt_cval_bms1',\n",
    "                        'hv_batavcelltemp_cval_bms1','hv_batcurr_cval_bms1','hv_batisores_cval_e2e','hv_batmaxchrgpwrlim_cval_1',\n",
    "                        'hv_batmaxdischrgpwrlim_cval_1','hv_curr_cval_dcl1','hv_dclink_volt_cval_dcl1','hv_ptc_cabin1_pwr_cval','hv_pwr_cval_dcl1',\n",
    "                        'lv_convpwr_cval_dcl1','maxrecuppwrprc_cval','maxtracpwrpct_cval','motortemperature_pti1','powerstagetemperature_pti1',\n",
    "                        'rmsmotorcurrent_pti1','roadgrad_cval_pt','selgr_rq_pt','start_soc','txoiltemp_cval_tcm','vehspd_cval_cpc','vehweight_cval_pt'],                 \n",
    "    \"TARGETS\":          ['hv_bat_soc_cval_bms1'],\n",
    "    \"PRIORS\":           ['emot_soc_pred'],  \n",
    "\n",
    "    # MODEL: -----------------------------------------------------------------------\n",
    "    \"HIDDEN_SIZE\":      200,    # features in the hidden state h\n",
    "    \"NUM_LAYERS\":       2,      # recurrent layers for stacked LSTMs. Default: 1\n",
    "    \"DROPOUT\":          0.35,   # usually: [0.2 - 0.5]\n",
    "    \n",
    "    # TRAINING & OPTIMIZER: --------------------------------------------------------\n",
    "    \"NUM_EPOCHS\":       5,\n",
    "    \"BATCH_SIZE\":       32,   # [2, 4, 8, 16, 32, 64, 128, 256]\n",
    "    \"LEARNING_RATE\":    1e-2,   # 0.001 lr\n",
    "    \"WEIGHT_DECAY\":     1e-2,   # weight decay coefficient (default: 1e-2)\n",
    "    \"MOMENTUM_SGD\":     0.0,   # (default: 0.0)\n",
    "    \"OPTIMIZER\":        'adamw',     # ('adam', 'sgd', 'adamw')\n",
    "    \"LRSCHEDULER\":      \"torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1.0)\",  # constant LR for 1.0 as multiplicative factor\n",
    "                        # torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience = 3, factor = 0.5, min_lr = 1e-7)\n",
    "\n",
    "    # LOSS FUNCTION: ---------------------------------------------------------------\n",
    "    \"CRITERION\":        \"nn.SmoothL1Loss()\", # ['nn.MSELoss()', 'nn.L1Loss()', 'nn.SmoothL1Loss()', 'nn.HuberLoss()', 'MASE()']\n",
    "    \"LOSS_FN\":          \"F.mse_loss(output, target)\", # ['F.mse_loss(output, target)', 'F.l1_loss(output, target)', 'F.smooth_l1_loss(output, target)', 'F.huber_loss(output, target)', 'F.mase_loss(output, target)']\n",
    "    \"P_LOSS_FACTOR\":    0.1, # Physics loss factor\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc61569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTUNA: SEARCH SPACE ---------------------------------------------------\n",
    "global search_space, search_space_NewData\n",
    "search_space = {\n",
    "    # MODEL: -----------------------------------------------------------------------\n",
    "    'HIDDEN_SIZE': ('int', 50, 400, 50),\n",
    "    'NUM_LAYERS': ('int', 1, 5),\n",
    "    'DROPOUT': ('float', 0.05, 0.5, 0.05),\n",
    "    #'WEIGHT_INIT': ('categorical', ('xavier', 'he', 'normal')),\n",
    "    #'BATCH_NORM_ON': ('categorical', (True, False))\n",
    "\n",
    "\n",
    "    # TRAINING & OPTIMIZER: --------------------------------------------------------\n",
    "    'OPTIMIZER': ('categorical', ('adam', 'sgd', 'adamw')),\n",
    "    'LEARNING_RATE': ('categorical', (1e-5, 5e-5, 1e-4, 3e-4, 5e-4, 8e-4, 1e-3, 3e-3, 5e-3, 8e-3, 1e-2, 2e-2, 5e-2, 1e-1, 2e-1)),\n",
    "    'WEIGHT_DECAY': ('categorical', (0.0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2)),\n",
    "    'MOMENTUM_SGD': ('float', 0.0, 0.9, 0.1),\n",
    "\n",
    "\n",
    "    'P_LOSS_FACTOR': ('float', 0.0, 1.0, 0.05)\n",
    "}\n",
    "\n",
    "search_space_NewData = {\n",
    "    # DATA PREPROCESSING: ---------------------------------------------------------\n",
    "    \"MIN_SEQ_LENGTH\": ('int', 300, 3600, 300),\n",
    "    'BATCH_SIZE': ('categorical', (4, 8, 16, 32, 64, 128)),\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "N_TRIALS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c4680",
   "metadata": {},
   "source": [
    "___\n",
    "SETUP: Locate devices & system folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7924eab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sieglew/MA-eR-PINN\n",
      "------------------------------------------------------------\n",
      "Directories:\n",
      "  /home/sieglew/MA-eR-PINN:\t\t\ttest, .git, archive, project, data, src\n",
      "  /mnt/nvme/datasets/sieglew:\t\t\tTripSequences\n",
      "------------------------------------------------------------\n",
      "Running in notebook mode\n",
      "CONFIG Dictionary:\n",
      "---------------------------------------------------------------------------------------------------------------------------------\n",
      "     Parameter        Value\n",
      "--  ---------------  -------------------------------------------------------------------------\n",
      "0   GPU_SELECT       0\n",
      "1   ROOT             /home/sieglew/MA-eR-PINN\n",
      "2   INPUT_LOCATION   TripSequences/trips_processed_pinn_2\n",
      "3   OUTPUT_LOCATION  src/models/pth\n",
      "4   SEED             25\n",
      "5   PLOT_ACTIVE      True\n",
      "6   TRAIN_VAL_TEST   [0.8, 0.19, 0.01]\n",
      "7   MAX_FILES        None\n",
      "8   MIN_SEQ_LENGTH   600\n",
      "9   SCALERS          {'feature_scaler': 'MaxAbsScaler()',\n",
      "                      'target_scaler': 'MinMaxScaler(feature_range=(0,\n",
      "                      1))',\n",
      "                      'prior_scaler': 'MinMaxScaler(feature_range=(0,\n",
      "                      1))'}\n",
      "10  FEATURES         ['accelpdlposn_cval',\n",
      "                      'actdrvtrnpwrprc_cval',\n",
      "                      'actualdcvoltage_pti1',\n",
      "                      'actualspeed_pti1',\n",
      "                      'actualtorque_pti1',\n",
      "                      'airtempinsd_cval_hvac',\n",
      "                      'airtempinsd_rq',\n",
      "                      'airtempoutsd_cval_cpc',\n",
      "                      'altitude_cval_ippc',\n",
      "                      'brc_stat_brc1',\n",
      "                      'brktempra_cval',\n",
      "                      'bs_brk_cval',\n",
      "                      'currpwr_contendrnbrkresist_cval',\n",
      "                      'elcomp_pwrcons_cval',\n",
      "                      'epto_pwr_cval',\n",
      "                      'hv_bat_dc_momvolt_cval_bms1',\n",
      "                      'hv_batavcelltemp_cval_bms1',\n",
      "                      'hv_batcurr_cval_bms1',\n",
      "                      'hv_batisores_cval_e2e',\n",
      "                      'hv_batmaxchrgpwrlim_cval_1',\n",
      "                      'hv_batmaxdischrgpwrlim_cval_1',\n",
      "                      'hv_curr_cval_dcl1',\n",
      "                      'hv_dclink_volt_cval_dcl1',\n",
      "                      'hv_ptc_cabin1_pwr_cval',\n",
      "                      'hv_pwr_cval_dcl1',\n",
      "                      'lv_convpwr_cval_dcl1',\n",
      "                      'maxrecuppwrprc_cval',\n",
      "                      'maxtracpwrpct_cval',\n",
      "                      'motortemperature_pti1',\n",
      "                      'powerstagetemperature_pti1',\n",
      "                      'rmsmotorcurrent_pti1',\n",
      "                      'roadgrad_cval_pt',\n",
      "                      'selgr_rq_pt',\n",
      "                      'start_soc',\n",
      "                      'txoiltemp_cval_tcm',\n",
      "                      'vehspd_cval_cpc',\n",
      "                      'vehweight_cval_pt']\n",
      "11  TARGETS          ['hv_bat_soc_cval_bms1']\n",
      "12  PRIORS           ['emot_soc_pred']\n",
      "13  HIDDEN_SIZE      200\n",
      "14  NUM_LAYERS       2\n",
      "15  DROPOUT          0.35\n",
      "16  NUM_EPOCHS       5\n",
      "17  BATCH_SIZE       32\n",
      "18  LEARNING_RATE    0.01\n",
      "19  WEIGHT_DECAY     0.01\n",
      "20  MOMENTUM_SGD     0.0\n",
      "21  OPTIMIZER        adamw\n",
      "22  LRSCHEDULER      torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1.0)\n",
      "23  CRITERION        nn.SmoothL1Loss()\n",
      "24  LOSS_FN          F.mse_loss(output, target)\n",
      "25  P_LOSS_FACTOR    0.1 \n",
      "---------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Torch version:  2.5.1+cu124\n",
      "Using: -->  CUDA:0\n"
     ]
    }
   ],
   "source": [
    "# LOCATE REPOSITORY/DATASTORAGE IN CURRENT SYSTEM ENVIRONMENT  ---------------------------\n",
    "import sys, os\n",
    "for key in CONFIG: globals()[key] = CONFIG[key]\n",
    "print(ROOT)\n",
    "if 'ROOT' not in globals(): ROOT = Path('../..').resolve()\n",
    "sys.path.append(os.path.abspath(ROOT))\n",
    "\n",
    "# INTERNAL MODULE IMPORTS ----------------------------------------------------------------\n",
    "from src.__init__ import *\n",
    "from src.utils.data_utils import *\n",
    "from src.utils.preprocess_utils import *\n",
    "from src.utils.eval_utils import *\n",
    "from src.utils.Trainers import *\n",
    "from src.models.lstm_models import *\n",
    "\n",
    "# SETUP ENVIRONMENT ---------------------------------------------------------------------\n",
    "DATA_PATH, IS_NOTEBOOK, DEVICE = setup_environment(CONFIG, ROOT, SEED, GPU_SELECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1963d1",
   "metadata": {},
   "source": [
    "___\n",
    "DATA SELECTION & PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cb1ce7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Total Files:\t16116\n",
      "Filtered Files:\t12258\n",
      "------------------------------------------------------------\n",
      "                FileName  Length  Index\n",
      "0        V13_T25.parquet   20843   7175\n",
      "1       V18_T775.parquet   19425   9298\n",
      "2       V13_T352.parquet   18308   6751\n",
      "3       V18_T972.parquet   17858   9680\n",
      "4      V16_T1629.parquet   17519   8453\n",
      "...                  ...     ...    ...\n",
      "12253   V12_T273.parquet     602   7938\n",
      "12254   V18_T883.parquet     601    669\n",
      "12255  V18_T1549.parquet     601   1928\n",
      "12256   V16_T522.parquet     601   5087\n",
      "12257  V17_T3857.parquet     601   7588\n",
      "\n",
      "[12258 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# FILE SOURCES ---------------------------------------------------------------\n",
    "input_folder = Path(DATA_PATH, INPUT_LOCATION) # Trip parquet files\n",
    "pth_folder = Path(ROOT, OUTPUT_LOCATION)\n",
    "files, trip_lengths, indices_by_length, sorted_trip_lengths, all_signals = prepare_data(input_folder, pth_folder, MAX_FILES, MIN_SEQ_LENGTH, ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb951c30",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# INPUT & TARGET SPECIFICATION ---------------------------------------------------\n",
    "# these signals are required for the physical Model calculation:\n",
    "base_signals = [\"signal_time\", \"hirestotalvehdist_cval_icuc\", \"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", \n",
    "                \"hv_batpwr_cval_bms1\", \"emot_pwr_cval\",\"bs_roadincln_cval\", \"roadgrad_cval_pt\"]\n",
    "\n",
    "# these signals have to be dropped (from Features) in order for appropriate training:\n",
    "columns_to_drop = [\"signal_time\",                       # works as index\n",
    "                    \"hirestotalvehdist_cval_icuc\",      # starts from 0, obtained by speed integration\n",
    "                    \"latitude_cval_ippc\",               # only GPS \n",
    "                    \"longitude_cval_ippc\",              # only GPS\n",
    "                    \"hv_batpwr_cval_bms1\",              # directly related to target (soc_gradient)\n",
    "                    \"hv_batmomavldischrgen_cval_1\",     # indirect target 1 in kWh\n",
    "                    \"hv_bat_soc_cval_bms1\",              # indirect target 2 in %SoC\n",
    "                    \"soc_gradient\",                     # actual target signal   \n",
    "                    \"emot_pwr_cval\",                    # replaced as physical prior for PINN\n",
    "                    \"emot_pwr_pred\",                    # actual physical prior for PINN\n",
    "                    ]\n",
    "\n",
    "# Ensure no element of \"columns_to_drop\" is included in \"FEATURES\"\n",
    "assert not any(col in FEATURES for col in columns_to_drop), \"Some columns to drop are still in FEATURES\"\n",
    "\n",
    "# ---------------------------------------------------\n",
    "selection_1 = [\"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", 'roadgrad_cval_pt', \"vehweight_cval_pt\", \"accelpdlposn_cval\", \"bs_brk_cval\", \"elcomp_pwrcons_cval\",\n",
    "               \"epto_pwr_cval\", \"motortemperature_pti1\", \"powerstagetemperature_pti1\", 'airtempinsd_cval_hvac', 'brktempra_cval', 'selgr_rq_pt']\n",
    "selection_2 = [\"hirestotalvehdist_cval_icuc\", \"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", \"hv_batpwr_cval_bms1\", \"emot_pwr_cval\", \"roadgrad_cval_pt\"]\n",
    "selection_3 = [\"vehspd_cval_cpc\", \"altitude_cval_ippc\", \"airtempoutsd_cval_cpc\", \"vehweight_cval_pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e39168d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Input Signals:\t37\n",
      "Target Signals:\t1\n",
      "Physical Prior Signals:\t1\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# FEATURE SELECTION  ----------------------------------------------------------------------------\n",
    "INPUT_COLUMNS = FEATURES; TARGET_COLUMN = TARGETS; PRIOR_COLUMN = PRIORS\n",
    "print(f\"{'-'*60}\\nInput Signals:\\t{len(FEATURES)}\\nTarget Signals:\\t{len(TARGETS)}\\nPhysical Prior Signals:\\t{len(PRIORS)}\\n{'-'*60}\")\n",
    "\n",
    "# FEATURE NORMALIZATION/SCALING -----------------------------------------------------------------\n",
    "scaler = eval(SCALERS['feature_scaler'])\n",
    "target_scaler = eval(SCALERS['target_scaler'])\n",
    "prior_scaler = eval(SCALERS['prior_scaler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bb0b2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --> Warning: Removed the last 15 samples to ensure a balanced batch size\n",
      "fitting Scalers: MaxAbsScaler, MinMaxScaler, MinMaxScaler\n",
      "\t50% of the fitting done...\n",
      "Done. Create DataSets and DataLoaders...\n",
      "\tNumber of batches created: 306\n",
      " --> Warning: Removed the last 25 samples to ensure a balanced batch size\n",
      "\tNumber of batches created: 72\n",
      " --> Warning: Removed the last 26 samples to ensure a balanced batch size\n",
      "\tNumber of batches created: 3\n",
      "------------------------------------------------------------\n",
      "Train size:  31737412\t\t(Files: 9792)\n",
      "Val. size:   7562244\t\t(Files: 2304)\n",
      "Test size:   375582\t\t(Files: 96) \n",
      " ------------------------------------------------------------\n",
      "\tRemoved 66 file from the dataset\n",
      "------------------------------------------------------------\n",
      "first 3 train files: ['V13_T25.parquet', 'V18_T775.parquet', 'V13_T352.parquet']\n"
     ]
    }
   ],
   "source": [
    "# DATA SET SPLITTING AND SORTING ----------------------------------------------------------------\n",
    "train_subset, val_subset, test_subset = random_split(files, TRAIN_VAL_TEST)\n",
    "\n",
    "# DATALOADER SETTINGS ------------------------------------------------------------------\n",
    "dataloader_settings = {\n",
    "    'batch_size': 1,                    # see *Note above\n",
    "    'shuffle': True,                    # shuffle the batches before each epoch\n",
    "    'collate_fn': collate_fn_PINN,      # include optional arguments\n",
    "    'num_workers': 8,                   # number of workers\n",
    "    'prefetch_factor': 4,               # number of samples loaded in advance by each worker\n",
    "    'persistent_workers': True,         # whether the data loader workers are allowed to persist\n",
    "    'pin_memory': False if DEVICE.type == 'cpu' else True}\n",
    "\n",
    "# PREPARE TRAIN, VAL & TEST DATALOADERS  ------------------------------------------------------------\n",
    "train_subset, train_dataset, train_dataset_batches, train_loader = prepare_dataloader_PINN(train_subset, indices_by_length, \\\n",
    "    BATCH_SIZE, INPUT_COLUMNS, TARGET_COLUMN, PRIOR_COLUMN, scaler, target_scaler, prior_scaler, dataloader_settings, fit=True, drop_last=True)\n",
    "\n",
    "val_subset, val_dataset, val_dataset_batches, val_loader = prepare_dataloader_PINN(val_subset, indices_by_length, \\\n",
    "    BATCH_SIZE, INPUT_COLUMNS, TARGET_COLUMN, PRIOR_COLUMN, scaler, target_scaler, prior_scaler, dataloader_settings, drop_last=True)\n",
    "\n",
    "test_subset, test_dataset, test_dataset_batches, test_loader = prepare_dataloader_PINN(test_subset, indices_by_length, \\\n",
    "    BATCH_SIZE, INPUT_COLUMNS, TARGET_COLUMN, PRIOR_COLUMN, scaler, target_scaler, prior_scaler, dataloader_settings, drop_last=True)\n",
    "\n",
    "# print dataset info\n",
    "subset_files = print_dataset_sizes(train_dataset, val_dataset, test_dataset, train_subset, val_subset, test_subset, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1245c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataloaders\n",
    "#train_loader = torch.load('train_loader.pth')\n",
    "#val_loader = torch.load('val_loader.pth')\n",
    "#test_loader = torch.load('test_loader.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8993b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_NOTEBOOK and False: \n",
    "    check_batch_PINN(train_loader)\n",
    "    visualize_padding(BATCH_SIZE, trip_lengths, sorted_trip_lengths, train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c3fe74",
   "metadata": {},
   "source": [
    "___\n",
    "MODEL & TRAINING CONFIGURATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ef486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM NETWORK -----------------------------------------------------------------------\n",
    "\n",
    "class LSTM1_packed_old_version(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, device=DEVICE):\n",
    "        super(LSTM1_packed_old_version, self).__init__()\n",
    "\n",
    "        self.input_size = input_size    # input size\n",
    "        self.hidden_size = hidden_size  # hidden state\n",
    "        self.num_layers = num_layers    # number of layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # LSTM CELL --------------------------------\n",
    "        self.lstm = nn.LSTM(\n",
    "            self.input_size,            # The number of expected features in the input x\n",
    "            self.hidden_size,           # The number of features in the hidden state h\n",
    "            self.num_layers,            # Number of recurrent layers for stacked LSTMs. Default: 1\n",
    "            batch_first=True,           # If True, then the input and output tensors are provided as (batch, seq, feature) instead of (seq, batch, feature). Default: False\n",
    "            bias=True,                  # If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n",
    "            dropout=self.dropout,       # usually: [0.2 - 0.5], introduces a Dropout layer on the outputs of each LSTM layer except the last layer, (dropout probability). Default: 0\n",
    "            bidirectional=False,        # If True, becomes a bidirectional LSTM. Default: False\n",
    "            proj_size=0,                # If > 0, will use LSTM with projections of corresponding size. Default: 0\n",
    "            device=device)\n",
    "\n",
    "        # LAYERS -----------------------------------\n",
    "        self.dropout_layer = nn.Dropout(self.dropout)\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size // 2)\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, hidden_size // 4)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size // 4)\n",
    "        self.fc3 = nn.Linear(hidden_size // 4, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, packed_input, batch_size=None):\n",
    "        packed_out, _ = self.lstm(packed_input)\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        out = self.relu(out)  # relu\n",
    "        out = self.dropout_layer(out)  # dropout\n",
    "        out = self.fc1(out)  # fully connected layer 1\n",
    "        out = self.bn1(out.transpose(1, 2)).transpose(1, 2)\n",
    "        out = self.relu(out)  # relu\n",
    "        out = self.fc2(out)  # fully connected layer 2\n",
    "        out = self.bn2(out.transpose(1, 2)).transpose(1, 2)  # batch normalization 2\n",
    "        out = self.relu(out)  # relu\n",
    "        out = self.fc3(out)  # fully connected layer 3\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60875ef",
   "metadata": {},
   "source": [
    "___\n",
    "TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac0d8b3",
   "metadata": {},
   "source": [
    "___\n",
    "OPTUNA: Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9c4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTUNA: OBJECTIVE ---------------------------------------------------\n",
    "def objective(trial):\n",
    "\n",
    "    # -----------------------------------------------------------------------------------\n",
    "    # OPTUNA: CREATE TRIAL OBJECTS ---------------------------------------------------\n",
    "    for param, (suggest_type, *args) in search_space.items():\n",
    "        if suggest_type == 'int': locals()[param.lower()] = trial.suggest_int(param, *args)\n",
    "        elif suggest_type == 'float': locals()[param.lower()] = trial.suggest_float(param, *args)\n",
    "        elif suggest_type == 'categorical': locals()[param.lower()] = trial.suggest_categorical(param, args)\n",
    "\n",
    "    # Update CONFIG with suggested hyperparameters\n",
    "    for param in search_space.keys(): CONFIG[param] = locals()[param.lower()]\n",
    "    # -----------------------------------------------------------------------------------\n",
    "\n",
    "    # TRAINING_CODE: -----------------------------------------------------------------\n",
    "    # INSTANTIATE MODEL --------------------\n",
    "    model = LSTM1_packed_old_version(len(INPUT_COLUMNS), HIDDEN_SIZE, NUM_LAYERS, DROPOUT).to(DEVICE)\n",
    "    optimizer = eval(OPTIMIZER)\n",
    "    \n",
    "    if eval(OPTIMIZER)=='adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    elif eval(OPTIMIZER)=='adamw':\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr = LEARNING_RATE, weight_decay = WEIGHT_DECAY)\n",
    "    elif eval(OPTIMIZER)=='sgd':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM_SGD, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    scheduler = eval(LRSCHEDULER); criterion = eval(CRITERION)\n",
    "\n",
    "    # LOSS FUNCTION ----------------------------------------------------------------   \n",
    "    def loss_fn_PINN_3(output, target, prior):\n",
    "        l_p = P_LOSS_FACTOR\n",
    "        y_pred = output; y_true = target; y_phys = prior\n",
    "        total_loss = F.mse_loss(y_true, (l_p * y_phys + (1 - l_p) * y_pred), reduction='mean')\n",
    "        return total_loss\n",
    "\n",
    "    # TRAIN -----------------------------------------------------------------\n",
    "    TRAINER = PTrainer_PINN(\n",
    "        model = model, \n",
    "        optimizer = optimizer,\n",
    "        scheduler = scheduler, \n",
    "        loss_fn = loss_fn_PINN_3, \n",
    "        train_loader = train_loader,\n",
    "        val_loader = val_loader,\n",
    "        test_loader = test_loader,\n",
    "        num_epochs = NUM_EPOCHS, \n",
    "        device = DEVICE, \n",
    "        is_notebook = IS_NOTEBOOK,\n",
    "        use_mixed_precision = True)\n",
    "\n",
    "    RESULTS = TRAINER.train_model()\n",
    "    plot_training_performance(RESULTS)\n",
    "\n",
    "    # RETURN latest val_loss ---------------------------------------------------------\n",
    "    val_loss = RESULTS['val_losses'][-1]\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45a39b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-12 13:44:43,083] A new study created in memory with name: no-name-183d2bf6-ab06-443c-ad99-45c26e382f5f\n",
      "[W 2025-01-12 13:44:43,086] Trial 0 failed with parameters: {'HIDDEN_SIZE': 100, 'NUM_LAYERS': 5, 'DROPOUT': 0.45, 'OPTIMIZER': 'adam', 'LEARNING_RATE': 0.01, 'WEIGHT_DECAY': 0.01, 'MOMENTUM_SGD': 0.4, 'P_LOSS_FACTOR': 0.75} because of the following error: KeyError('optimizer').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sieglew/.conda/envs/sieglew/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1151765/32039563.py\", line 16, in objective\n",
      "    for param in search_space.keys(): CONFIG[param] = locals()[param.lower()]\n",
      "                                                      ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "KeyError: 'optimizer'\n",
      "[W 2025-01-12 13:44:43,087] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# OPTUNA: STUDY -------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Print the best hyperparameters\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_params)\n",
      "File \u001b[0;32m~/.conda/envs/sieglew/lib/python3.11/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sieglew/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/sieglew/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.conda/envs/sieglew/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.conda/envs/sieglew/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m suggest_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlocals\u001b[39m()[param\u001b[38;5;241m.\u001b[39mlower()] \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_categorical(param, args[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Update CONFIG with suggested hyperparameters\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m search_space\u001b[38;5;241m.\u001b[39mkeys(): CONFIG[param] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# -----------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# TRAINING_CODE: -----------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# INSTANTIATE MODEL --------------------\u001b[39;00m\n\u001b[1;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTM1_packed_old_version(\u001b[38;5;28mlen\u001b[39m(INPUT_COLUMNS), HIDDEN_SIZE, NUM_LAYERS, DROPOUT)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'optimizer'"
     ]
    }
   ],
   "source": [
    "# OPTUNA: STUDY -------------------------------------------------------------------\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc2065",
   "metadata": {},
   "source": [
    "___\n",
    "SAVE CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7542bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL -----------------------------------------------------------------\n",
    "CHECKPOINT, model_destination_path = save_checkpoint(TRAINER, train_loader, val_loader, test_loader, RESULTS, CONFIG, subset_files, pth_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cddb8e",
   "metadata": {},
   "source": [
    "___\n",
    "LOAD CHECKPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bb2d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_destination_path = Path(pth_folder, \"LSTM1_packed_old_version_241216_082030.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81daa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MODEL -----------------------------------------------------------------\n",
    "CHECKPOINT = load_checkpoint(model_destination_path, DEVICE)\n",
    "for key in CHECKPOINT.keys(): globals()[key] = CHECKPOINT[key]\n",
    "# load model and optimizer states --------------------------------------------\n",
    "model.load_state_dict(model_state_dict)\n",
    "optimizer.load_state_dict(optimizer_state_dict)\n",
    "model.eval()  # set model to evaluation mode for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4d64ba",
   "metadata": {},
   "source": [
    "___\n",
    "EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f09213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION -----------------------------------------------------------------\n",
    "# get file list of test subset\n",
    "test_files = CHECKPOINT[\"test_files\"]; print(f\"{'-'*60}\\nTest subset: {len(test_files)} files\\n{'-'*60}\")\n",
    "# -------------------------------------\n",
    "# evaluate model on test set\n",
    "test_loss, all_outputs, all_targets, all_priors, all_original_lengths = TRAINER.evaluate_model()\n",
    "# -------------------------------------\n",
    "# Inverse-transform on all outputs and targets for evaluation\n",
    "scaled_outputs = [target_scaler.inverse_transform(output_sequence.reshape(1, -1)).squeeze() for output_sequence in all_outputs]\n",
    "scaled_targets = [target_scaler.inverse_transform(target_sequence.reshape(1, -1)).squeeze() for target_sequence in all_targets]\n",
    "scaled_priors = [prior_scaler.inverse_transform(prior_sequence.reshape(1, -1)).squeeze() for prior_sequence in all_priors]\n",
    "\n",
    "# concatenate:\n",
    "all_y_true, all_y_pred, all_y_phys = np.concatenate(scaled_targets), np.concatenate(scaled_outputs), np.concatenate(scaled_priors)\n",
    "\n",
    "# calculate evaluation metrics\n",
    "print(f\"Test Loss:\\t\\t{test_loss:.6f}\")\n",
    "metrics = calculate_metrics(all_y_true, all_y_pred) # [rmse, mae, std_dev, mape, r2, max_error]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ed8d9",
   "metadata": {},
   "source": [
    "___\n",
    "PLOT RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbdbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random sample sequence from test set\n",
    "sample_int = random.randint(1, len(test_files)-1)\n",
    "y_true, y_pred, y_phys = scaled_targets[sample_int], scaled_outputs[sample_int], scaled_priors[sample_int]\n",
    "\n",
    "###############################################\n",
    "# PLOT PREDICTION -----------------------------------------------------------------\n",
    "if PLOT_ACTIVE:\n",
    "     plt.figure(figsize=(18,4)); plt.xlabel('Time in s'); plt.ylabel('SOC in %'); plt.title('Battery State of Charge: Prediction vs. Actual Data') \n",
    "     plt.plot(y_true, label='Actual Data') # actual plot\n",
    "     plt.plot(np.arange(0, len(y_true), 1), y_pred, label='Predicted Data') # predicted plot\n",
    "     plt.plot(y_phys, label='Physical Prior') # physical prior\n",
    "     plt.ylim(0, 100) # set y-axis limits\n",
    "\n",
    "     plt.legend()\n",
    "     plt.text(0.01, 0.02, f\"RMSE: {root_mean_squared_error(y_true, y_pred):.4f}\\nStd Dev: {np.std(y_true - y_pred):.4f}\\nModel ID: {model_name_id}\",\\\n",
    "          transform=plt.gca().transAxes, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "     plt.figure(figsize=(18,4)); plt.xlabel('Time in s'); plt.ylabel('SOC in %')\n",
    "     plt.plot(savgol_filter(y_true.flatten(), window_length=60, polyorder=3), label='Actual Data (Smoothed)') # actual plot\n",
    "     plt.plot(np.arange(0, len(y_true), 1), savgol_filter(y_pred.flatten(), window_length=60, polyorder=3), label='Predicted Data (Smoothed)') # predicted plot\n",
    "     plt.ylim(0, 100) # set y-axis limits\n",
    "     plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sieglew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
